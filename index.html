<!DOCTYPE html>
<html lang="ko" data-theme="dark">
<head>
    <!-- BEGIN: Google adsense -->
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2110881342960271" crossorigin="anonymous"></script>
    <!-- END: Google adsense -->
    <!-- BEGIN: Google adsense repair -->
    <script async src="https://fundingchoicesmessages.google.com/i/pub-2110881342960271?ers=1" nonce="laI6FT8gpRxugDJv5AGJRA"></script><script nonce="laI6FT8gpRxugDJv5AGJRA">(function() {function signalGooglefcPresent() {if (!window.frames['googlefcPresent']) {if (document.body) {const iframe = document.createElement('iframe'); iframe.style = 'width: 0; height: 0; border: none; z-index: -1000; left: -1000px; top: -1000px;'; iframe.style.display = 'none'; iframe.name = 'googlefcPresent'; document.body.appendChild(iframe);} else {setTimeout(signalGooglefcPresent, 0);}}}signalGooglefcPresent();})();</script>
    <!-- END: Google adsense repair -->
    <!-- BEGIN: Google analytics -->
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-1VWQF060SX"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-1VWQF060SX');
    </script>
    <!-- END: Google analytics -->
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="author" content="MINZKN.COM">
    <meta name="description" content="Python Complete Guide - 초급부터 고급까지, 데이터 과학/머신러닝/딥러닝을 아우르는 포괄적인 파이썬 레퍼런스">
    <meta name="license" content="MIT">
    <title>Python Complete Guide - 완벽한 파이썬 가이드</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@400;500;600;700&family=Fira+Code:wght@400;500&display=swap" rel="stylesheet">
    <style>
        /* ====================================================
           CSS Custom Properties - 테마 시스템
           ==================================================== */
        :root {
            --header-height: 60px;
            --nav-width: 260px;

            /* Dark theme (기본) */
            --bg-primary:    #0d1117;
            --bg-secondary:  #161b22;
            --bg-tertiary:   #1c2128;
            --bg-card:       #21262d;
            --border:        #30363d;
            --border-subtle: #21262d;

            --text-primary:   #e6edf3;
            --text-secondary: #8b949e;
            --text-muted:     #6e7681;

            --accent:       #FFD43B;   /* Python yellow */
            --accent-hover: #ffc107;
            --accent-blue:  #4584b6;   /* Python blue (다크 배경용) */
            --link:         #79c0ff;
            --link-hover:   #a5d6ff;

            --code-bg: #1e1e1e;
            --code-fg: #d4d4d4;

            --header-bg: rgba(22, 27, 34, 0.95);
            --nav-bg:    #161b22;

            --shadow:    rgba(0, 0, 0, 0.5);
            --shadow-sm: rgba(0, 0, 0, 0.25);

            /* SVG 테마 적응 색상 */
            --svg-blue:        rgba(33, 150, 243, 0.15);
            --svg-green:       rgba(76, 175, 80, 0.15);
            --svg-orange:      rgba(255, 152, 0, 0.15);
            --svg-pink:        rgba(233, 30, 99, 0.15);
            --svg-gray:        rgba(139, 148, 158, 0.1);
            --svg-inner:       #2d333b;
            --svg-blue-text:   #58a6ff;
            --svg-green-text:  #56d364;
            --svg-orange-text: #d29922;
            --svg-pink-text:   #f778ba;
        }

        [data-theme="light"] {
            --bg-primary:    #f6f8fa;
            --bg-secondary:  #ffffff;
            --bg-tertiary:   #eaeef2;
            --bg-card:       #ffffff;
            --border:        #d0d7de;
            --border-subtle: #eaeef2;

            --text-primary:   #24292f;
            --text-secondary: #57606a;
            --text-muted:     #6e7781;

            --accent:       #3776AB;   /* Python blue (라이트 배경용) */
            --accent-hover: #2d5f8a;
            --accent-blue:  #3776AB;
            --link:         #0969da;
            --link-hover:   #0550ae;

            --code-bg: #1e1e1e;
            --code-fg: #d4d4d4;

            --header-bg: rgba(255, 255, 255, 0.97);
            --nav-bg:    #ffffff;

            --shadow:    rgba(0, 0, 0, 0.1);
            --shadow-sm: rgba(0, 0, 0, 0.05);

            /* SVG 테마 적응 색상 */
            --svg-blue:        #e3f2fd;
            --svg-green:       #e8f5e9;
            --svg-orange:      #fff3e0;
            --svg-pink:        #fce4ec;
            --svg-gray:        #f0f0f0;
            --svg-inner:       #ffffff;
            --svg-blue-text:   #1565C0;
            --svg-green-text:  #2E7D32;
            --svg-orange-text: #E65100;
            --svg-pink-text:   #c2185b;
        }

        /* ====================================================
           Reset & Base
           ==================================================== */
        *, *::before, *::after {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        html {
            scroll-behavior: smooth;
            scroll-padding-top: calc(var(--header-height) + 16px);
        }

        body {
            font-family: "Noto Sans KR", "Malgun Gothic", "Apple SD Gothic Neo", sans-serif;
            font-size: 16px;
            line-height: 1.8;
            color: var(--text-primary);
            background: var(--bg-primary);
            transition: background 0.3s, color 0.3s;
            min-height: 100vh;
        }

        a {
            color: var(--link);
            text-decoration: none;
        }
        a:hover {
            color: var(--link-hover);
            text-decoration: underline;
        }

        /* ====================================================
           Progress Bar
           ==================================================== */
        .progress-bar {
            position: fixed;
            top: 0;
            left: 0;
            height: 3px;
            background: linear-gradient(90deg, var(--accent), var(--accent-blue));
            width: 0%;
            transition: width 0.1s;
            z-index: 2000;
        }

        /* ====================================================
           Site Header
           ==================================================== */
        .site-header {
            position: sticky;
            top: 0;
            height: var(--header-height);
            background: var(--header-bg);
            backdrop-filter: blur(10px);
            -webkit-backdrop-filter: blur(10px);
            border-bottom: 1px solid var(--border);
            z-index: 100;
            transition: background 0.3s, border-color 0.3s;
        }

        .header-inner {
            display: flex;
            align-items: center;
            justify-content: space-between;
            height: 100%;
            padding: 0 20px;
        }

        .header-left {
            display: flex;
            align-items: center;
            gap: 12px;
        }

        /* ====================================================
           Home Icon
           ==================================================== */
        .home-icon {
            display: flex;
            align-items: center;
            justify-content: center;
            width: 32px;
            height: 32px;
            font-size: 1.4rem;
            text-decoration: none;
            flex-shrink: 0;
            line-height: 1;
            transition: opacity 0.2s;
        }

        .home-icon:hover {
            text-decoration: none;
            opacity: 0.7;
        }

        /* ====================================================
           Hamburger
           ==================================================== */
        .hamburger {
            display: none;
            flex-direction: column;
            justify-content: center;
            gap: 5px;
            width: 36px;
            height: 36px;
            background: none;
            border: none;
            cursor: pointer;
            padding: 6px;
            border-radius: 6px;
            flex-shrink: 0;
        }

        .hamburger span {
            display: block;
            height: 2px;
            background: var(--text-primary);
            border-radius: 2px;
            transition: all 0.3s ease;
        }

        .hamburger.open span:nth-child(1) { transform: translateY(7px) rotate(45deg); }
        .hamburger.open span:nth-child(2) { opacity: 0; }
        .hamburger.open span:nth-child(3) { transform: translateY(-7px) rotate(-45deg); }

        /* ====================================================
           Brand
           ==================================================== */
        .brand {
            display: flex;
            align-items: center;
            gap: 10px;
            text-decoration: none;
            color: var(--text-primary);
        }
        .brand:hover { text-decoration: none; }

        .brand-icon {
            width: 32px;
            height: 32px;
            flex-shrink: 0;
        }

        .brand-name {
            font-size: 1rem;
            font-weight: 700;
            color: var(--accent);
            letter-spacing: -0.02em;
            white-space: nowrap;
        }

        /* ====================================================
           Header Right / Theme Toggle
           ==================================================== */
        .header-right {
            display: flex;
            align-items: center;
            gap: 8px;
        }

        .theme-toggle {
            display: flex;
            align-items: center;
            justify-content: center;
            width: 36px;
            height: 36px;
            background: var(--bg-tertiary);
            border: 1px solid var(--border);
            border-radius: 8px;
            cursor: pointer;
            font-size: 1rem;
            transition: all 0.2s;
            color: var(--text-primary);
        }

        .theme-toggle:hover {
            background: var(--bg-card);
            border-color: var(--accent);
        }

        /* ====================================================
           Nav Overlay (모바일)
           ==================================================== */
        .nav-overlay {
            display: none;
            position: fixed;
            inset: 0;
            background: rgba(0, 0, 0, 0.5);
            z-index: 90;
            opacity: 0;
            transition: opacity 0.3s;
            pointer-events: none;
        }

        .nav-overlay.active {
            opacity: 1;
            pointer-events: auto;
        }

        /* ====================================================
           Layout (사이드바 + 메인)
           ==================================================== */
        .layout {
            display: grid;
            grid-template-columns: var(--nav-width) 1fr;
            min-height: calc(100vh - var(--header-height));
            align-items: start;
        }

        /* ====================================================
           Side Nav
           ==================================================== */
        .side-nav {
            width: var(--nav-width);
            background: var(--nav-bg);
            border-right: 1px solid var(--border);
            position: sticky;
            top: var(--header-height);
            height: calc(100vh - var(--header-height));
            overflow-y: auto;
            overflow-x: hidden;
            padding: 20px 0;
            transition: background 0.3s, border-color 0.3s, transform 0.3s ease;
        }

        .side-nav::-webkit-scrollbar { width: 4px; }
        .side-nav::-webkit-scrollbar-track { background: transparent; }
        .side-nav::-webkit-scrollbar-thumb { background: var(--border); border-radius: 2px; }

        .side-nav ul {
            list-style: none;
            padding: 0;
        }

        .side-nav li { margin: 0; }

        .side-nav a {
            display: block;
            padding: 8px 20px;
            color: var(--text-secondary);
            text-decoration: none;
            font-size: 0.875rem;
            font-weight: 500;
            transition: all 0.2s;
            border-left: 3px solid transparent;
        }

        .side-nav a:hover {
            color: var(--text-primary);
            background: var(--bg-tertiary);
            border-left-color: var(--accent);
            text-decoration: none;
        }

        .side-nav a.active {
            color: var(--accent);
            background: var(--bg-tertiary);
            border-left-color: var(--accent);
            font-weight: 600;
        }

        .side-nav a:focus-visible {
            outline: 2px solid var(--accent);
            outline-offset: -2px;
        }

        /* ====================================================
           Main Content
           ==================================================== */
        .main-content {
            min-width: 0;
            padding-bottom: 60px;
        }

        /* ====================================================
           Content Hero
           ==================================================== */
        .content-hero {
            text-align: center;
            padding: 60px 48px 50px;
            border-bottom: 1px solid var(--border);
            background: var(--bg-secondary);
        }

        .content-hero .python-logo {
            width: 96px;
            height: 96px;
            margin: 0 auto 20px;
            display: block;
        }

        .content-hero h1 {
            font-size: 2.5rem;
            font-weight: 700;
            color: var(--accent);
            margin-bottom: 10px;
            letter-spacing: -0.03em;
        }

        .content-hero .subtitle {
            font-size: 1.1rem;
            color: var(--text-secondary);
        }

        /* ====================================================
           Sections
           ==================================================== */
        section {
            padding: 48px;
            border-bottom: 1px solid var(--border);
            background: var(--bg-secondary);
            transition: background 0.3s;
        }

        /* ====================================================
           Headings
           ==================================================== */
        h2 {
            font-size: 1.75rem;
            font-weight: 700;
            color: var(--text-primary);
            margin-bottom: 20px;
            padding-bottom: 12px;
            border-bottom: 2px solid var(--accent);
            line-height: 1.3;
        }

        h3 {
            font-size: 1.2rem;
            font-weight: 600;
            color: var(--link);
            margin: 30px 0 12px;
            line-height: 1.4;
        }

        h4 {
            font-size: 1.0rem;
            font-weight: 600;
            color: var(--text-primary);
            margin: 16px 0 8px;
        }

        p {
            margin-bottom: 14px;
            color: var(--text-primary);
        }

        /* ====================================================
           Inline Code
           ==================================================== */
        code {
            font-family: "Fira Code", "D2Coding", "D2 Coding", "Consolas", monospace;
            font-size: 0.875em;
            background: var(--bg-tertiary);
            color: var(--link);
            padding: 0.15em 0.4em;
            border-radius: 4px;
            border: 1px solid var(--border);
        }

        /* ====================================================
           Code Block
           ==================================================== */
        .code-block {
            background: var(--code-bg);
            color: var(--code-fg);
            padding: 20px 24px;
            border-radius: 8px;
            margin: 20px 0;
            overflow-x: auto;
            font-family: "Fira Code", "D2Coding", "D2 Coding", "Consolas", monospace;
            font-size: 0.875rem;
            line-height: 1.7;
            border-left: 4px solid var(--accent-blue);
            white-space: pre;
            display: block;
        }

        .code-block code {
            display: block;
            white-space: pre;
            background: none;
            color: inherit;
            padding: 0;
            border: none;
            border-radius: 0;
            font-size: inherit;
        }

        .code-block .keyword  { color: #569cd6; }
        .code-block .string   { color: #ce9178; }
        .code-block .comment  { color: #6a9955; }
        .code-block .function { color: #dcdcaa; }
        .code-block .number   { color: #b5cea8; }
        .code-block .builtin  { color: #4ec9b0; }
        .code-block .decorator{ color: #d7ba7d; }
        .code-block .class    { color: #4ec9b0; }

        /* ====================================================
           Lists
           ==================================================== */
        ul, ol {
            margin: 12px 0 12px 28px;
        }

        li {
            margin-bottom: 6px;
            color: var(--text-primary);
        }

        /* ====================================================
           Feature Grid & Cards
           ==================================================== */
        .feature-grid {
            display: grid;
            grid-template-columns: repeat(auto-fill, minmax(230px, 1fr));
            gap: 16px;
            margin: 24px 0;
        }

        .feature-card {
            background: var(--bg-card);
            border: 1px solid var(--border);
            border-radius: 10px;
            padding: 20px;
            transition: transform 0.2s, border-color 0.2s, box-shadow 0.2s;
        }

        .feature-card:hover {
            transform: translateY(-3px);
            border-color: var(--accent);
            box-shadow: 0 6px 20px var(--shadow-sm);
        }

        .feature-card h4 {
            color: var(--accent);
            margin-bottom: 8px;
            margin-top: 0;
        }

        .feature-card ul {
            margin: 8px 0 0 16px;
        }

        .feature-card li {
            font-size: 0.875rem;
        }

        /* ====================================================
           Level Badge
           ==================================================== */
        .level-badge {
            display: inline-block;
            padding: 3px 12px;
            border-radius: 20px;
            font-size: 0.8rem;
            font-weight: 600;
            margin-bottom: 16px;
            margin-right: 4px;
        }

        .level-badge.level-beginner     { background: #1a7f37; color: #fff; }
        .level-badge.level-intermediate { background: #9a6700; color: #fff; }
        .level-badge.level-advanced     { background: #cf222e; color: #fff; }
        .level-badge.level-expert       { background: #8250df; color: #fff; }

        /* ====================================================
           SVG Container
           ==================================================== */
        .svg-container {
            background: var(--bg-card);
            border: 1px solid var(--border);
            border-radius: 10px;
            padding: 20px;
            margin: 20px 0;
            text-align: center;
        }

        .svg-container svg {
            max-width: 100%;
            height: auto;
        }

        /* ====================================================
           Highlight
           ==================================================== */
        .highlight {
            background: rgba(255, 212, 59, 0.2);
            color: var(--text-primary);
            padding: 2px 6px;
            border-radius: 4px;
            font-weight: 500;
        }

        [data-theme="light"] .highlight {
            background: rgba(55, 118, 171, 0.15);
        }

        /* ====================================================
           Info Boxes
           ==================================================== */
        .tip-box, .warning-box {
            padding: 14px 18px;
            margin: 18px 0;
            border-left: 4px solid;
            border-radius: 0 8px 8px 0;
        }

        .tip-box {
            background: rgba(79, 132, 182, 0.12);
            border-color: var(--accent-blue);
        }

        .warning-box {
            background: rgba(154, 103, 0, 0.12);
            border-color: #e09000;
        }

        [data-theme="light"] .tip-box    { background: #e3f2fd; border-color: #2196F3; }
        [data-theme="light"] .warning-box{ background: #fff3e0; border-color: #ff9800; }

        .tip-box ul, .warning-box ul {
            margin: 8px 0 0 18px;
        }

        /* ====================================================
           Level Guide Boxes - 레벨별 가이드 박스
           ==================================================== */
        .level-guide {
            margin: 20px 0;
            border-radius: 10px;
            overflow: hidden;
            border: 1px solid var(--border);
        }
        .level-guide-header {
            padding: 10px 16px;
            font-weight: 600;
            font-size: 0.95rem;
            cursor: pointer;
            display: flex;
            align-items: center;
            gap: 8px;
            user-select: none;
        }
        .level-guide-header::after {
            content: '▼';
            font-size: 0.7rem;
            margin-left: auto;
            transition: transform 0.3s;
        }
        .level-guide-header.collapsed::after {
            transform: rotate(-90deg);
        }
        .level-guide-content {
            padding: 14px 18px;
            line-height: 1.8;
        }
        .level-guide-content.collapsed {
            display: none;
        }
        .level-guide-content ul {
            margin: 6px 0 6px 18px;
        }
        .level-guide-content li {
            margin-bottom: 4px;
        }
        .level-guide-content code {
            font-size: 0.88em;
        }
        .level-guide-content p {
            margin-bottom: 8px;
        }

        /* 초급 */
        .level-guide.beginner {
            background: rgba(76, 175, 80, 0.06);
            border-color: rgba(76, 175, 80, 0.3);
        }
        .level-guide.beginner .level-guide-header {
            background: rgba(76, 175, 80, 0.1);
            color: #4CAF50;
        }
        [data-theme="light"] .level-guide.beginner {
            background: #e8f5e9;
            border-color: rgba(76, 175, 80, 0.4);
        }
        [data-theme="light"] .level-guide.beginner .level-guide-header {
            background: #c8e6c9;
            color: #2E7D32;
        }

        /* 중급 */
        .level-guide.intermediate {
            background: rgba(33, 150, 243, 0.06);
            border-color: rgba(33, 150, 243, 0.3);
        }
        .level-guide.intermediate .level-guide-header {
            background: rgba(33, 150, 243, 0.1);
            color: #42A5F5;
        }
        [data-theme="light"] .level-guide.intermediate {
            background: #e3f2fd;
            border-color: rgba(33, 150, 243, 0.4);
        }
        [data-theme="light"] .level-guide.intermediate .level-guide-header {
            background: #bbdefb;
            color: #1565C0;
        }

        /* 고급 */
        .level-guide.advanced {
            background: rgba(156, 39, 176, 0.06);
            border-color: rgba(156, 39, 176, 0.3);
        }
        .level-guide.advanced .level-guide-header {
            background: rgba(156, 39, 176, 0.1);
            color: #AB47BC;
        }
        [data-theme="light"] .level-guide.advanced {
            background: #f3e5f5;
            border-color: rgba(156, 39, 176, 0.4);
        }
        [data-theme="light"] .level-guide.advanced .level-guide-header {
            background: #e1bee7;
            color: #7B1FA2;
        }

        /* ====================================================
           Two Columns
           ==================================================== */
        .two-columns {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 24px;
            margin: 18px 0;
        }

        /* ====================================================
           Comparison Table
           ==================================================== */
        .comparison-table {
            width: 100%;
            border-collapse: collapse;
            margin: 18px 0;
            font-size: 0.9rem;
        }

        .comparison-table th,
        .comparison-table td {
            padding: 10px 14px;
            text-align: left;
            border-bottom: 1px solid var(--border);
        }

        .comparison-table th {
            background: var(--accent-blue);
            color: #fff;
            font-weight: 600;
        }

        .comparison-table tr:nth-child(even) td {
            background: var(--bg-tertiary);
        }

        .comparison-table tbody tr:hover td {
            background: rgba(79, 132, 182, 0.1);
        }

        /* ====================================================
           Quiz Box
           ==================================================== */
        .quiz-box {
            background: linear-gradient(135deg, #162032 0%, #1e1040 100%);
            border: 1px solid var(--accent);
            border-radius: 12px;
            padding: 28px;
            margin: 28px 0;
            color: var(--text-primary);
        }

        [data-theme="light"] .quiz-box {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            border: none;
            color: white;
        }

        .quiz-box h3 {
            color: var(--accent);
            margin-top: 0;
            margin-bottom: 16px;
        }

        [data-theme="light"] .quiz-box h3 { color: white; }

        .quiz-option {
            background: var(--bg-tertiary);
            border: 1px solid var(--border);
            padding: 12px 16px;
            border-radius: 8px;
            margin: 8px 0;
            cursor: pointer;
            transition: all 0.2s;
            color: var(--text-primary);
        }

        .quiz-option:hover {
            border-color: var(--accent);
            background: rgba(255, 212, 59, 0.1);
        }

        [data-theme="light"] .quiz-option {
            background: rgba(255, 255, 255, 0.2);
            border-color: transparent;
            color: white;
        }

        [data-theme="light"] .quiz-option:hover {
            background: rgba(255, 255, 255, 0.35);
        }

        /* ====================================================
           Resource Links
           ==================================================== */
        .resource-links {
            display: grid;
            grid-template-columns: repeat(auto-fill, minmax(170px, 1fr));
            gap: 12px;
            margin: 18px 0;
        }

        .resource-link {
            background: var(--bg-card);
            border: 1px solid var(--border);
            padding: 16px;
            border-radius: 8px;
            text-align: center;
            text-decoration: none;
            color: var(--link);
            transition: all 0.2s;
            font-size: 0.9rem;
        }

        .resource-link:hover {
            border-color: var(--accent);
            transform: translateY(-2px);
            text-decoration: none;
            color: var(--link-hover);
            box-shadow: 0 4px 12px var(--shadow-sm);
        }

        /* ====================================================
           Footer
           ==================================================== */
        footer {
            padding: 32px 48px;
            text-align: center;
            border-top: 1px solid var(--border);
            background: var(--nav-bg);
            font-size: 0.875rem;
        }

        footer p {
            color: var(--text-secondary);
            margin-bottom: 6px;
        }

        /* ====================================================
           Back to Top Button
           ==================================================== */
        .back-to-top {
            position: fixed;
            bottom: 28px;
            right: 28px;
            width: 44px;
            height: 44px;
            background: var(--accent);
            color: #000;
            border: none;
            border-radius: 50%;
            font-size: 1.1rem;
            font-weight: 700;
            cursor: pointer;
            z-index: 500;
            opacity: 0;
            transform: translateY(10px);
            transition: opacity 0.3s, transform 0.3s, box-shadow 0.2s;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .back-to-top.visible {
            opacity: 1;
            transform: translateY(0);
        }

        .back-to-top:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 14px var(--shadow);
        }

        /* ====================================================
           Responsive
           ==================================================== */
        @media (max-width: 1024px) {
            .layout {
                grid-template-columns: 1fr;
            }

            .side-nav {
                position: fixed;
                top: var(--header-height);
                left: 0;
                height: calc(100vh - var(--header-height));
                transform: translateX(-100%);
                z-index: 95;
                box-shadow: 4px 0 20px var(--shadow);
            }

            .side-nav.open {
                transform: translateX(0);
            }

            .nav-overlay { display: block; }

            .hamburger { display: flex; }

            section { padding: 32px 24px; }

            .content-hero { padding: 40px 24px 32px; }

            footer { padding: 24px; }
        }

        @media (max-width: 768px) {
            .brand-name { display: none; }

            .content-hero h1 { font-size: 1.8rem; }

            .two-columns { grid-template-columns: 1fr; }

            .comparison-table {
                display: block;
                overflow-x: auto;
                -webkit-overflow-scrolling: touch;
            }

            .feature-grid { grid-template-columns: 1fr; }

            h2 { font-size: 1.4rem; }
            h3 { font-size: 1.1rem; }

            .back-to-top {
                bottom: 16px;
                right: 16px;
                width: 40px;
                height: 40px;
            }
        }

        @media (prefers-reduced-motion: reduce) {
            *, *::before, *::after {
                transition-duration: 0.01ms !important;
                animation-duration: 0.01ms !important;
            }
        }
    </style>
</head>
<body>
    <div class="progress-bar" id="progressBar"></div>

    <!-- 상단 헤더 바 -->
    <header class="site-header">
        <div class="header-inner">
            <div class="header-left">
                <a href="https://www.minzkn.com/" class="home-icon" aria-label="MINZKN.COM" target="_top" rel="noopener">&#127968;</a>
                <button class="hamburger" id="hamburger" aria-label="메뉴 열기/닫기">
                    <span></span><span></span><span></span>
                </button>
                <a href="#intro" class="brand">
                    <svg class="brand-icon" viewBox="0 0 100 100" xmlns="http://www.w3.org/2000/svg">
                        <circle cx="50" cy="50" r="45" fill="#3776AB"/>
                        <text x="50" y="65" font-size="50" font-weight="bold" fill="white" text-anchor="middle">Py</text>
                        <circle cx="30" cy="35" r="8" fill="#FFD43B"/>
                        <circle cx="70" cy="35" r="8" fill="#FFD43B"/>
                    </svg>
                    <span class="brand-name">Python Complete Guide</span>
                </a>
            </div>
            <div class="header-right">
                <button class="theme-toggle" id="themeToggle" aria-label="테마 전환">
                    <span class="theme-icon">☀️</span>
                </button>
            </div>
        </div>
    </header>

    <!-- 모바일 오버레이 -->
    <div class="nav-overlay" id="navOverlay"></div>

    <!-- 레이아웃: 사이드바 + 메인 -->
    <div class="layout">

        <!-- 사이드바 네비게이션 -->
        <nav class="side-nav" id="sideNav" aria-label="목차">
            <ul>
                <li><a href="#intro">1. 파이썬이란?</a></li>
                <li><a href="#basics">2. 기초 문법</a></li>
                <li><a href="#datatypes">3. 자료형</a></li>
                <li><a href="#control">4. 제어문</a></li>
                <li><a href="#functions">5. 함수</a></li>
                <li><a href="#oop">6. 객체지향</a></li>
                <li><a href="#exception">7. 예외 처리</a></li>
                <li><a href="#modules">8. 모듈/패키지</a></li>
                <li><a href="#fileio">9. 파일 입출력</a></li>
                <li><a href="#regex">10. 정규식</a></li>
                <li><a href="#testing">11. 테스팅</a></li>
                
                <li><a href="#data-science">12. 데이터 과학</a></li>
                <li><a href="#machine-learning">13. 머신러닝</a></li>
                <li><a href="#deep-learning">14. 딥러닝</a></li>
                <li><a href="#resources">15. 참고 자료</a></li>
            </ul>
        </nav>

        <!-- 메인 컨텐츠 -->
        <main class="main-content">

            <!-- 히어로 섹션 -->
            <div class="content-hero">
                <svg class="python-logo" viewBox="0 0 100 100" xmlns="http://www.w3.org/2000/svg">
                    <circle cx="50" cy="50" r="45" fill="#3776AB"/>
                    <text x="50" y="65" font-size="50" font-weight="bold" fill="white" text-anchor="middle">Py</text>
                    <circle cx="30" cy="35" r="8" fill="#FFD43B"/>
                    <circle cx="70" cy="35" r="8" fill="#FFD43B"/>
                </svg>
                <h1>Python Complete Guide</h1>
                <p class="subtitle">초급부터 고급까지: 파이썬의 모든 것</p>
            </div>

        <section id="intro">
            <h2>1. 파이썬이란?</h2>
            <p>
                <span class="highlight">파이썬(Python)</span>은 1991년 네덜란드 CWI의 <strong>귀도 반 로섬(Guido van Rossum)</strong>이 발표한 고급 프로그래밍 언어입니다.
                파이썬이라는 이름은 자신이 좋아하던 코미디 쇼 "몬티 파이썬의 날아다니는 서커스"에서 따왔다고 합니다.
            </p>
            <p>
                파이썬은 <strong>TIOBE Index</strong>에서 꾸준히 1위를 차지하며, 전 세계에서 가장 인기 있는 프로그래밍 언어로 자리 잡았습니다.
                웹 개발(Django, Flask), 데이터 과학(NumPy, Pandas), 인공지능/머신러닝(TensorFlow, PyTorch), 자동화 스크립팅, 게임 개발, IoT 등
                거의 모든 소프트웨어 분야에서 활용됩니다. 특히 <strong>간결하고 읽기 쉬운 문법</strong>은 프로그래밍 입문자부터 숙련 개발자까지 폭넓은 사용자층을 형성하는 핵심 이유입니다.
            </p>

            <div class="svg-container">
                <!-- Python 활용 분야 다이어그램 -->
                <svg width="700" height="380" viewBox="0 0 700 380" xmlns="http://www.w3.org/2000/svg">
                    <!-- 중앙 Python 원 -->
                    <circle cx="350" cy="190" r="65" fill="#667eea" stroke="#4a5ae0" stroke-width="3"/>
                    <text x="350" y="185" text-anchor="middle" fill="white" font-weight="bold" font-size="18">Python</text>
                    <text x="350" y="205" text-anchor="middle" fill="rgba(255,255,255,0.8)" font-size="11">범용 언어</text>

                    <!-- 웹 개발 -->
                    <rect x="30" y="20" width="140" height="70" rx="12" fill="var(--svg-blue)" stroke="#2196F3" stroke-width="2"/>
                    <text x="100" y="50" text-anchor="middle" font-weight="bold" fill="var(--svg-blue-text)" font-size="14">웹 개발</text>
                    <text x="100" y="70" text-anchor="middle" fill="var(--text-secondary)" font-size="11">Django, Flask, FastAPI</text>
                    <line x1="170" y1="55" x2="290" y2="155" stroke="#2196F3" stroke-width="1.5" stroke-dasharray="4,3"/>

                    <!-- 데이터 과학 -->
                    <rect x="530" y="20" width="140" height="70" rx="12" fill="var(--svg-green)" stroke="#4CAF50" stroke-width="2"/>
                    <text x="600" y="50" text-anchor="middle" font-weight="bold" fill="var(--svg-green-text)" font-size="14">데이터 과학</text>
                    <text x="600" y="70" text-anchor="middle" fill="var(--text-secondary)" font-size="11">NumPy, Pandas</text>
                    <line x1="530" y1="55" x2="410" y2="155" stroke="#4CAF50" stroke-width="1.5" stroke-dasharray="4,3"/>

                    <!-- AI / ML -->
                    <rect x="530" y="155" width="140" height="70" rx="12" fill="var(--svg-orange)" stroke="#ff9800" stroke-width="2"/>
                    <text x="600" y="185" text-anchor="middle" font-weight="bold" fill="var(--svg-orange-text)" font-size="14">AI / ML</text>
                    <text x="600" y="205" text-anchor="middle" fill="var(--text-secondary)" font-size="11">TensorFlow, PyTorch</text>
                    <line x1="530" y1="190" x2="415" y2="190" stroke="#ff9800" stroke-width="1.5" stroke-dasharray="4,3"/>

                    <!-- 자동화 -->
                    <rect x="30" y="155" width="140" height="70" rx="12" fill="var(--svg-pink)" stroke="#e91e63" stroke-width="2"/>
                    <text x="100" y="185" text-anchor="middle" font-weight="bold" fill="var(--svg-pink-text)" font-size="14">자동화</text>
                    <text x="100" y="205" text-anchor="middle" fill="var(--text-secondary)" font-size="11">스크립팅, 크롤링</text>
                    <line x1="170" y1="190" x2="285" y2="190" stroke="#e91e63" stroke-width="1.5" stroke-dasharray="4,3"/>

                    <!-- 시각화 -->
                    <rect x="30" y="290" width="140" height="70" rx="12" fill="var(--svg-green)" stroke="#4CAF50" stroke-width="2"/>
                    <text x="100" y="320" text-anchor="middle" font-weight="bold" fill="var(--svg-green-text)" font-size="14">시각화</text>
                    <text x="100" y="340" text-anchor="middle" fill="var(--text-secondary)" font-size="11">Matplotlib, Seaborn</text>
                    <line x1="170" y1="325" x2="310" y2="245" stroke="#4CAF50" stroke-width="1.5" stroke-dasharray="4,3"/>

                    <!-- DevOps / 인프라 -->
                    <rect x="280" y="300" width="140" height="70" rx="12" fill="var(--svg-blue)" stroke="#2196F3" stroke-width="2"/>
                    <text x="350" y="330" text-anchor="middle" font-weight="bold" fill="var(--svg-blue-text)" font-size="14">DevOps</text>
                    <text x="350" y="350" text-anchor="middle" fill="var(--text-secondary)" font-size="11">Ansible, Fabric</text>
                    <line x1="350" y1="300" x2="350" y2="255" stroke="#2196F3" stroke-width="1.5" stroke-dasharray="4,3"/>

                    <!-- 게임 / IoT -->
                    <rect x="530" y="290" width="140" height="70" rx="12" fill="var(--svg-orange)" stroke="#ff9800" stroke-width="2"/>
                    <text x="600" y="320" text-anchor="middle" font-weight="bold" fill="var(--svg-orange-text)" font-size="14">게임 / IoT</text>
                    <text x="600" y="340" text-anchor="middle" fill="var(--text-secondary)" font-size="11">Pygame, RPi</text>
                    <line x1="530" y1="325" x2="390" y2="245" stroke="#ff9800" stroke-width="1.5" stroke-dasharray="4,3"/>
                </svg>
            </div>
            
            <h3>파이썬의 핵심 철학 (PEP 20)</h3>
            <p>파이썬의 설계 원칙은 <strong>PEP 20 (The Zen of Python)</strong>에 담겨 있으며, 인터프리터에서 <code>import this</code>를 실행하면 확인할 수 있습니다. 이 철학은 코드 작성 시 가독성과 단순함을 최우선으로 두라는 메시지를 전달합니다.</p>
            <div class="tip-box">
                <ul>
                    <li>"아름다운 게 추한 것보다 낫다." (Beautiful is better than ugly)</li>
                    <li>"명시적인 것이 암시적인 것보다 낫다." (Explicit is better than implicit)</li>
                    <li>"단순함이 복잡함보다 낫다." (Simple is better than complex)</li>
                    <li>"복잡함이 난해한 것보다 낫다." (Complex is better than complicated)</li>
                    <li>"가독성은 중요하다." (Readability counts)</li>
                </ul>
            </div>
            
            <p><strong>"인생은 너무 짧다. 그래서 파이썬이 필요하다."</strong> ("Life is short, You need Python.")</p>

            <div class="level-guide beginner">
                <div class="level-guide-header">초급자 가이드 - 파이썬을 왜 배워야 할까?</div>
                <div class="level-guide-content">
                    <p>파이썬은 프로그래밍을 처음 접하는 분에게 가장 권장되는 언어입니다. 그 이유는:</p>
                    <ul>
                        <li><strong>쉬운 문법</strong>: 영어 문장을 읽듯 코드를 읽을 수 있습니다. 예를 들어 <code>if age >= 18: print("성인")</code>은 "만약 나이가 18 이상이면 '성인'을 출력하라"와 같습니다.</li>
                        <li><strong>설치 후 바로 시작</strong>: python.org에서 설치 후 터미널에 <code>python</code>을 입력하면 바로 코드를 실행할 수 있습니다.</li>
                        <li><strong>방대한 학습 자료</strong>: 한국어 강좌, 책, 유튜브 영상 등 풍부한 자료가 있어 독학이 용이합니다.</li>
                        <li><strong>높은 취업 수요</strong>: 데이터 분석, AI, 웹 개발, 자동화 등 거의 모든 IT 분야에서 파이썬 개발자를 찾고 있습니다.</li>
                    </ul>
                    <p><strong>처음 시작하는 팁:</strong> Python을 설치한 후 터미널(또는 명령 프롬프트)에서 <code>python</code>을 입력하면 대화형 모드(REPL)가 시작됩니다. 여기서 <code>print("Hello!")</code>를 입력해보세요. 이것이 여러분의 첫 번째 파이썬 프로그램입니다!</p>
                </div>
            </div>

            <div class="level-guide intermediate">
                <div class="level-guide-header">중급자 가이드 - 파이썬의 실무 활용</div>
                <div class="level-guide-content">
                    <p>기본 문법을 익혔다면, 파이썬이 실무에서 어떻게 활용되는지 이해하는 것이 중요합니다:</p>
                    <ul>
                        <li><strong>웹 개발</strong>: Django(대규모 서비스, Instagram/Pinterest 사용), Flask(경량 API), FastAPI(고성능 비동기 API)로 백엔드를 구축합니다.</li>
                        <li><strong>데이터 엔지니어링</strong>: Apache Airflow(워크플로 자동화), PySpark(대규모 데이터 처리)로 데이터 파이프라인을 구축합니다.</li>
                        <li><strong>DevOps/자동화</strong>: Ansible, Fabric으로 서버 관리를 자동화하고, Selenium으로 웹 테스트를 자동화합니다.</li>
                        <li><strong>패키지 관리</strong>: 실무에서는 <code>venv</code> 대신 <code>poetry</code>나 <code>uv</code>를 사용하여 의존성을 더 체계적으로 관리하는 추세입니다.</li>
                    </ul>
                </div>
            </div>

            <div class="level-guide advanced">
                <div class="level-guide-header">고급자 가이드 - 파이썬의 내부 구조와 한계</div>
                <div class="level-guide-content">
                    <p>파이썬의 내부 동작 원리를 이해하면 더 효율적인 코드를 작성할 수 있습니다:</p>
                    <ul>
                        <li><strong>CPython 바이트코드</strong>: Python 소스코드는 먼저 바이트코드(.pyc)로 컴파일되고, 이후 CPython VM이 이를 해석 실행합니다. <code>dis</code> 모듈로 바이트코드를 확인할 수 있습니다. (<code>import dis; dis.dis(함수명)</code>)</li>
                        <li><strong>GIL의 실제 영향</strong>: GIL은 CPU-bound 작업에서만 병목이 됩니다. I/O-bound 작업(네트워크, 파일)에서는 GIL이 자동 해제되어 멀티스레딩이 효과적입니다. CPU-bound는 <code>multiprocessing</code>이나 C 확장 모듈을 사용하세요.</li>
                        <li><strong>메모리 관리</strong>: CPython은 참조 카운팅(Reference Counting)과 세대별 가비지 컬렉터(Generational GC)를 사용합니다. 순환 참조는 GC가 처리하지만, <code>__del__</code> 메서드가 있으면 수집이 지연될 수 있습니다.</li>
                        <li><strong>성능 한계 극복</strong>: 성능이 중요한 부분은 Cython, ctypes, pybind11로 C/C++ 확장을 만들거나, Numba JIT 컴파일러를 사용하여 수십~수백 배 속도 향상이 가능합니다.</li>
                    </ul>
                </div>
            </div>

            <h3>파이썬 인터프리터 종류</h3>
            <p>파이썬은 언어 사양(specification)과 구현체(implementation)가 분리되어 있습니다. 동일한 파이썬 코드를 다양한 인터프리터에서 실행할 수 있으며, 각 인터프리터는 다른 플랫폼이나 성능 요구사항에 최적화되어 있습니다.</p>
            <div class="feature-grid">
                <div class="feature-card">
                    <h4>CPython</h4>
                    <p>C로 작성된 공식 인터프리터. Reference 구현체로 사실상 표준이며, python.org에서 다운로드하는 것이 바로 CPython입니다. <strong>GIL(Global Interpreter Lock)</strong>을 사용하는데, 이는 한 번에 하나의 스레드만 Python 바이트코드를 실행하도록 제한하는 뮤텍스입니다. 메모리 관리의 안전성을 보장하지만, CPU 집약적 작업에서 멀티스레드 병렬 실행이 제한되는 단점이 있습니다.</p>
                </div>
                <div class="feature-card">
                    <h4>PyPy</h4>
                    <p>JIT(Just-In-Time) 컴파일러를 내장한 고성능 인터프리터. 반복 연산이 많은 코드에서 CPython 대비 수~수십 배 빠른 성능을 제공합니다.</p>
                </div>
                <div class="feature-card">
                    <h4>Jython</h4>
                    <p>JVM(Java Virtual Machine) 위에서 실행되는 인터프리터. Java 라이브러리를 직접 호출할 수 있어 Java 생태계와의 통합에 유용합니다.</p>
                </div>
                <div class="feature-card">
                    <h4>IronPython</h4>
                    <p>.NET CLR(Common Language Runtime) 위에서 실행되며, C#이나 VB.NET 등 .NET 라이브러리와 상호 운용이 가능합니다.</p>
                </div>
                <div class="feature-card">
                    <h4>Brython</h4>
                    <p>JavaScript로 구현된 브라우저용 인터프리터. HTML 페이지 내에서 Python 코드를 직접 실행할 수 있어 웹 프론트엔드 개발에 활용됩니다.</p>
                </div>
            </div>
            
            <h3>Python 2.x vs 3.x 차이점</h3>
            <div class="warning-box">
                <strong>권장:</strong> 이제 Python 3.x 이상을 기준으로 학습하세요. Python 2.x는 2020년에 지원이 종료되었습니다.
            </div>
            <ul>
                <li><strong>print</strong>: 2.x는 <code>print "hello"</code>, 3.x는 <code>print("hello")</code></li>
                <li><strong>나눗셈</strong>: 2.x는 정수나누기 결과가 정수, 3.x는 실수</li>
                <li><strong>유니코드</strong>: 2.x는 <code>u"문자열"</code>, 3.x는 기본이 유니코드</li>
                <li><strong>한글 변수</strong>: 3.x부터 한글 변수명 사용 가능</li>
            </ul>
            
            <h3>Python 3.14 새로운 기능 (2025년 10월 출시)</h3>
            <p>Python 3.14는 성능 개선, 새로운 문법, 디버깅 도구 등 다양한 혁신을 포함합니다. 특히 GIL 제거를 향한 Free-threaded 모드와 Template Strings는 파이썬 생태계에 큰 변화를 가져올 핵심 기능입니다.</p>
            <div class="feature-grid">
                <div class="feature-card">
                    <h4>PEP 750: Template Strings</h4>
                    <p><code>t"..."</code> 접두사로 템플릿 문자열 생성. f-string과 달리 즉시 평가되지 않아 SQL 인젝션 방지 등 보안이 필요한 곳에 활용됩니다.</p>
                </div>
                <div class="feature-card">
                    <h4>PEP 734: Multiple Interpreters</h4>
                    <p>하나의 프로세스 내에서 여러 독립적인 인터프리터를 실행하여 GIL 제약 없이 진정한 병렬 처리를 구현할 수 있습니다.</p>
                </div>
                <div class="feature-card">
                    <h4>PEP 649: Deferred Annotations</h4>
                    <p>타입 어노테이션이 런타임에 필요할 때까지 평가를 지연시켜 순환 참조 문제를 해결하고 모듈 로딩 속도를 개선합니다.</p>
                </div>
                <div class="feature-card">
                    <h4>PEP 768: Debugger Interface</h4>
                    <p>외부 프로세스에서 안전하게 디버거를 연결할 수 있는 표준 인터페이스를 제공하여 프로덕션 환경의 디버깅을 용이하게 합니다.</p>
                </div>
                <div class="feature-card">
                    <h4>PEP 784: Zstandard</h4>
                    <p>Facebook이 개발한 고성능 Zstandard 압축 알고리즘을 표준 라이브러리에 포함하여 별도 설치 없이 빠른 데이터 압축/해제가 가능합니다.</p>
                </div>
                <div class="feature-card">
                    <h4>Free-threaded Mode</h4>
                    <p>GIL(Global Interpreter Lock)을 비활성화하여 멀티코어 CPU를 최대한 활용하는 진정한 멀티스레딩 실행이 가능합니다. 실험적 기능으로 점진적 안정화 중입니다.</p>
                </div>
            </div>
            
            <h3>주요 CLI 옵션</h3>
            <p>파이썬 인터프리터는 명령줄에서 다양한 옵션을 지원합니다. 이 옵션들을 활용하면 디버깅, 최적화, 스크립트 실행 방식을 세밀하게 제어할 수 있습니다.</p>
            <table class="comparison-table">
                <tr><th>옵션</th><th>설명</th></tr>
                <tr><td><code>python</code></td><td>인자 없이 실행: 대화형 인터프리터</td></tr>
                <tr><td><code>-d</code></td><td>디버그 출력</td></tr>
                <tr><td><code>-O</code></td><td>최적화 모드 (assert 제거, __pycache__에 최적화된 .pyc 생성)</td></tr>
                <tr><td><code>-v</code></td><td>자세한 출력 (import 추적)</td></tr>
                <tr><td><code>-c "cmd"</code></td><td>명령어 실행</td></tr>
                <tr><td><code>-S</code></td><td>시작 시 import site 건너뛰기</td></tr>
            </table>
            
            <h3>파이썬 환경변수</h3>
            <p>환경변수를 통해 파이썬 인터프리터의 동작을 전역적으로 설정할 수 있습니다. 모듈 검색 경로, 인코딩 설정 등을 OS 수준에서 지정합니다.</p>
            <table class="comparison-table">
                <tr><th>변수</th><th>설명</th></tr>
                <tr><td><code>PYTHONPATH</code></td><td>모듈 파일 위치</td></tr>
                <tr><td><code>PYTHONSTARTUP</code></td><td>인터프리터 시작 시 실행 파일</td></tr>
                <tr><td><code>PYTHONHOME</code></td><td>모듈 검색 경로</td></tr>
                <tr><td><code>PYTHONCASEOK</code></td><td>대소문자 구분 안 함 (Windows)</td></tr>
            </table>
            
            <h3>예약어 (Keywords)</h3>
            <p>다음 예약어는 변수나 식별자로 사용할 수 없습니다 (Python 3.10+ 기준):</p>
            <div class="code-block">False, None, True, and, as, assert, async, await, break, class,
continue, def, del, elif, else, except, finally, for, from, global,
if, import, in, is, lambda, match, case, nonlocal, not, or, pass,
raise, return, try, while, with, yield</div>
            
            <h3>연산자 우선순위</h3>
            <p>여러 연산자가 하나의 표현식에 함께 사용될 때, 어떤 연산이 먼저 수행되는지를 결정하는 규칙입니다. 숫자가 작을수록 우선순위가 높습니다. 괄호 <code>()</code>를 사용하면 우선순위를 명시적으로 지정할 수 있습니다. 할당 연산자(<code>=, +=</code> 등)는 표현식이 아닌 <strong>문(statement)</strong>이므로 이 표에 포함되지 않습니다.</p>
            <table class="comparison-table">
                <tr><th>우선순위</th><th>연산자</th><th>설명</th></tr>
                <tr><td>1 (최고)</td><td>(expr), [list], {dict}, {set}</td><td>괄호, 리터럴</td></tr>
                <tr><td>2</td><td>x[i], x.attr, x()</td><td>인덱싱, 속성 참조, 호출</td></tr>
                <tr><td>3</td><td>await x</td><td>Await 표현식</td></tr>
                <tr><td>4</td><td>**</td><td>지수 (거듭제곱)</td></tr>
                <tr><td>5</td><td>+x, -x, ~x</td><td>단항 양수, 음수, 비트 NOT</td></tr>
                <tr><td>6</td><td>*, /, //, %, @</td><td>곱셈, 나눗셈, 나머지, 행렬곱</td></tr>
                <tr><td>7</td><td>+, -</td><td>덧셈, 뺄셈</td></tr>
                <tr><td>8</td><td>&lt;&lt;, &gt;&gt;</td><td>비트 시프트</td></tr>
                <tr><td>9</td><td>&amp;</td><td>비트 AND</td></tr>
                <tr><td>10</td><td>^</td><td>비트 XOR</td></tr>
                <tr><td>11</td><td>|</td><td>비트 OR</td></tr>
                <tr><td>12</td><td>==, !=, &lt;, &lt;=, &gt;, &gt;=, is, is not, in, not in</td><td>비교, 식별, 멤버십</td></tr>
                <tr><td>13</td><td>not</td><td>논리 NOT</td></tr>
                <tr><td>14</td><td>and</td><td>논리 AND</td></tr>
                <tr><td>15</td><td>or</td><td>논리 OR</td></tr>
                <tr><td>16</td><td>if – else</td><td>조건 표현식</td></tr>
                <tr><td>17</td><td>lambda</td><td>람다 표현식</td></tr>
                <tr><td>18 (최저)</td><td>:=</td><td>Walrus 연산자</td></tr>
            </table>
        </section>
        
        <section id="basics">
            <h2>2. 기초 문법</h2>
            <span class="level-badge level-beginner">초급</span>

            <p>
                파이썬의 기초 문법은 다른 언어에 비해 <strong>직관적이고 자연어에 가깝게</strong> 설계되어 있습니다.
                중괄호(<code>{}</code>) 대신 <strong>들여쓰기</strong>로 코드 블록을 구분하고, 세미콜론(<code>;</code>) 없이도 한 줄이 하나의 문장이 됩니다.
                이런 설계 덕분에 파이썬 코드는 마치 영어 문장을 읽는 것처럼 읽히며, 초보자도 빠르게 프로그래밍의 핵심 개념을 익힐 수 있습니다.
            </p>

            <div class="level-guide beginner">
                <div class="level-guide-header">초급자 가이드 - 기초 문법의 핵심</div>
                <div class="level-guide-content">
                    <p>파이썬 기초 문법에서 가장 중요한 3가지를 기억하세요:</p>
                    <ul>
                        <li><strong>들여쓰기가 곧 문법</strong>: C, Java에서는 중괄호 <code>{}</code>로 코드 블록을 구분하지만, 파이썬은 들여쓰기(보통 스페이스 4칸)로 구분합니다. 탭과 스페이스를 섞으면 에러가 납니다!</li>
                        <li><strong>변수 선언이 필요 없다</strong>: <code>int x = 5;</code>처럼 타입을 명시하지 않고, 그냥 <code>x = 5</code>로 작성하면 됩니다. 파이썬이 자동으로 타입을 결정합니다.</li>
                        <li><strong>세미콜론이 필요 없다</strong>: 한 줄이 하나의 문장입니다. 줄바꿈 자체가 구분자 역할을 합니다.</li>
                    </ul>
                    <p><strong>흔한 실수:</strong> <code>if</code>문 뒤에 콜론(<code>:</code>)을 빼먹는 것입니다. <code>if x > 0:</code>처럼 반드시 콜론을 붙여야 합니다.</p>
                </div>
            </div>

            <div class="level-guide intermediate">
                <div class="level-guide-header">중급자 가이드 - PEP 8 코딩 스타일</div>
                <div class="level-guide-content">
                    <p>실무에서는 PEP 8 스타일 가이드를 준수하는 것이 중요합니다. 팀 협업 시 코드 일관성을 유지하는 핵심 규칙:</p>
                    <ul>
                        <li><strong>네이밍 규칙</strong>: 변수/함수는 <code>snake_case</code>, 클래스는 <code>PascalCase</code>, 상수는 <code>UPPER_SNAKE_CASE</code></li>
                        <li><strong>한 줄 길이</strong>: 최대 79자(PEP 8 권장). 현대적 프로젝트에서는 100~120자까지 허용하기도 합니다.</li>
                        <li><strong>import 순서</strong>: 표준 라이브러리 → 서드파티 → 로컬 모듈 순서로 작성하고, 그룹 사이에 빈 줄을 넣습니다.</li>
                        <li><strong>자동 도구</strong>: <code>black</code>(코드 포매터), <code>isort</code>(import 정렬), <code>flake8</code>(린터), <code>ruff</code>(올인원 린터)를 사용하면 스타일을 자동으로 맞출 수 있습니다.</li>
                    </ul>
                </div>
            </div>

            <div class="level-guide advanced">
                <div class="level-guide-header">고급자 가이드 - 파이썬 실행 모델의 이해</div>
                <div class="level-guide-content">
                    <p>파이썬의 실행 과정을 깊이 이해하면 디버깅과 최적화에 도움이 됩니다:</p>
                    <ul>
                        <li><strong>모든 것이 객체</strong>: 정수 <code>42</code>도, 함수 <code>print</code>도, 모듈 <code>os</code>도 모두 객체입니다. <code>id()</code>로 메모리 주소를, <code>type()</code>으로 타입 객체를 확인할 수 있습니다.</li>
                        <li><strong>변수는 이름표(label)</strong>: 파이썬 변수는 C의 변수와 다릅니다. 값을 담는 "상자"가 아니라 객체를 가리키는 "이름표"입니다. <code>a = [1,2,3]; b = a</code>에서 <code>a</code>와 <code>b</code>는 같은 리스트 객체를 가리키며, <code>id(a) == id(b)</code>입니다.</li>
                        <li><strong>정수 캐싱(Integer Interning)</strong>: CPython은 -5~256 범위의 정수를 미리 캐싱합니다. 이 범위의 정수는 <code>is</code> 비교가 True이지만, 그 밖의 정수는 False일 수 있습니다. 값 비교에는 항상 <code>==</code>를 사용하세요.</li>
                        <li><strong>문자열 인터닝(String Interning)</strong>: 식별자처럼 보이는 문자열(영문/숫자/밑줄로만 구성)은 자동으로 인터닝되어 동일 객체를 재사용합니다.</li>
                    </ul>
                </div>
            </div>

            <h3>Hello, World! 출력하기</h3>
            <p>프로그래밍의 첫걸음은 언제나 "Hello, World!"를 출력하는 것입니다.</p>
            
            <div class="code-block">
<span class="keyword">print</span>(<span class="string">"Hello, World!"</span>)
<span class="comment"># 결과: Hello, World!</span>
            </div>
            
            <div class="tip-box">
                <strong>💡 팁:</strong> 파이썬에서 print()는 함수의 일종입니다. 괄호 안에 넣은 내용을 화면에 출력해줍니다.
            </div>
            
            <h3>변수와 주석</h3>
            <p>변수는 데이터를 저장하는 공간입니다. 주석은 코드에 설명을 추가하는 데 사용됩니다.</p>
            
            <div class="code-block">
<span class="comment"># 변수 선언의 예</span>
name = <span class="string">"민준"</span>
age = <span class="number">25</span>
height = <span class="number">175.5</span>

<span class="keyword">print</span>(name)  <span class="comment"># 민준</span>
<span class="keyword">print</span>(age)   <span class="comment"># 25</span>
            </div>
            
            <h3>주석 (Comments)과 독스트링 (Docstrings)</h3>
            <p><code>#</code>으로 시작하는 <strong>주석(comment)</strong>은 인터프리터가 완전히 무시하는 메모입니다. 반면, 삼중 따옴표(<code>"""</code> 또는 <code>'''</code>)로 작성하는 <strong>독스트링(docstring)</strong>은 실제로는 <strong>문자열 리터럴</strong>이며, 함수·클래스·모듈의 첫 줄에 오면 <code>__doc__</code> 속성에 저장되어 <code>help()</code>로 조회할 수 있습니다. 독스트링은 주석처럼 보이지만 런타임에 존재하는 문자열이라는 점이 핵심 차이입니다.</p>
            <div class="code-block">
<span class="comment"># 한 줄 주석입니다 (인터프리터가 무시)</span>

<span class="keyword">def</span> <span class="function">greet</span>(name):
    <span class="string">"""인사말을 반환합니다.

    이것은 독스트링(docstring)으로, 함수의 __doc__ 속성에 저장됩니다.
    help(greet)로 확인할 수 있습니다.
    """</span>
    <span class="keyword">return</span> <span class="string">f"안녕, {name}!"</span>

<span class="keyword">print</span>(greet.<span class="function">__doc__</span>)  <span class="comment"># 독스트링 출력</span>
            </div>
            
            <h3>여러 줄로 구문 작성</h3>
            <p>긴 코드를 여러 줄에 걸쳐 작성할 수 있습니다. 백슬래시(<code>\</code>)를 사용하거나 괄호(<code>[]</code>, <code>{}</code>, <code>()</code>) 안에서는 자동으로 줄이 연결됩니다. 세미콜론(<code>;</code>)으로 한 줄에 여러 구문을 작성할 수도 있지만, PEP 8에서는 권장하지 않습니다.</p>
            <div class="code-block">
<span class="comment"># \(백슬래시)로 줄 연결</span>
a = <span class="number">1</span> + \
    <span class="number">2</span> + \
    <span class="number">3</span>

<span class="comment"># [], {}, ()는 자동으로 연결</span>
numbers = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>,
          <span class="number">4</span>, <span class="number">5</span>]

<span class="comment"># 한 줄에 여러 구문 (세미콜론)</span>
x = <span class="number">1</span>; y = <span class="number">2</span>; <span class="keyword">print</span>(x + y)
            </div>
            
            <h3>식별자 (Identifiers)</h3>
            <p>식별자는 변수, 함수, 클래스 등에 붙이는 이름입니다. 파이썬의 명명 규칙은 PEP 8을 따르며, 언더스코어의 개수에 따라 특별한 의미를 가집니다.</p>
            <ul>
                <li>영문자, 숫자, _(밑줄) 사용 가능 (숫자로 시작 불가)</li>
                <li>대소문자 엄격히 구분</li>
                <li>Python 3.x부터 한글 변수명 사용 가능</li>
                <li><code>_var</code> : 관례적으로 내부 사용(private)을 의미하며, <code>from module import *</code>에서 제외됩니다.</li>
                <li><code>__var</code> : 이름 맹글링(name mangling) 적용. 클래스 내에서 <code>_ClassName__var</code>로 변환되어 하위 클래스와의 이름 충돌을 방지합니다.</li>
                <li><code>__var__</code> : <strong>던더(dunder, double underscore)</strong> 또는 <strong>매직 메서드/속성</strong>이라 불립니다. <code>__init__</code>, <code>__str__</code>, <code>__len__</code> 등 Python이 특별한 용도로 예약한 이름입니다. 직접 새로 정의하지 않는 것이 좋습니다.</li>
                <li><code>var_</code> : Python 예약어와의 충돌을 피하기 위한 관례 (예: <code>class_</code>, <code>type_</code>)</li>
            </ul>
            
            <h3>들여쓰기 (Indentation)</h3>
            <div class="warning-box">
                <strong>중요:</strong> 파이썬은 들여쓰기로 블록을 구분합니다. 콜론(:) 뒤에 들여쓰기를 하세요.
            </div>
            <div class="code-block">
<span class="keyword">if</span> x > <span class="number">0</span>:
    <span class="keyword">print</span>(<span class="string">"양수"</span>)  <span class="comment"># 4칸 들여쓰기</span>
    <span class="keyword">if</span> x > <span class="number">10</span>:
        <span class="keyword">print</span>(<span class="string">"큰 양수"</span>)  <span class="comment"># 8칸 들여쓰기</span>
            </div>
            
            <h3>첫 줄 Shebang과 인코딩</h3>
            <p>Unix/Linux 환경에서 스크립트를 직접 실행하려면 첫 줄에 <strong>Shebang(#!)</strong>을 추가합니다. 인코딩 선언(<code># -*- coding: utf-8 -*-</code>)은 Python 3에서는 기본이 UTF-8이므로 생략 가능하지만, Python 2 호환이나 명시적 선언이 필요할 때 사용합니다.</p>
            <div class="code-block">
<span class="comment">#!/usr/bin/env python</span>
<span class="comment"># -*- coding: utf-8 -*-</span>

<span class="keyword">print</span>(<span class="string">"안녕하세요"</span>)
            </div>
            
            <div class="svg-container">
                <!-- Variable Concept SVG -->
                <svg width="600" height="180" viewBox="0 0 600 180" xmlns="http://www.w3.org/2000/svg">
                    <rect x="50" y="50" width="150" height="80" rx="10" fill="var(--svg-blue)" stroke="#2196F3" stroke-width="2"/>
                    <text x="125" y="95" text-anchor="middle" font-weight="bold" fill="var(--text-primary)">name</text>

                    <line x1="200" y1="90" x2="270" y2="90" stroke="#667eea" stroke-width="2"/>
                    <polygon points="270,70 300,90 270,110" fill="#667eea"/>

                    <rect x="300" y="50" width="150" height="80" rx="10" fill="var(--svg-orange)" stroke="#ff9800" stroke-width="2"/>
                    <text x="375" y="95" text-anchor="middle" font-weight="bold" fill="var(--text-primary)">"민준"</text>

                    <text x="375" y="150" text-anchor="middle" fill="var(--text-secondary)" font-size="14">메모리 공간 (객체)</text>

                    <!-- 범례 -->
                    <text x="125" y="30" text-anchor="middle" fill="var(--text-secondary)" font-size="12">변수 (이름표)</text>
                    <text x="375" y="30" text-anchor="middle" fill="var(--text-secondary)" font-size="12">값 (객체)</text>
                    <text x="240" y="75" text-anchor="middle" fill="#667eea" font-size="12">참조</text>
                </svg>
            </div>
            <h3>Walrus 연산자 (:=)</h3>
            <p>Python 3.8부터 도입된 <strong>Walrus 연산자(:=)</strong>는 표현식 내에서 변수에 값을 할당하면서 동시에 그 값을 반환합니다. <code>:=</code> 기호가 바다코끼리(walrus)의 눈과 엄니를 닮았다고 하여 이 이름이 붙었습니다. 조건문이나 반복문에서 중복 호출을 줄이는 데 유용합니다.</p>
            
            <div class="code-block">
<span class="comment"># 기존 방식</span>
result = <span class="function">some_function</span>()
<span class="keyword">if</span> result:
    <span class="keyword">print</span>(result)

<span class="comment"># Walrus 연산자 사용</span>
<span class="keyword">if</span> (result := <span class="function">some_function</span>()):
    <span class="keyword">print</span>(result)

<span class="comment"># 리스트 comprehension에서의 사용</span>
<span class="keyword">if</span> (n := <span class="builtin">int</span>(<span class="string">"42"</span>)) > <span class="number">40</span>:
    <span class="keyword">print</span>(<span class="string">f"숫자는 {n}입니다"</span>)
            </div>
            
        </section>
        
        <section id="datatypes">
            <h2>3. 자료형 (Data Types)</h2>
            <span class="level-badge level-beginner">초급</span>
            
            <p>
                파이썬은 <strong>동적 타이핑(Dynamic Typing)</strong> 언어로, 변수를 선언할 때 자료형을 명시하지 않아도 됩니다.
                인터프리터가 대입된 값에 따라 자동으로 자료형을 결정합니다. 파이썬의 모든 데이터는 객체(object)이며, <code>type()</code> 함수로 자료형을 확인할 수 있습니다.
                기본 자료형은 크게 <strong>숫자형</strong>(int, float, complex), <strong>시퀀스형</strong>(str, list, tuple), <strong>매핑형</strong>(dict), <strong>집합형</strong>(set, frozenset), <strong>불리언형</strong>(bool), <strong>None</strong>으로 분류됩니다.
            </p>

            <div class="svg-container">
                <!-- 파이썬 자료형 분류 다이어그램 -->
                <svg width="700" height="220" viewBox="0 0 700 220" xmlns="http://www.w3.org/2000/svg">
                    <!-- 중앙 제목 -->
                    <rect x="260" y="10" width="180" height="35" rx="8" fill="#667eea" stroke="#4a5ae0" stroke-width="2"/>
                    <text x="350" y="33" text-anchor="middle" fill="white" font-weight="bold" font-size="13">Python 자료형</text>

                    <!-- 분기선 -->
                    <line x1="350" y1="45" x2="350" y2="60" stroke="var(--text-secondary)" stroke-width="1.5"/>
                    <line x1="70" y1="60" x2="630" y2="60" stroke="var(--text-secondary)" stroke-width="1.5"/>

                    <!-- 숫자형 -->
                    <line x1="70" y1="60" x2="70" y2="80" stroke="var(--text-secondary)" stroke-width="1.5"/>
                    <rect x="15" y="80" width="110" height="35" rx="7" fill="var(--svg-blue)" stroke="#2196F3" stroke-width="1.5"/>
                    <text x="70" y="103" text-anchor="middle" fill="var(--svg-blue-text)" font-weight="bold" font-size="11">숫자형</text>
                    <text x="70" y="135" text-anchor="middle" fill="var(--text-secondary)" font-size="10">int, float</text>
                    <text x="70" y="150" text-anchor="middle" fill="var(--text-secondary)" font-size="10">complex, bool</text>

                    <!-- 시퀀스형 -->
                    <line x1="210" y1="60" x2="210" y2="80" stroke="var(--text-secondary)" stroke-width="1.5"/>
                    <rect x="155" y="80" width="110" height="35" rx="7" fill="var(--svg-green)" stroke="#4CAF50" stroke-width="1.5"/>
                    <text x="210" y="103" text-anchor="middle" fill="var(--svg-green-text)" font-weight="bold" font-size="11">시퀀스형</text>
                    <text x="210" y="135" text-anchor="middle" fill="var(--text-secondary)" font-size="10">str, list</text>
                    <text x="210" y="150" text-anchor="middle" fill="var(--text-secondary)" font-size="10">tuple, range</text>

                    <!-- 매핑형 -->
                    <line x1="350" y1="60" x2="350" y2="80" stroke="var(--text-secondary)" stroke-width="1.5"/>
                    <rect x="295" y="80" width="110" height="35" rx="7" fill="var(--svg-orange)" stroke="#ff9800" stroke-width="1.5"/>
                    <text x="350" y="103" text-anchor="middle" fill="var(--svg-orange-text)" font-weight="bold" font-size="11">매핑형</text>
                    <text x="350" y="140" text-anchor="middle" fill="var(--text-secondary)" font-size="10">dict</text>

                    <!-- 집합형 -->
                    <line x1="490" y1="60" x2="490" y2="80" stroke="var(--text-secondary)" stroke-width="1.5"/>
                    <rect x="435" y="80" width="110" height="35" rx="7" fill="var(--svg-pink)" stroke="#e91e63" stroke-width="1.5"/>
                    <text x="490" y="103" text-anchor="middle" fill="var(--svg-pink-text)" font-weight="bold" font-size="11">집합형</text>
                    <text x="490" y="135" text-anchor="middle" fill="var(--text-secondary)" font-size="10">set</text>
                    <text x="490" y="150" text-anchor="middle" fill="var(--text-secondary)" font-size="10">frozenset</text>

                    <!-- 기타 -->
                    <line x1="630" y1="60" x2="630" y2="80" stroke="var(--text-secondary)" stroke-width="1.5"/>
                    <rect x="575" y="80" width="110" height="35" rx="7" fill="var(--svg-gray)" stroke="var(--border)" stroke-width="1.5"/>
                    <text x="630" y="103" text-anchor="middle" fill="var(--text-secondary)" font-weight="bold" font-size="11">기타</text>
                    <text x="630" y="135" text-anchor="middle" fill="var(--text-secondary)" font-size="10">None, bytes</text>
                    <text x="630" y="150" text-anchor="middle" fill="var(--text-secondary)" font-size="10">bytearray</text>

                    <!-- 불변/가변 범례 -->
                    <rect x="80" y="175" width="260" height="25" rx="5" fill="none" stroke="#4CAF50" stroke-width="1.5" stroke-dasharray="4,2"/>
                    <text x="210" y="192" text-anchor="middle" fill="var(--svg-green-text)" font-size="10" font-weight="bold">불변(Immutable): int, str, tuple, frozenset</text>

                    <rect x="370" y="175" width="240" height="25" rx="5" fill="none" stroke="#ff9800" stroke-width="1.5" stroke-dasharray="4,2"/>
                    <text x="490" y="192" text-anchor="middle" fill="var(--svg-orange-text)" font-size="10" font-weight="bold">가변(Mutable): list, dict, set, bytearray</text>
                </svg>
            </div>

            <h3>숫자 (Numbers)</h3>
            <p>파이썬은 정수(int), 실수(float), 복소수(complex) 세 가지 숫자 자료형을 지원합니다. 정수는 크기 제한이 없어 아무리 큰 수도 표현할 수 있으며(메모리가 허용하는 한), 2진수(<code>0b</code>), 8진수(<code>0o</code>), 16진수(<code>0x</code>) 리터럴도 사용 가능합니다.</p>
            <div class="code-block">
<span class="comment"># 정수 (Integer)</span>
integer = <span class="number">42</span>

<span class="comment"># 실수 (Float)</span>
float_num = <span class="number">3.14</span>
scientific = <span class="number">3.4e10</span>  <span class="comment"># 지수 표기</span>

<span class="comment"># 복소수 (Complex)</span>
complex_num = <span class="number">3 + 4j</span>
<span class="keyword">print</span>(complex_num.real)  <span class="comment"># 3.0 (실수부)</span>
<span class="keyword">print</span>(complex_num.imag)  <span class="comment"># 4.0 (허수부)</span>
<span class="keyword">print</span>(complex_num.conjugate())  <span class="comment"># (3-4j) (켤레복소수)</span>

<span class="comment"># 8진수 (0o으로 시작)</span>
octal = <span class="number">0o34</span>

<span class="comment"># 16진수 (0x로 시작)</span>
hex_num = <span class="number">0xFF</span>
            </div>
            
            <h3>문자열 (String)</h3>
            <p>문자열은 작은따옴표(<code>'...'</code>) 또는 큰따옴표(<code>"..."</code>)로 생성하며, 삼중 따옴표(<code>"""..."""</code>)로 여러 줄 문자열을 만들 수 있습니다. 파이썬 3에서 문자열은 기본적으로 유니코드(Unicode)이므로 한글 등 다국어 처리가 자연스럽습니다. <strong>f-string</strong>(Python 3.6+)을 사용하면 변수를 문자열에 직접 삽입할 수 있습니다.</p>
            <div class="code-block">
single = <span class="string">'작은따옴표'</span>
double = <span class="string">"큰따옴표"</span>
multi_line = <span class="string">"""여러 줄
문자열"""</span>

<span class="comment"># 문자열 포맷팅</span>
name = <span class="string">"철수"</span>
<span class="keyword">print</span>(<span class="string">f"안녕하세요, {name}님!"</span>)  <span class="comment"># 안녕하세요, 철수님!</span>
            </div>
            
            <h3>문자열 주요 메서드</h3>
            <p>파이썬 문자열은 <strong>불변(immutable)</strong> 객체이므로 모든 메서드는 원본을 수정하지 않고 새로운 문자열을 반환합니다. 다음은 가장 자주 사용되는 문자열 메서드들입니다.</p>
            <table class="comparison-table">
                <tr><th>메서드</th><th>설명</th></tr>
                <tr><td>.upper()</td><td>대문자 변환</td></tr>
                <tr><td>.lower()</td><td>소문자 변환</td></tr>
                <tr><td>.strip()</td><td>좌우 공백 제거</td></tr>
                <tr><td>.split()</td><td>분할 (리스트 반환)</td></tr>
                <tr><td>.join()</td><td>합치기</td></tr>
                <tr><td>.replace()</td><td>치환</td></tr>
                <tr><td>.find()</td><td>위치 찾기 (-1 if not found)</td></tr>
                <tr><td>.index()</td><td>위치 찾기 (오류 if not found)</td></tr>
                <tr><td>.count()</td><td>개수 세기</td></tr>
                <tr><td>.startswith()</td><td>시작 문자열 확인</td></tr>
                <tr><td>.endswith()</td><td>끝 문자열 확인</td></tr>
                <tr><td>.isalpha()</td><td>영문자 여부</td></tr>
                <tr><td>.isdigit()</td><td>숫자 여부</td></tr>
                <tr><td>.splitlines()</td><td>줄바꿈으로 분할</td></tr>
                <tr><td>.zfill()</td><td>0으로 패딩</td></tr>
            </table>
            
            <h3>문자열 슬라이싱</h3>
            <p>슬라이싱은 <code>[시작:끝:간격]</code> 문법으로 문자열의 일부를 추출합니다. 인덱스는 0부터 시작하며, 음수 인덱스는 끝에서부터 역순으로 셉니다. 끝 인덱스는 해당 위치를 <strong>포함하지 않습니다</strong>.</p>
            <div class="code-block">
s = <span class="string">"Hello Python"</span>
s[<span class="number">0</span>]     <span class="comment"># 'H' (인덱싱)</span>
s[<span class="number">0</span>:<span class="number">5</span>]   <span class="comment"># 'Hello' (슬라이싱, 끝 제외)</span>
s[<span class="number">6</span>:]     <span class="comment"># 'Python' (6부터 끝까지)</span>
s[:<span class="number">5</span>]     <span class="comment"># 'Hello' (처음부터 5까지)</span>
s[-<span class="number">1</span>]     <span class="comment"># 'n' (마지막 문자)</span>
s[<span class="number">0</span>:<span class="number">10</span>:<span class="number">2</span>] <span class="comment"># 'HloPto' (step 2)</span>
s[::<span class="number">-</span><span class="number">1</span>]  <span class="comment"># 'nohtyP olleH' (역순)</span>
            </div>
            
            <h3>Escape 문자</h3>
            <p>이스케이프 문자는 백슬래시(<code>\</code>)와 함께 사용되어 줄바꿈, 탭 등 특수 문자를 표현합니다. 이스케이프 시퀀스를 무시하려면 문자열 앞에 <code>r</code>(raw string)을 붙입니다. 예: <code>r"C:\new"</code></p>
            <table class="comparison-table">
                <tr><th>코드</th><th>설명</th></tr>
                <tr><td>\n</td><td>줄바꿈</td></tr>
                <tr><td>\t</td><td>탭</td></tr>
                <tr><td>\\</td><td>백슬래시</td></tr>
                <tr><td>\'</td><td>작은따옴표</td></tr>
                <tr><td>\"</td><td>큰따옴표</td></tr>
                <tr><td>\r</td><td>캐리지 리턴</td></tr>
                <tr><td>\b</td><td>백스페이스</td></tr>
            </table>
            
            <h3>리스트와 튜플</h3>
            <p><strong>리스트(list)</strong>는 순서가 있고 수정 가능한(mutable) 시퀀스로 <code>[]</code>로 생성합니다. <strong>튜플(tuple)</strong>은 순서가 있지만 수정 불가능한(immutable) 시퀀스로 <code>()</code>로 생성합니다. 튜플은 변경되면 안 되는 데이터(좌표, DB 레코드 등)에 사용하며, 딕셔너리의 키로도 활용할 수 있습니다.</p>
            <div class="code-block">
<span class="comment"># 리스트 (수정 가능) - []</span>
fruits = [<span class="string">"사과"</span>, <span class="string">"바나나"</span>, <span class="string">"딸기"</span>]
fruits[<span class="number">0</span>] = <span class="string">"포도"</span>  <span class="comment"># 가능</span>

<span class="comment"># 튜플 (수정 불가능) - ()</span>
coordinates = (<span class="number">10</span>, <span class="number">20</span>, <span class="number">30</span>)
<span class="comment"># coordinates[0] = 5  # 오류 발생!</span>
            </div>
            
            <h3>리스트 주요 메서드</h3>
            <p>리스트는 가변(mutable) 객체이므로 메서드를 통해 원본을 직접 수정할 수 있습니다. <code>append()</code>, <code>insert()</code> 등은 리스트 자체를 변경하고 <code>None</code>을 반환한다는 점에 주의하세요.</p>
            <table class="comparison-table">
                <tr><th>메서드</th><th>설명</th><th>예시</th></tr>
                <tr><td>.append(x)</td><td>끝에 추가</td><td>[1,2].append(3) → [1,2,3]</td></tr>
                <tr><td>.extend(iterable)</td><td>iterable 추가</td><td>[1].extend([2,3]) → [1,2,3]</td></tr>
                <tr><td>.insert(i, x)</td><td>위치에 삽입</td><td>[1,3].insert(1,2) → [1,2,3]</td></tr>
                <tr><td>.remove(x)</td><td>첫 번째 x 제거</td><td>[1,2,3].remove(2) → [1,3]</td></tr>
                <tr><td>.pop([i])</td><td>위치 값 제거/반환</td><td>[1,2,3].pop() → 3</td></tr>
                <tr><td>.clear()</td><td>모두 제거</td><td>[1,2].clear() → []</td></tr>
                <tr><td>.index(x)</td><td>첫 번째 x 인덱스</td><td>[1,2,3].index(2) → 1</td></tr>
                <tr><td>.count(x)</td><td>x 개수</td><td>[1,2,2].count(2) → 2</td></tr>
                <tr><td>.sort(*, key, reverse)</td><td>정렬</td><td>[3,1,2].sort() → [1,2,3]</td></tr>
                <tr><td>.reverse()</td><td>역순</td><td>[1,2,3].reverse() → [3,2,1]</td></tr>
                <tr><td>.copy()</td><td> shallow 복사</td><td>[1,2].copy() → [1,2]</td></tr>
            </table>
            
            <h3>List Comprehension (리스트 내포)</h3>
            <p>리스트 컴프리헨션은 한 줄로 리스트를 생성하는 파이썬의 강력한 문법입니다. <code>[표현식 for 변수 in 반복가능객체 if 조건]</code> 형식으로 작성하며, for 루프보다 간결하고 일반적으로 더 빠릅니다. 중첩 컴프리헨션으로 다차원 리스트도 생성할 수 있습니다.</p>
            <div class="code-block">
<span class="comment"># 기본</span>
squares = [x**<span class="number">2</span> <span class="keyword">for</span> x <span class="keyword">in</span> <span class="builtin">range</span>(<span class="number">5</span>)]
<span class="comment"># [0, 1, 4, 9, 16]</span>

<span class="comment"># 조건 포함</span>
evens = [x <span class="keyword">for</span> x <span class="keyword">in</span> <span class="builtin">range</span>(<span class="number">10</span>) <span class="keyword">if</span> x % <span class="number">2</span> == <span class="number">0</span>]
<span class="comment"># [0, 2, 4, 6, 8]</span>

<span class="comment"># 중첩</span>
matrix = [[j <span class="keyword">for</span> j <span class="keyword">in</span> <span class="builtin">range</span>(<span class="number">3</span>)] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="builtin">range</span>(<span class="number">3</span>)]
            </div>
            
            <h3>딕셔너리 (Dictionary)</h3>
            <p>딕셔너리는 <strong>키-값(key-value) 쌍</strong>으로 데이터를 저장하는 자료형입니다. <code>{}</code>로 생성하며, 키를 통해 O(1) 시간복잡도로 값에 접근할 수 있습니다. Python 3.7부터 삽입 순서가 보장되며, 키는 불변(hashable) 객체만 사용 가능합니다.</p>
            <div class="code-block">
<span class="comment"># 딕셔너리 생성 (키-값 쌍)</span>
person = {<span class="string">"이름"</span>: <span class="string">"민준"</span>, <span class="string">"나이"</span>: <span class="number">25</span>, <span class="string">"도시"</span>: <span class="string">"서울"</span>}

<span class="comment"># 값 접근</span>
<span class="keyword">print</span>(person[<span class="string">"이름"</span>])          <span class="comment"># 민준</span>
<span class="keyword">print</span>(person.get(<span class="string">"나이"</span>))      <span class="comment"># 25 (키 없을 때 None 반환)</span>
<span class="keyword">print</span>(person.get(<span class="string">"직업"</span>, <span class="string">"미정"</span>))  <span class="comment"># 미정 (기본값 지정)</span>

<span class="comment"># 추가 / 수정</span>
person[<span class="string">"직업"</span>] = <span class="string">"개발자"</span>
person.update({<span class="string">"나이"</span>: <span class="number">26</span>, <span class="string">"취미"</span>: <span class="string">"독서"</span>})

<span class="comment"># 삭제</span>
<span class="keyword">del</span> person[<span class="string">"취미"</span>]
person.pop(<span class="string">"직업"</span>, <span class="keyword">None</span>)   <span class="comment"># 키 없어도 오류 없음</span>

<span class="comment"># 순회</span>
<span class="keyword">for</span> key <span class="keyword">in</span> person.keys():
    <span class="keyword">print</span>(key)
<span class="keyword">for</span> value <span class="keyword">in</span> person.values():
    <span class="keyword">print</span>(value)
<span class="keyword">for</span> key, value <span class="keyword">in</span> person.items():
    <span class="keyword">print</span>(<span class="string">f"{key}: {value}"</span>)

<span class="comment"># 딕셔너리 컴프리헨션</span>
squares = {x: x**<span class="number">2</span> <span class="keyword">for</span> x <span class="keyword">in</span> <span class="builtin">range</span>(<span class="number">5</span>)}
<span class="comment"># {0: 0, 1: 1, 2: 4, 3: 9, 4: 16}</span>

<span class="comment"># 딕셔너리 병합 (Python 3.9+)</span>
d1 = {<span class="string">"a"</span>: <span class="number">1</span>}
d2 = {<span class="string">"b"</span>: <span class="number">2</span>}
merged = d1 | d2    <span class="comment"># {"a": 1, "b": 2}</span>
            </div>

            <h3>집합 컴프리헨션 (Set Comprehension)</h3>
            <p>리스트 컴프리헨션과 동일한 문법이지만 <code>{}</code>를 사용하여 중복 없는 집합을 생성합니다. 소괄호 <code>()</code>를 사용하면 <strong>제너레이터 표현식</strong>이 되어 한 번에 모든 값을 메모리에 저장하지 않고 필요할 때 하나씩 생성하므로 메모리 효율적입니다.</p>
            <div class="code-block">
<span class="comment"># 집합 컴프리헨션</span>
unique_squares = {x**<span class="number">2</span> <span class="keyword">for</span> x <span class="keyword">in</span> [-<span class="number">2</span>, -<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]}
<span class="comment"># {0, 1, 4}</span>

<span class="comment"># 제너레이터 표현식 (메모리 효율)</span>
gen = (x**<span class="number">2</span> <span class="keyword">for</span> x <span class="keyword">in</span> <span class="builtin">range</span>(<span class="number">10</span>))
<span class="comment"># next(gen)으로 하나씩 꺼냄</span>
            </div>

            <div class="svg-container">
                <!-- Data Types Comparison SVG -->
                <svg width="700" height="250" viewBox="0 0 700 250" xmlns="http://www.w3.org/2000/svg">
                    <!-- List Box -->
                    <rect x="30" y="30" width="180" height="180" rx="15" fill="var(--svg-green)" stroke="#4CAF50" stroke-width="3"/>
                    <text x="120" y="60" text-anchor="middle" font-weight="bold" fill="var(--svg-green-text)" font-size="16">List (리스트)</text>
                    <text x="120" y="85" text-anchor="middle" fill="var(--text-secondary)" font-size="12">[]</text>
                    <rect x="50" y="100" width="140" height="30" rx="5" fill="var(--svg-inner)" stroke="#4CAF50"/>
                    <text x="120" y="120" text-anchor="middle" fill="var(--text-primary)">"사과"</text>
                    <rect x="50" y="135" width="140" height="30" rx="5" fill="var(--svg-inner)" stroke="#4CAF50"/>
                    <text x="120" y="155" text-anchor="middle" fill="var(--text-primary)">"바나나"</text>
                    <rect x="50" y="170" width="140" height="30" rx="5" fill="var(--svg-inner)" stroke="#4CAF50"/>
                    <text x="120" y="190" text-anchor="middle" fill="var(--text-primary)">"딸기"</text>
                    <text x="120" y="225" text-anchor="middle" fill="#4CAF50" font-size="12">✏️ 수정 가능</text>

                    <!-- Tuple Box -->
                    <rect x="260" y="30" width="180" height="180" rx="15" fill="var(--svg-orange)" stroke="#ff9800" stroke-width="3"/>
                    <text x="350" y="60" text-anchor="middle" font-weight="bold" fill="var(--svg-orange-text)" font-size="16">Tuple (튜플)</text>
                    <text x="350" y="85" text-anchor="middle" fill="var(--text-secondary)" font-size="12">()</text>
                    <rect x="280" y="100" width="140" height="30" rx="5" fill="var(--svg-inner)" stroke="#ff9800"/>
                    <text x="350" y="120" text-anchor="middle" fill="var(--text-primary)">"사과"</text>
                    <rect x="280" y="135" width="140" height="30" rx="5" fill="var(--svg-inner)" stroke="#ff9800"/>
                    <text x="350" y="155" text-anchor="middle" fill="var(--text-primary)">"바나나"</text>
                    <rect x="280" y="170" width="140" height="30" rx="5" fill="var(--svg-inner)" stroke="#ff9800"/>
                    <text x="350" y="190" text-anchor="middle" fill="var(--text-primary)">"딸기"</text>
                    <text x="350" y="225" text-anchor="middle" fill="#ff9800" font-size="12">🔒 수정 불가</text>

                    <!-- Dict Box -->
                    <rect x="490" y="30" width="180" height="180" rx="15" fill="var(--svg-blue)" stroke="#2196F3" stroke-width="3"/>
                    <text x="580" y="60" text-anchor="middle" font-weight="bold" fill="var(--svg-blue-text)" font-size="16">Dict (사전)</text>
                    <text x="580" y="85" text-anchor="middle" fill="var(--text-secondary)" font-size="12">{"key": "value"}</text>
                    <rect x="510" y="100" width="140" height="25" rx="5" fill="var(--svg-inner)" stroke="#2196F3"/>
                    <text x="580" y="118" text-anchor="middle" fill="var(--text-primary)" font-size="13">"이름": "민준"</text>
                    <rect x="510" y="130" width="140" height="25" rx="5" fill="var(--svg-inner)" stroke="#2196F3"/>
                    <text x="580" y="148" text-anchor="middle" fill="var(--text-primary)" font-size="13">"나이": 25</text>
                    <rect x="510" y="160" width="140" height="25" rx="5" fill="var(--svg-inner)" stroke="#2196F3"/>
                    <text x="580" y="178" text-anchor="middle" fill="var(--text-primary)" font-size="13">"도시": "서울"</text>
                    <text x="580" y="215" text-anchor="middle" fill="#2196F3" font-size="12">🔑 키-값 쌍</text>
                </svg>
            </div>
            
            <h3>집합 (Set)</h3>
            <p>집합(set)은 <strong>중복을 허용하지 않고 순서가 없는</strong> 자료형입니다. 수학의 집합 연산(합집합, 교집합, 차집합, 대칭차집합)을 지원하며, 멤버십 테스트(<code>in</code>)가 리스트보다 훨씬 빠릅니다(O(1)). 빈 집합은 <code>set()</code>으로 생성합니다(<code>{}</code>는 빈 딕셔너리).</p>
            <div class="code-block">
<span class="comment"># 집합 (중복 불가, 순서 없음)</span>
s = {<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>}
s.add(<span class="number">4</span>)        <span class="comment"># 추가</span>
s.remove(<span class="number">2</span>)      <span class="comment"># 제거</span>

<span class="comment"># 집합 연산</span>
a = {<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>}
b = {<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>}
<span class="keyword">print</span>(a | b)  <span class="comment"># 합집합: {1, 2, 3, 4}</span>
<span class="keyword">print</span>(a & b)  <span class="comment"># 교집합: {2, 3}</span>
<span class="keyword">print</span>(a - b)  <span class="comment"># 차집합: {1}</span>
            </div>
            
            <h3>None (Null)</h3>
            <p><code>None</code>은 파이썬의 '값이 없음'을 나타내는 특별한 싱글턴 객체입니다. 다른 언어의 <code>null</code>에 해당하며, 함수가 명시적으로 값을 반환하지 않을 때도 <code>None</code>이 반환됩니다. None 비교는 <code>==</code> 대신 <code>is</code>를 사용하는 것이 권장됩니다.</p>
            <div class="code-block">
x = <span class="keyword">None</span>
<span class="keyword">print</span>(x <span class="keyword">is</span> <span class="keyword">None</span>)  <span class="comment"># True</span>
<span class="keyword">print</span>(x == <span class="keyword">None</span>)  <span class="comment"># True (하지만 is를 권장)</span>
            </div>
            
            <h3>불변 vs 가변 객체</h3>
            <p>파이썬 객체는 생성 후 값을 변경할 수 있는지에 따라 <strong>가변(mutable)</strong>과 <strong>불변(immutable)</strong>으로 나뉩니다. 불변 객체를 수정하려 하면 새로운 객체가 생성되며, 가변 객체는 원본이 직접 변경됩니다. 이 차이는 함수 인자 전달, 복사, 딕셔너리 키 사용 등에서 중요합니다.</p>
            <div class="tip-box">
                <ul>
                    <li><strong>불변:</strong> int, float, str, tuple, frozenset</li>
                    <li><strong>가변:</strong> list, dict, set</li>
                </ul>
            </div>

            <div class="level-guide beginner">
                <div class="level-guide-header">초급자 가이드 - 자료형 선택 기준</div>
                <div class="level-guide-content">
                    <p>어떤 자료형을 사용해야 할지 고민될 때 참고하세요:</p>
                    <ul>
                        <li><strong>숫자를 다룰 때</strong> → <code>int</code>(정수), <code>float</code>(소수점). 대부분의 경우 이 두 가지로 충분합니다.</li>
                        <li><strong>글자/문장을 다룰 때</strong> → <code>str</code>(문자열). 작은따옴표든 큰따옴표든 상관없습니다.</li>
                        <li><strong>여러 값을 순서대로 저장할 때</strong> → <code>list</code>(리스트). 가장 자주 사용하는 자료형입니다.</li>
                        <li><strong>이름표(키)로 값을 찾을 때</strong> → <code>dict</code>(딕셔너리). 전화번호부처럼 "이름 → 번호"의 관계를 저장합니다.</li>
                        <li><strong>참/거짓을 나타낼 때</strong> → <code>bool</code>. <code>True</code> 또는 <code>False</code> 값만 가집니다.</li>
                    </ul>
                    <p><strong>타입 변환:</strong> <code>int("42")</code>는 문자열을 정수로, <code>str(42)</code>는 정수를 문자열로, <code>float("3.14")</code>는 문자열을 실수로 변환합니다.</p>
                </div>
            </div>

            <div class="level-guide intermediate">
                <div class="level-guide-header">중급자 가이드 - 자료형의 성능과 실무 패턴</div>
                <div class="level-guide-content">
                    <p>자료형마다 연산별 시간복잡도가 다릅니다. 올바른 자료형 선택이 성능에 큰 영향을 미칩니다:</p>
                    <ul>
                        <li><strong>리스트 vs 집합</strong>: <code>in</code> 연산에서 리스트는 O(n), 집합(set)은 O(1)입니다. 멤버십 검사가 빈번하면 <code>set</code>을 사용하세요.</li>
                        <li><strong>딕셔너리 컴프리헨션</strong>: <code>{k: v for k, v in pairs}</code>로 딕셔너리를 간결하게 생성할 수 있습니다.</li>
                        <li><strong>언패킹(Unpacking)</strong>: <code>a, b, *rest = [1, 2, 3, 4, 5]</code>에서 <code>a=1</code>, <code>b=2</code>, <code>rest=[3,4,5]</code>입니다.</li>
                        <li><strong>딕셔너리 병합(3.9+)</strong>: <code>merged = dict1 | dict2</code>로 두 딕셔너리를 병합할 수 있습니다.</li>
                        <li><strong>defaultdict 활용</strong>: <code>collections.defaultdict(list)</code>를 사용하면 키 존재 여부를 확인하지 않고도 안전하게 값을 추가할 수 있습니다.</li>
                    </ul>
                </div>
            </div>

            <div class="level-guide advanced">
                <div class="level-guide-header">고급자 가이드 - 자료형의 내부 구현</div>
                <div class="level-guide-content">
                    <p>CPython의 자료형 구현을 이해하면 성능 최적화에 도움이 됩니다:</p>
                    <ul>
                        <li><strong>리스트 내부</strong>: CPython의 리스트는 포인터 배열(array of pointers)로 구현됩니다. <code>append()</code>는 평균 O(1)이지만, 배열이 가득 차면 약 1.125배 크기로 재할당합니다. <code>insert(0, x)</code>는 모든 요소를 이동하므로 O(n)입니다.</li>
                        <li><strong>딕셔너리 내부</strong>: CPython 3.6+에서 딕셔너리는 compact dict 구현을 사용합니다. 해시 테이블 + 삽입 순서 배열로 구성되어, 삽입 순서가 보장되면서도 이전보다 20-25% 메모리를 절약합니다.</li>
                        <li><strong>문자열 인코딩</strong>: CPython 3.3+에서 문자열은 내용에 따라 Latin-1(1바이트), UCS-2(2바이트), UCS-4(4바이트) 중 가장 효율적인 인코딩을 자동 선택합니다(PEP 393 Flexible String Representation).</li>
                        <li><strong>__slots__</strong>: 클래스에 <code>__slots__</code>를 정의하면 <code>__dict__</code> 대신 고정 크기 배열을 사용하여 인스턴스당 수십 바이트의 메모리를 절약합니다. 수백만 개의 객체를 생성할 때 유용합니다.</li>
                        <li><strong>array 모듈</strong>: 동일 타입의 숫자만 저장할 때 <code>array.array</code>를 사용하면 리스트 대비 메모리를 4-8배 절약합니다.</li>
                    </ul>
                </div>
            </div>
        </section>
        
        <section id="control">
            <h2>4. 제어문</h2>
            <span class="level-badge level-beginner">초급</span>
            <span class="level-badge level-intermediate">중급</span>

            <p>
                제어문은 프로그램의 <strong>실행 흐름을 제어</strong>하는 구문입니다.
                <strong>조건문(if-elif-else)</strong>으로 조건에 따라 다른 코드를 실행하고,
                <strong>반복문(for, while)</strong>으로 코드를 반복 실행합니다.
                Python 3.10부터는 <strong>Match-Case</strong>(구조적 패턴 매칭)를 통해 복잡한 데이터 구조의 형태를 매칭하여 분기할 수 있습니다.
                <code>break</code>, <code>continue</code>, <code>pass</code> 등의 키워드로 반복 흐름을 세밀하게 제어합니다.
            </p>

            <h3>조건문 (if-elif-else)</h3>
            <p>조건문은 주어진 조건의 참/거짓에 따라 코드 실행 흐름을 분기합니다. <code>if</code>로 시작하고, 추가 조건은 <code>elif</code>(else if의 축약), 모든 조건에 해당하지 않는 경우 <code>else</code>를 사용합니다. 파이썬에는 C/Java의 삼항 연산자 대신 <code>값1 if 조건 else 값2</code> 형태의 조건부 표현식이 있습니다.</p>
            <div class="code-block">
score = <span class="number">85</span>

<span class="keyword">if</span> score >= <span class="number">90</span>:
    grade = <span class="string">"A"</span>
<span class="keyword">elif</span> score >= <span class="number">80</span>:
    grade = <span class="string">"B"</span>
<span class="keyword">elif</span> score >= <span class="number">70</span>:
    grade = <span class="string">"C"</span>
<span class="keyword">else</span>:
    grade = <span class="string">"F"</span>

<span class="keyword">print</span>(<span class="string">f"학점: {grade}"</span>)  <span class="comment"># 학점: B</span>
            </div>
            
            <h3>반복문 (for, while)</h3>
            <p><code>for</code> 문은 시퀀스(리스트, 문자열, range 등)의 각 요소를 순회하며 실행합니다. <code>while</code> 문은 조건이 참인 동안 반복 실행합니다. <code>range(n)</code>은 0부터 n-1까지의 정수 시퀀스를 생성하며, <code>range(start, stop, step)</code>으로 시작값, 끝값, 간격을 지정할 수 있습니다.</p>
            <div class="code-block">
<span class="comment"># for 반복문</span>
<span class="keyword">for</span> i <span class="keyword">in</span> <span class="builtin">range</span>(<span class="number">5</span>):
    <span class="keyword">print</span>(i)  <span class="comment"># 0, 1, 2, 3, 4</span>

<span class="comment"># while 반복문</span>
count = <span class="number">0</span>
<span class="keyword">while</span> count < <span class="number">3</span>:
    <span class="keyword">print</span>(<span class="string">f"카운트: {count}"</span>)
    count += <span class="number">1</span>
            </div>
            
            <h3>Match-Case (Structural Pattern Matching)</h3>
            <p>Python 3.10에서 도입된 <strong>구조적 패턴 매칭</strong>은 C/Java의 switch-case보다 훨씬 강력합니다. 단순 값 비교뿐 아니라 튜플, 리스트, 클래스 인스턴스 등 데이터 구조의 형태를 매칭하고, 매칭된 부분을 변수에 바인딩할 수 있습니다. 와일드카드 <code>_</code>는 기본(default) 케이스에 사용됩니다.</p>
            <div class="code-block">
<span class="keyword">def</span> <span class="function">http_status</span>(status):
    <span class="keyword">match</span> status:
        <span class="keyword">case</span> <span class="number">200</span>:
            <span class="keyword">return</span> <span class="string">"OK"</span>
        <span class="keyword">case</span> <span class="number">404</span>:
            <span class="keyword">return</span> <span class="string">"Not Found"</span>
        <span class="keyword">case</span> <span class="number">500</span>:
            <span class="keyword">return</span> <span class="string">"Server Error"</span>
        <span class="keyword">case</span> _:
            <span class="keyword">return</span> <span class="string">"Unknown"</span>

<span class="comment"># 패턴 매칭 with tuple/list</span>
<span class="keyword">def</span> <span class="function">location</span>(point):
    <span class="keyword">match</span> point:
        <span class="keyword">case</span> (<span class="number">0</span>, <span class="number">0</span>):
            <span class="keyword">return</span> <span class="string">"원점"</span>
        <span class="keyword">case</span> (x, <span class="number">0</span>):
            <span class="keyword">return</span> <span class="string">f"x축 위: {x}"</span>
        <span class="keyword">case</span> (x, y):
            <span class="keyword">return</span> <span class="string">f"점 ({x}, {y})"</span>
            </div>
            
            <h3>Break, Continue, Else (반복문)</h3>
            <p><code>break</code>는 반복문을 즉시 종료하고, <code>continue</code>는 현재 반복을 건너뛰고 다음 반복으로 진행합니다. 파이썬의 독특한 기능으로, <code>for/while</code> 뒤에 <code>else</code> 블록을 붙일 수 있으며, 이는 <code>break</code> 없이 반복이 정상 완료되었을 때만 실행됩니다.</p>
            <div class="code-block">
<span class="keyword">for</span> i <span class="keyword">in</span> <span class="builtin">range</span>(<span class="number">10</span>):
    <span class="keyword">if</span> i == <span class="number">3</span>:
        <span class="keyword">continue</span>  <span class="comment"># 다음 반복으로</span>
    <span class="keyword">if</span> i == <span class="number">7</span>:
        <span class="keyword">break</span>  <span class="comment"># 반복 종료</span>
    <span class="keyword">print</span>(i)
<span class="keyword">else</span>:
    <span class="keyword">print</span>(<span class="string">"완료"</span>)  <span class="comment"># break로 나가면 실행 안됨</span>
            </div>
            
            <div class="svg-container">
                <!-- Loop Flow SVG -->
                <svg width="500" height="300" viewBox="0 0 500 300" xmlns="http://www.w3.org/2000/svg">
                    <!-- Start -->
                    <ellipse cx="250" cy="30" rx="60" ry="25" fill="#4CAF50"/>
                    <text x="250" y="35" text-anchor="middle" fill="white" font-weight="bold">시작</text>

                    <!-- Condition -->
                    <polygon points="250,80 320,130 250,180 180,130" fill="#FF9800"/>
                    <text x="250" y="135" text-anchor="middle" fill="white" font-weight="bold">조건</text>
                    <text x="250" y="155" text-anchor="middle" fill="white" font-size="11">확인?</text>

                    <!-- Arrow down from Start -->
                    <line x1="250" y1="55" x2="250" y2="80" stroke="var(--text-secondary)" stroke-width="2" marker-end="url(#arrowhead)"/>

                    <!-- Yes path -->
                    <line x1="320" y1="130" x2="400" y2="130" stroke="#4CAF50" stroke-width="2"/>
                    <text x="360" y="120" fill="#4CAF50" font-weight="bold">Yes</text>
                    <line x1="400" y1="130" x2="400" y2="200" stroke="#4CAF50" stroke-width="2"/>
                    <rect x="330" y="200" width="140" height="40" rx="8" fill="#4CAF50"/>
                    <text x="400" y="225" text-anchor="middle" fill="white" font-weight="bold">실행</text>

                    <!-- No path -->
                    <line x1="180" y1="130" x2="100" y2="130" stroke="#f44336" stroke-width="2"/>
                    <text x="140" y="120" fill="#f44336" font-weight="bold">No</text>
                    <line x1="100" y1="130" x2="100" y2="250" stroke="#f44336" stroke-width="2"/>
                    <ellipse cx="100" cy="265" rx="50" ry="20" fill="#f44336"/>
                    <text x="100" y="270" text-anchor="middle" fill="white" font-weight="bold">종료</text>

                    <!-- Arrow from execute back to condition (루프백) -->
                    <path d="M 400 240 Q 400 280 320 280 Q 250 280 250 180" stroke="#3776AB" stroke-width="2" fill="none" stroke-dasharray="5,5" marker-end="url(#loopArrow)"/>
                    <text x="340" y="270" fill="#3776AB" font-size="11" font-weight="bold">반복</text>

                    <!-- Arrow definitions -->
                    <defs>
                        <marker id="arrowhead" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                            <polygon points="0 0, 10 3.5, 0 7" fill="var(--text-secondary)"/>
                        </marker>
                        <marker id="loopArrow" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                            <polygon points="0 0, 10 3.5, 0 7" fill="#3776AB"/>
                        </marker>
                    </defs>
                </svg>
            </div>
            
            <div class="tip-box">
                <strong>💡 팁:</strong> range() 함수는 숫자 시퀀스를 생성합니다. range(5)는 0부터 4까지입니다.
            </div>

            <div class="level-guide beginner">
                <div class="level-guide-header">초급자 가이드 - 제어문의 일상적 비유</div>
                <div class="level-guide-content">
                    <p>제어문을 일상생활에 비유하면 쉽게 이해할 수 있습니다:</p>
                    <ul>
                        <li><strong>if문 = 교차로</strong>: "비가 오면 우산을 챙기고, 아니면 그냥 나간다" → <code>if 비: 우산() else: 외출()</code></li>
                        <li><strong>for문 = 체크리스트</strong>: "장바구니의 각 물건에 대해 가격을 확인한다" → <code>for 물건 in 장바구니: 가격확인(물건)</code></li>
                        <li><strong>while문 = 반복 알람</strong>: "목표에 도달할 때까지 계속 시도한다" → <code>while not 목표달성: 시도()</code></li>
                    </ul>
                    <p><strong>주의:</strong> <code>while True:</code>는 무한 루프를 만듭니다. 반드시 <code>break</code>로 탈출 조건을 설정하세요. 무한 루프에 빠지면 Ctrl+C로 중단할 수 있습니다.</p>
                </div>
            </div>

            <div class="level-guide intermediate">
                <div class="level-guide-header">중급자 가이드 - 파이썬다운(Pythonic) 반복 패턴</div>
                <div class="level-guide-content">
                    <p>인덱스 기반 반복 대신 파이썬다운 반복 패턴을 사용하세요:</p>
                    <ul>
                        <li><strong>enumerate()</strong>: 인덱스가 필요할 때 <code>for i, v in enumerate(리스트):</code>를 사용합니다. <code>for i in range(len(리스트)):</code>는 비-파이썬적(unpythonic)입니다.</li>
                        <li><strong>zip()</strong>: 두 리스트를 동시에 순회할 때 <code>for a, b in zip(리스트1, 리스트2):</code>를 사용합니다.</li>
                        <li><strong>삼항 연산자</strong>: <code>result = "짝수" if x % 2 == 0 else "홀수"</code>로 간결하게 조건 분기합니다.</li>
                        <li><strong>any() / all()</strong>: <code>if any(x > 10 for x in numbers):</code>로 "하나라도 만족하면", <code>if all(x > 0 for x in numbers):</code>로 "모두 만족하면"을 표현합니다.</li>
                        <li><strong>for-else 실전 활용</strong>: 소수 판별 시 <code>for i in range(2, n):</code> 반복 후 <code>else</code>에서 "소수임"을 확인하는 패턴이 대표적입니다.</li>
                    </ul>
                </div>
            </div>

            <div class="level-guide advanced">
                <div class="level-guide-header">고급자 가이드 - 반복 성능 최적화와 Match-Case 심화</div>
                <div class="level-guide-content">
                    <p>대규모 데이터 처리 시 반복문 성능을 최적화하는 기법과 패턴 매칭 고급 활용법:</p>
                    <ul>
                        <li><strong>컴프리헨션 vs for 루프</strong>: 리스트 컴프리헨션은 일반 for 루프보다 약 20-30% 빠릅니다. C 레벨에서 최적화된 LIST_APPEND 바이트코드를 사용하기 때문입니다.</li>
                        <li><strong>제너레이터 표현식</strong>: 메모리 절약이 필요하면 <code>[...]</code> 대신 <code>(...)</code>를 사용하세요. <code>sum(x**2 for x in range(10**7))</code>은 리스트를 생성하지 않아 메모리를 절약합니다.</li>
                        <li><strong>itertools 활용</strong>: <code>itertools.chain()</code>으로 여러 이터러블을 연결하고, <code>itertools.islice()</code>로 슬라이싱하면 대용량 데이터를 메모리 효율적으로 처리할 수 있습니다.</li>
                        <li><strong>Match-Case 클래스 패턴</strong>: <code>case Point(x=0, y=y):</code>처럼 클래스 인스턴스의 속성을 매칭하고 추출할 수 있습니다. <code>__match_args__</code>를 정의하면 위치 기반 매칭도 가능합니다.</li>
                        <li><strong>Match-Case 가드(Guard)</strong>: <code>case x if x > 0:</code>처럼 <code>if</code> 가드를 사용하여 패턴 매칭에 추가 조건을 걸 수 있습니다.</li>
                    </ul>
                </div>
            </div>
        </section>

        <section id="functions">
            <h2>5. 함수 (Functions)</h2>
            <span class="level-badge level-beginner">초급</span>
            <span class="level-badge level-intermediate">중급</span>

            <p>
                함수는 특정 작업을 수행하는 코드 블록을 하나로 묶어 <strong>이름을 부여</strong>한 것입니다. 함수를 사용하면 동일한 코드를 여러 번 작성할 필요 없이 <strong>호출만으로 재사용</strong>할 수 있고,
                프로그램을 논리적 단위로 분리하여 <strong>가독성과 유지보수성</strong>을 크게 높일 수 있습니다.
                파이썬에서 함수는 <strong>일급 객체(First-class Object)</strong>로, 변수에 할당하거나 다른 함수의 인자로 전달하는 등 유연하게 활용할 수 있습니다.
                또한 <code>lambda</code>, 클로저(closure), 데코레이터(decorator), 제너레이터(generator) 등 다양한 고급 기법을 지원합니다.
            </p>
            
            <h3>기본 함수 정의</h3>
            <p>함수는 <code>def</code> 키워드로 정의하며, 함수명 뒤 괄호 안에 매개변수를 선언합니다. 함수 본문 첫 줄에 문자열을 작성하면 <strong>docstring</strong>(문서 문자열)이 되어 <code>help()</code> 함수로 확인할 수 있습니다. <code>return</code>으로 값을 반환하며, 생략 시 <code>None</code>이 반환됩니다.</p>
            <div class="code-block">
<span class="keyword">def</span> <span class="function">greet</span>(name):
    <span class="string">"""인사말을 출력하는 함수"""</span>
    <span class="keyword">return</span> <span class="string">f"안녕하세요, {name}님!"</span>

result = <span class="function">greet</span>(<span class="string">"민준"</span>)
<span class="keyword">print</span>(result)  <span class="comment"># 안녕하세요, 민준님!</span>
            </div>
            
            <h3>매개변수와 반환값</h3>
            <p>매개변수에 <strong>기본값(default value)</strong>을 지정하면 호출 시 해당 인자를 생략할 수 있습니다. 기본값이 있는 매개변수는 반드시 기본값이 없는 매개변수 뒤에 위치해야 합니다. 여러 값을 반환하려면 튜플로 반환하고 언패킹하여 받을 수 있습니다.</p>
            <div class="code-block">
<span class="keyword">def</span> <span class="function">add_numbers</span>(a, b=<span class="number">0</span>):
    <span class="string">"""두 수를 더하는 함수 (기본값 지원)"""</span>
    <span class="keyword">return</span> a + b

<span class="function">add_numbers</span>(<span class="number">5</span>, <span class="number">3</span>)    <span class="comment"># 8</span>
<span class="function">add_numbers</span>(<span class="number">5</span>)         <span class="comment"># 5 (b의 기본값 0 사용)</span>
            </div>
            
            <h3>*args와 **kwargs</h3>
            <p><code>*args</code>는 위치 인자를 <strong>튜플</strong>로 묶어서 받고, <code>**kwargs</code>는 키워드 인자를 <strong>딕셔너리</strong>로 묶어서 받습니다. 이를 통해 함수가 임의 개수의 인자를 처리할 수 있습니다. 반대로, 호출 시 <code>*리스트</code>나 <code>**딕셔너리</code>를 사용하면 인자를 풀어서(unpacking) 전달할 수 있습니다.</p>
            <div class="code-block">
<span class="keyword">def</span> <span class="function">print_all</span>(*args, **kwargs):
    <span class="keyword">print</span>(<span class="string">"args:"</span>, args)
    <span class="keyword">print</span>(<span class="string">"kwargs:"</span>, kwargs)

<span class="function">print_all</span>(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, name=<span class="string">"민준"</span>, age=<span class="number">25</span>)
<span class="comment"># args: (1, 2, 3)</span>
<span class="comment"># kwargs: {'name': '민준', 'age': 25}</span>
            </div>
            
            <h3>Lambda (익명 함수)</h3>
            <p><code>lambda</code>는 이름 없는 한 줄짜리 함수를 생성합니다. <code>lambda 매개변수: 표현식</code> 형식이며, <code>sorted()</code>, <code>map()</code>, <code>filter()</code> 등 함수를 인자로 받는 고차 함수와 함께 자주 사용됩니다. 복잡한 로직에는 일반 <code>def</code> 함수가 권장됩니다.</p>
            <div class="code-block">
<span class="comment"># lambda 함수</span>
square = <span class="keyword">lambda</span> x: x ** <span class="number">2</span>
<span class="keyword">print</span>(square(<span class="number">5</span>))  <span class="comment"># 25</span>

<span class="comment"># 정렬에 사용</span>
pairs = [(<span class="number">1</span>, <span class="string">"one"</span>), (<span class="number">3</span>, <span class="string">"three"</span>), (<span class="number">2</span>, <span class="string">"two"</span>)]
pairs.sort(key=<span class="keyword">lambda</span> x: x[<span class="number">0</span>])
<span class="comment"># [(1, 'one'), (2, 'two'), (3, 'three')]</span>
            </div>
            
            <h3>고급 함수 기법</h3>
            <p><strong>클로저(Closure)</strong>는 외부 함수의 변수를 기억하는 내부 함수이며, 상태를 유지하는 함수를 만들 때 유용합니다. <strong>데코레이터(Decorator)</strong>는 <code>@</code> 문법으로 함수를 감싸서 기존 기능을 변경하지 않으면서 새로운 동작을 추가하는 패턴입니다. (더 실전적인 데코레이터 활용은 아래 <em>데코레이터 (Decorators)</em> 섹션에서 다룹니다.)</p>
            <div class="code-block">
<span class="comment"># 클로저 (Closure)</span>
<span class="keyword">def</span> <span class="function">make_counter</span>():
    count = [<span class="number">0</span>]
    <span class="keyword">def</span> <span class="function">counter</span>():
        count[<span class="number">0</span>] += <span class="number">1</span>
        <span class="keyword">return</span> count[<span class="number">0</span>]
    <span class="keyword">return</span> counter

c = <span class="function">make_counter</span>()
<span class="keyword">print</span>(c())  <span class="comment"># 1</span>
<span class="keyword">print</span>(c())  <span class="comment"># 2</span>

<span class="comment"># 데코레이터</span>
<span class="keyword">def</span> <span class="function">my_decorator</span>(func):
    <span class="keyword">def</span> <span class="function">wrapper</span>(*args, **kwargs):
        <span class="keyword">print</span>(<span class="string">"Before"</span>)
        result = func(*args, **kwargs)
        <span class="keyword">print</span>(<span class="string">"After"</span>)
        <span class="keyword">return</span> result
    <span class="keyword">return</span> wrapper

<span class="decorator">@my_decorator</span>
<span class="keyword">def</span> <span class="function">say_hello</span>():
    <span class="keyword">print</span>(<span class="string">"Hello!"</span>)
            </div>
            
            <h3>일급 시민 (First-class Citizens)</h3>
            <p>파이썬에서 함수는 <strong>일급 객체(First-class Object)</strong>입니다. 이는 함수를 변수에 할당하고, 다른 함수의 인자로 전달하고, 함수의 반환값으로 사용할 수 있다는 의미입니다. 이 특성이 데코레이터, 콜백, 함수형 프로그래밍 등 고급 패턴의 기반이 됩니다.</p>
            <div class="code-block">
<span class="comment"># 함수를 변수에 할당</span>
my_func = <span class="builtin">print</span>
my_func(<span class="string">"Hello"</span>)

<span class="comment"># 함수를 인자로 전달</span>
<span class="keyword">def</span> <span class="function">apply</span>(func, x):
    <span class="keyword">return</span> func(x)

<span class="keyword">def</span> <span class="function">double</span>(x): <span class="keyword">return</span> x * <span class="number">2</span>
<span class="keyword">print</span>(<span class="function">apply</span>(double, <span class="number">5</span>))  <span class="comment"># 10</span>

<span class="comment"># 함수 반환</span>
<span class="keyword">def</span> <span class="function">get_adder</span>(n):
    <span class="keyword">return</span> <span class="keyword">lambda</span> x: x + n

add5 = <span class="function">get_adder</span>(<span class="number">5</span>)
<span class="keyword">print</span>(add5(<span class="number">3</span>))  <span class="comment"># 8</span>
            </div>
            
            <h3>함수 Annotations</h3>
            <p>함수 어노테이션은 매개변수와 반환값의 <strong>타입 정보를 메타데이터</strong>로 기록합니다. 런타임에는 강제되지 않지만, <code>mypy</code>와 같은 정적 분석 도구가 타입 오류를 사전에 검출하는 데 활용합니다. <code>__annotations__</code> 속성으로 어노테이션 정보를 확인할 수 있습니다.</p>
            <div class="code-block">
<span class="keyword">def</span> <span class="function">greet</span>(name: <span class="builtin">str</span>, times: <span class="builtin">int</span> = <span class="number">1</span>) -> <span class="builtin">str</span>:
    <span class="keyword">return</span> <span class="string">"Hello! "</span> * times + name

<span class="comment"># Annotations 확인</span>
<span class="keyword">print</span>(greet.__annotations__)
<span class="comment"># {'name': <class 'str'>, 'times': <class 'int'>, 'return': <class 'str'>}</span>
            </div>
            
            <h3>제너레이터 (Generator) - 함수에서</h3>
            <p>제너레이터는 <code>yield</code> 키워드를 사용하여 값을 <strong>하나씩 느리게(lazy) 생성</strong>하는 특수 함수입니다. 모든 값을 메모리에 한꺼번에 저장하지 않으므로 대용량 데이터 처리에 매우 효율적입니다. <code>next()</code>로 다음 값을 수동으로 가져오거나, <code>for</code> 문에서 자동으로 순회할 수 있습니다.</p>
            <div class="code-block">
<span class="keyword">def</span> <span class="function">fibonacci</span>(n):
    a, b = <span class="number">0</span>, <span class="number">1</span>
    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="builtin">range</span>(n):
        <span class="keyword">yield</span> a
        a, b = b, a + b

<span class="keyword">for</span> num <span class="keyword">in</span> <span class="function">fibonacci</span>(<span class="number">10</span>):
    <span class="keyword">print</span>(num)  <span class="comment"># 0, 1, 1, 2, 3, 5, 8, 13, 21, 34</span>

<span class="comment"># next()로 수동 가져오기</span>
gen = <span class="function">fibonacci</span>(<span class="number">5</span>)
<span class="keyword">print</span>(<span class="builtin">next</span>(gen))  <span class="comment"># 0</span>
<span class="keyword">print</span>(<span class="builtin">next</span>(gen))  <span class="comment"># 1</span>
            </div>
            
            <div class="svg-container">
                <!-- Function Concept SVG -->
                <svg width="600" height="200" viewBox="0 0 600 200" xmlns="http://www.w3.org/2000/svg">
                    <defs>
                        <marker id="arrow2" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                            <polygon points="0 0, 10 3.5, 0 7" fill="#3776AB"/>
                        </marker>
                    </defs>

                    <!-- Input -->
                    <rect x="10" y="65" width="130" height="70" rx="8" fill="var(--svg-blue)" stroke="#2196F3" stroke-width="2"/>
                    <text x="75" y="97" text-anchor="middle" fill="var(--text-primary)" font-weight="bold">입력 (Input)</text>
                    <text x="75" y="118" text-anchor="middle" fill="var(--text-secondary)" font-size="11">매개변수</text>

                    <!-- Arrow to Function -->
                    <line x1="140" y1="103" x2="185" y2="103" stroke="#3776AB" stroke-width="3" marker-end="url(#arrow2)"/>

                    <!-- Function Box -->
                    <rect x="190" y="50" width="190" height="100" rx="15" fill="#667eea"/>
                    <text x="285" y="103" text-anchor="middle" fill="white" font-weight="bold" font-size="18">함수 (Function)</text>
                    <text x="285" y="128" text-anchor="middle" fill="white" font-size="11">실행 로직</text>

                    <!-- Arrow from Function -->
                    <line x1="380" y1="103" x2="425" y2="103" stroke="#3776AB" stroke-width="3" marker-end="url(#arrow2)"/>

                    <!-- Output -->
                    <rect x="430" y="65" width="130" height="70" rx="8" fill="var(--svg-green)" stroke="#4CAF50" stroke-width="2"/>
                    <text x="495" y="97" text-anchor="middle" fill="var(--text-primary)" font-weight="bold">출력 (Output)</text>
                    <text x="495" y="118" text-anchor="middle" fill="var(--text-secondary)" font-size="11">반환값</text>
                </svg>
            </div>
            <h3>데코레이터 (Decorators)</h3>
            <p>데코레이터는 기존 함수를 감싸서(wrapping) 원본 코드를 수정하지 않고 로깅, 인증, 성능 측정 등 <strong>횡단 관심사(Cross-cutting Concerns)</strong>를 추가하는 디자인 패턴입니다. <code>@decorator_name</code> 문법은 <code>func = decorator_name(func)</code>의 축약형입니다. <code>functools.wraps</code>를 사용하면 원본 함수의 메타데이터가 보존됩니다.</p>
            
            <div class="code-block">
<span class="keyword">def</span> <span class="function">timer_decorator</span>(func):
    <span class="keyword">def</span> <span class="function">wrapper</span>(*args, **kwargs):
        <span class="keyword">import</span> time
        start = time.time()
        result = func(*args, **kwargs)
        end = time.time()
        <span class="keyword">print</span>(<span class="string">f"{func.__name__} 실행 시간: {end-start:.2f}초"</span>)
        <span class="keyword">return</span> result
    <span class="keyword">return</span> wrapper

<span class="decorator">@timer_decorator</span>
<span class="keyword">def</span> <span class="function">slow_function</span>():
    <span class="keyword">import</span> time
    time.sleep(<span class="number">1</span>)
    <span class="keyword">return</span> <span class="string">"완료"</span>

<span class="function">slow_function</span>()
            </div>
            
            <h3>컨텍스트 매니저 (Context Manager)</h3>
            <p><code>with</code> 문은 리소스(파일, 네트워크 연결, 락 등)의 <strong>획득과 해제를 자동으로 관리</strong>합니다. 예외가 발생하더라도 반드시 리소스가 정리되므로, <code>try-finally</code>보다 안전하고 간결합니다. <code>__enter__</code>와 <code>__exit__</code> 메서드를 구현하거나 <code>contextlib.contextmanager</code> 데코레이터로 커스텀 컨텍스트 매니저를 만들 수 있습니다.</p>
            
            <div class="code-block">
<span class="keyword">with</span> <span class="builtin">open</span>(<span class="string">"test.txt"</span>, <span class="string">"w"</span>) <span class="keyword">as</span> f:
    f.<span class="function">write</span>(<span class="string">"안녕하세요!"</span>)
<span class="comment"># 파일이 자동으로 닫힘</span>
            </div>

            <h3>async/await (비동기 프로그래밍)</h3>
            <p>비동기 프로그래밍은 I/O 대기 시간(네트워크 요청, 파일 읽기 등)에 다른 작업을 수행하여 효율성을 극대화합니다. <code>async def</code>로 코루틴(coroutine) 함수를 정의하고, <code>await</code>로 비동기 작업의 완료를 기다립니다. <code>asyncio</code>는 Python 표준 라이브러리의 비동기 I/O 프레임워크로, <code>asyncio.run()</code>으로 이벤트 루프를 시작하며, <code>asyncio.gather()</code>로 여러 코루틴을 동시에 실행할 수 있습니다.</p>

            <div class="code-block">
<span class="keyword">import</span> asyncio

<span class="keyword">async</span> <span class="function">def</span> <span class="function">fetch_data</span>():
    <span class="keyword">print</span>(<span class="string">"데이터 가져오는 중..."</span>)
    <span class="keyword">await</span> asyncio.sleep(<span class="number">2</span>)
    <span class="keyword">return</span> {<span class="string">"data"</span>: <span class="string">"some data"</span>}

<span class="keyword">async</span> <span class="function">def</span> <span class="function">main</span>():
    result = <span class="keyword">await</span> <span class="function">fetch_data</span>()
    <span class="keyword">print</span>(result)

asyncio.run(<span class="function">main</span>())
            </div>

            <div class="level-guide beginner">
                <div class="level-guide-header">초급자 가이드 - 함수를 쉽게 이해하기</div>
                <div class="level-guide-content">
                    <p>함수를 일상생활에 비유하면:</p>
                    <ul>
                        <li><strong>함수 = 레시피</strong>: "재료(매개변수)를 넣으면 요리(결과)가 나오는 레시피"입니다. <code>def 볶음밥(밥, 계란): return 완성된_볶음밥</code></li>
                        <li><strong>왜 함수를 만드나?</strong>: 같은 코드를 10번 반복해서 쓰면 수정할 때 10곳을 다 고쳐야 합니다. 함수로 만들면 1곳만 고치면 됩니다.</li>
                        <li><strong>return vs print</strong>: <code>return</code>은 값을 "돌려주는 것"이고, <code>print</code>는 화면에 "보여주는 것"입니다. <code>return</code>한 값은 변수에 저장하거나 다른 연산에 사용할 수 있습니다.</li>
                    </ul>
                    <p><strong>초보자 팁:</strong> 함수 이름은 동사로 시작하세요. <code>calculate_total()</code>, <code>get_user_name()</code>, <code>send_email()</code>처럼 "무엇을 하는지" 이름에 담으면 읽기 좋습니다.</p>
                </div>
            </div>

            <div class="level-guide intermediate">
                <div class="level-guide-header">중급자 가이드 - 함수 설계 원칙과 실무 패턴</div>
                <div class="level-guide-content">
                    <p>좋은 함수를 작성하기 위한 실무 원칙:</p>
                    <ul>
                        <li><strong>단일 책임 원칙</strong>: 하나의 함수는 하나의 작업만 수행해야 합니다. 함수 설명에 "그리고"가 들어가면 분리를 고려하세요.</li>
                        <li><strong>가변 기본값 함정</strong>: <code>def f(items=[])</code>는 모든 호출이 같은 리스트를 공유합니다! <code>def f(items=None): items = items or []</code>로 작성하세요.</li>
                        <li><strong>키워드 전용 인자</strong>: <code>def f(*, name, age)</code>에서 <code>*</code> 뒤의 인자는 반드시 키워드로 전달해야 합니다. API 설계 시 실수를 방지합니다.</li>
                        <li><strong>위치 전용 인자(3.8+)</strong>: <code>def f(x, y, /)</code>에서 <code>/</code> 앞의 인자는 위치로만 전달할 수 있습니다.</li>
                        <li><strong>functools.wraps</strong>: 데코레이터 작성 시 반드시 <code>@functools.wraps(func)</code>를 사용하여 원본 함수의 <code>__name__</code>, <code>__doc__</code> 등 메타데이터를 보존하세요.</li>
                    </ul>
                </div>
            </div>

            <div class="level-guide advanced">
                <div class="level-guide-header">고급자 가이드 - 함수의 내부 동작과 고급 패턴</div>
                <div class="level-guide-content">
                    <p>함수 객체의 내부 구조와 고급 활용 패턴:</p>
                    <ul>
                        <li><strong>함수 객체 속성</strong>: 함수는 <code>__code__</code>(바이트코드), <code>__closure__</code>(클로저 변수), <code>__defaults__</code>(기본값), <code>__globals__</code>(전역 네임스페이스) 등의 속성을 가집니다.</li>
                        <li><strong>LEGB 규칙</strong>: 변수 탐색 순서는 Local → Enclosing → Global → Built-in입니다. <code>nonlocal</code>은 Enclosing 스코프의 변수를 수정할 때, <code>global</code>은 Global 스코프의 변수를 수정할 때 사용합니다.</li>
                        <li><strong>제너레이터 send()</strong>: <code>gen.send(value)</code>로 제너레이터에 값을 전달할 수 있어 양방향 통신이 가능합니다. 이는 코루틴(coroutine)의 기초입니다.</li>
                        <li><strong>yield from</strong>: <code>yield from iterable</code>은 서브 제너레이터에게 제어권을 위임합니다. 재귀적 제너레이터나 코루틴 체이닝에 사용됩니다.</li>
                        <li><strong>데코레이터 팩토리</strong>: 인자를 받는 데코레이터는 3단 중첩 함수입니다. <code>@retry(max_attempts=3)</code>처럼 설정 가능한 데코레이터를 만들 수 있습니다.</li>
                        <li><strong>asyncio 동시성</strong>: <code>asyncio.gather()</code>로 여러 코루틴을 동시에 실행하고, <code>asyncio.Semaphore</code>로 동시 실행 수를 제한할 수 있습니다.</li>
                    </ul>
                </div>
            </div>

        </section>

        <section id="oop">
            <h2>6. 객체지향 프로그래밍 (OOP)</h2>
            <span class="level-badge level-intermediate">중급</span>
            <span class="level-badge level-advanced">고급</span>
            
            <p>
                <strong>객체지향 프로그래밍(OOP)</strong>은 관련 데이터와 동작을 하나의 <strong>객체(Object)</strong>로 묶어 프로그램을 설계하는 패러다임입니다.
                <strong>캡슐화(Encapsulation)</strong>로 데이터를 보호하고, <strong>상속(Inheritance)</strong>으로 코드를 재사용하며,
                <strong>다형성(Polymorphism)</strong>으로 같은 인터페이스에 다른 구현을 제공합니다.
                파이썬은 모든 것이 객체이며, 클래스 기반 OOP를 <code>class</code> 키워드, 특수 메서드(dunder methods), <code>@property</code>, ABC, Protocol 등으로 풍부하게 지원합니다.
            </p>
            
            <h3>클래스와 객체</h3>
            <p><strong>클래스</strong>는 객체를 만들기 위한 설계도(blueprint)이고, <strong>객체</strong>는 클래스로부터 생성된 실체(instance)입니다. <code>__init__</code> 메서드는 생성자로, 객체 초기화 시 자동 호출됩니다. <code>self</code>는 인스턴스 자신을 가리키며, 모든 인스턴스 메서드의 첫 번째 매개변수입니다.</p>
            <div class="code-block">
<span class="keyword">class</span> <span class="function">Dog</span>:
    <span class="string">"""개를 나타내는 클래스"""</span>
    
    <span class="keyword">def</span> <span class="function">__init__</span>(self, name, age):
        self.name = name
        self.age = age
    
    <span class="keyword">def</span> <span class="function">bark</span>(self):
        <span class="keyword">return</span> <span class="string">f"{self.name}가 멍멍짖습니다!"</span>

<span class="comment"># 객체 생성</span>
my_dog = <span class="function">Dog</span>(<span class="string">"멍이"</span>, <span class="number">3</span>)
<span class="keyword">print</span>(my_dog.<span class="function">bark</span>())  <span class="comment"># 멍이가 멍멍짖습니다!</span>
            </div>
            
            <h3>상속 (Inheritance)</h3>
            <p>상속은 기존 클래스(부모/기반 클래스)의 속성과 메서드를 새로운 클래스(자식/파생 클래스)가 물려받는 메커니즘입니다. 코드 재사용을 촉진하고, 자식 클래스에서 부모 메서드를 <strong>오버라이드(재정의)</strong>하여 다형성을 구현할 수 있습니다.</p>
            <div class="code-block">
<span class="keyword">class</span> <span class="function">Animal</span>:
    <span class="keyword">def</span> <span class="function">__init__</span>(self, name):
        self.name = name

    <span class="keyword">def</span> <span class="function">speak</span>(self):
        <span class="keyword">pass</span>

<span class="keyword">class</span> <span class="function">Cat</span>(<span class="function">Animal</span>):  <span class="comment"># Animal 상속</span>
    <span class="keyword">def</span> <span class="function">speak</span>(self):
        <span class="keyword">return</span> <span class="string">f"{self.name}가 야옹합니다!"</span>

<span class="keyword">class</span> <span class="function">Dog</span>(<span class="function">Animal</span>):  <span class="comment"># Animal 상속</span>
    <span class="keyword">def</span> <span class="function">speak</span>(self):
        <span class="keyword">return</span> <span class="string">f"{self.name}가 멍멍합니다!"</span>
            </div>
            
            <h3>다중 상속</h3>
            <p>파이썬은 하나의 클래스가 여러 부모 클래스를 동시에 상속받는 <strong>다중 상속</strong>을 지원합니다. 이를 통해 여러 기능을 조합한 클래스를 만들 수 있으며, 이런 패턴을 <strong>믹스인(Mixin)</strong>이라 합니다. 다중 상속 시 메서드 충돌은 MRO(Method Resolution Order) 규칙에 따라 해결됩니다.</p>
            <div class="code-block">
<span class="keyword">class</span> <span class="function">Flyable</span>:
    <span class="keyword">def</span> <span class="function">fly</span>(self):
        <span class="keyword">return</span> <span class="string">"날고 있습니다!"</span>

<span class="keyword">class</span> <span class="function">Swimmable</span>:
    <span class="keyword">def</span> <span class="function">swim</span>(self):
        <span class="keyword">return</span> <span class="string">"수영하고 있습니다!"</span>

<span class="keyword">class</span> <span class="function">Duck</span>(Flyable, Swimmable):
    <span class="keyword">def</span> <span class="function">quack</span>(self):
        <span class="keyword">return</span> <span class="string">"꽥꽥!"</span>

duck = <span class="function">Duck</span>()
<span class="keyword">print</span>(duck.fly())   <span class="comment"># 날고 있습니다!</span>
<span class="keyword">print</span>(duck.swim())  <span class="comment"># 수영하고 있습니다!</span>
<span class="keyword">print</span>(duck.quack())  <span class="comment"># 꽥꽥!</span>
            </div>
            
            <h3>MRO (Method Resolution Order)</h3>
            <p>MRO는 다중 상속에서 메서드를 찾는 순서를 결정하는 알고리즘입니다. 파이썬은 <strong>C3 선형화(C3 Linearization)</strong> 알고리즘을 사용하며, <code>클래스.__mro__</code> 또는 <code>클래스.mro()</code>로 순서를 확인할 수 있습니다. <code>super()</code>는 이 MRO 순서에 따라 다음 클래스의 메서드를 호출합니다.</p>
            <div class="code-block">
<span class="keyword">print</span>(Duck.__mro__)
<span class="comment"># (<class '__main__.Duck'>, <class '__main__.Flyable'>, ...)</span>
            </div>
            
            <h3>super()와 메서드 오버라이드</h3>
            <p><code>super()</code>는 부모 클래스의 메서드를 호출할 때 사용합니다. 자식 클래스에서 부모와 같은 이름의 메서드를 정의하면 <strong>오버라이드(재정의)</strong>되며, 부모의 기능을 확장하려면 <code>super().메서드()</code>를 호출한 후 추가 로직을 작성합니다.</p>
            <div class="code-block">
<span class="keyword">class</span> <span class="function">Animal</span>:
    <span class="keyword">def</span> <span class="function">__init__</span>(self, name):
        self.name = name

    <span class="keyword">def</span> <span class="function">speak</span>(self):
        <span class="keyword">return</span> <span class="string">"소리"</span>

<span class="keyword">class</span> <span class="function">Dog</span>(Animal):
    <span class="keyword">def</span> <span class="function">speak</span>(self):
        <span class="keyword">return</span> <span class="string">f"{self.name}가 멍멍합니다!"</span>

<span class="keyword">class</span> <span class="function">Cat</span>(Animal):
    <span class="keyword">def</span> <span class="function">speak</span>(self):
        <span class="keyword">return</span> <span class="string">f"{self.name}가 야옹합니다!"</span>
            </div>
            
            <h3>특수 메서드 (Dunder Methods)</h3>
            <p>특수 메서드(매직 메서드)는 이름 양쪽에 이중 밑줄(<code>__</code>)이 있어 <strong>던더(Dunder)</strong> 메서드라 불립니다. 연산자 오버로딩(<code>__add__</code>, <code>__eq__</code>), 문자열 표현(<code>__repr__</code>, <code>__str__</code>), 컨테이너 프로토콜(<code>__len__</code>, <code>__getitem__</code>) 등 파이썬의 내장 동작을 커스터마이즈할 수 있습니다.</p>
            <div class="code-block">
<span class="keyword">class</span> <span class="function">Vector</span>:
    <span class="keyword">def</span> <span class="function">__init__</span>(self, x, y):
        self.x = x
        self.y = y
    
    <span class="keyword">def</span> <span class="function">__add__</span>(self, other):
        <span class="keyword">return</span> <span class="function">Vector</span>(self.x + other.x, self.y + other.y)
    
    <span class="keyword">def</span> <span class="function">__repr__</span>(self):
        <span class="keyword">return</span> <span class="string">f"Vector({self.x}, {self.y})"</span>
    
    <span class="keyword">def</span> <span class="function">__len__</span>(self):
        <span class="keyword">return</span> <span class="number">2</span>
    
    <span class="keyword">def</span> <span class="function">__getitem__</span>(self, index):
        <span class="keyword">return</span> [self.x, self.y][index]

v1 = <span class="function">Vector</span>(<span class="number">1</span>, <span class="number">2</span>)
v2 = <span class="function">Vector</span>(<span class="number">3</span>, <span class="number">4</span>)
<span class="keyword">print</span>(v1 + v2)  <span class="comment"># Vector(4, 6)</span>
            </div>
            
            <h3>속성 (Properties)</h3>
            <p><code>@property</code> 데코레이터를 사용하면 메서드를 속성처럼 접근할 수 있으며, <strong>getter/setter/deleter</strong>를 통해 값의 유효성 검증이나 계산된 속성을 구현할 수 있습니다. 이는 Java의 getter/setter 패턴보다 훨씬 파이썬다운(Pythonic) 방식입니다.</p>
            <div class="code-block">
<span class="keyword">class</span> <span class="function">Circle</span>:
    <span class="keyword">def</span> <span class="function">__init__</span>(self, radius):
        self._radius = radius  <span class="comment"># private 속성</span>
    
    <span class="decorator">@property</span>
    <span class="keyword">def</span> <span class="function">radius</span>(self):
        <span class="keyword">return</span> self._radius
    
    <span class="decorator">@radius.setter</span>
    <span class="keyword">def</span> <span class="function">radius</span>(self, value):
        <span class="keyword">if</span> value < <span class="number">0</span>:
            <span class="keyword">raise</span> ValueError(<span class="string">"반지름은 0 이상이어야 합니다"</span>)
        self._radius = value
    
    <span class="decorator">@property</span>
    <span class="keyword">def</span> <span class="function">area</span>(self):
        <span class="keyword">return</span> <span class="number">3.14</span> * self._radius ** <span class="number">2</span>

c = <span class="function">Circle</span>(<span class="number">5</span>)
<span class="keyword">print</span>(c.area)  <span class="comment"># 78.5</span>
c.radius = <span class="number">10</span>
<span class="keyword">print</span>(c.area)  <span class="comment"># 314.0</span>
            </div>
            
            <h3>클래스 변수 vs 인스턴스 변수</h3>
            <p><strong>클래스 변수</strong>는 클래스 본문에 직접 선언되어 모든 인스턴스가 공유하는 변수입니다. <strong>인스턴스 변수</strong>는 <code>self</code>를 통해 선언되어 각 인스턴스마다 독립적인 값을 가집니다. 클래스 변수에 가변 객체(리스트 등)를 사용할 때는 의도치 않은 공유에 주의해야 합니다.</p>
            <div class="code-block">
<span class="keyword">class</span> <span class="function">Dog</span>:
    species = <span class="string">"Canis familiaris"</span>  <span class="comment"># 클래스 변수</span>
    
    <span class="keyword">def</span> <span class="function">__init__</span>(self, name):
        self.name = name  <span class="comment"># 인스턴스 변수</span>

<span class="keyword">print</span>(<span class="function">Dog</span>.species)  <span class="comment"># Canis familiaris</span>
dog1 = <span class="function">Dog</span>(<span class="string">"Max"</span>)
dog2 = <span class="function">Dog</span>(<span class="string">"Buddy"</span>)
<span class="keyword">print</span>(dog1.name, dog2.name)  <span class="comment"># Max Buddy</span>
            </div>
            
            <h3>정적 메서드와 클래스 메서드</h3>
            <p><code>@staticmethod</code>는 인스턴스(<code>self</code>)나 클래스(<code>cls</code>)에 접근하지 않는 유틸리티 함수를 클래스 내에 정의할 때 사용합니다. <code>@classmethod</code>는 첫 번째 인자로 클래스 자체(<code>cls</code>)를 받아 팩토리 메서드나 대안 생성자를 만들 때 활용됩니다.</p>
            <div class="code-block">
<span class="keyword">class</span> <span class="function">MyClass</span>:
    <span class="builtin">value</span> = <span class="number">10</span>
    
    <span class="decorator">@staticmethod</span>
    <span class="keyword">def</span> <span class="function">static_method</span>():
        <span class="keyword">return</span> <span class="string">"정적 메서드"</span>
    
    <span class="decorator">@classmethod</span>
    <span class="keyword">def</span> <span class="function">class_method</span>(cls):
        <span class="keyword">return</span> f<span class="string">"클래스 메서드: {cls.value}"</span>

<span class="keyword">print</span>(<span class="function">MyClass</span>.static_method())  <span class="comment"># 정적 메서드</span>
<span class="keyword">print</span>(<span class="function">MyClass</span>.class_method())   <span class="comment"># 클래스 메서드: 10</span>
            </div>
            
            <h3>Private 멤버 (Encapsulation)</h3>
            <p>파이썬에는 진정한 private 접근 제한이 없지만, 언더스코어 관례로 접근을 제어합니다. <code>_변수</code>는 '내부용'이라는 관례적 표시이고, <code>__변수</code>(이중 밑줄)는 <strong>네임 맹글링(Name Mangling)</strong>이 적용되어 <code>_클래스명__변수</code>로 변환됩니다. 이를 통해 하위 클래스와의 이름 충돌을 방지합니다.</p>
            <div class="code-block">
<span class="keyword">class</span> <span class="function">BankAccount</span>:
    <span class="keyword">def</span> <span class="function">__init__</span>(self, balance):
        self.__balance = balance  <span class="comment"># name mangling: _BankAccount__balance</span>
    
    <span class="decorator">@property</span>
    <span class="keyword">def</span> <span class="function">balance</span>(self):
        <span class="keyword">return</span> self.__balance
    
    <span class="keyword">def</span> <span class="function">deposit</span>(self, amount):
        <span class="keyword">if</span> amount > <span class="number">0</span>:
            self.__balance += amount
    
    <span class="keyword">def</span> <span class="function">withdraw</span>(self, amount):
        <span class="keyword">if</span> amount <= self.__balance:
            self.__balance -= amount
            <span class="keyword">return</span> <span class="keyword">True</span>
        <span class="keyword">return</span> <span class="keyword">False</span>

account = <span class="function">BankAccount</span>(<span class="number">1000</span>)
<span class="comment"># account.__balance  # 오류!</span>
<span class="keyword">print</span>(account.balance)  <span class="comment"># 1000</span>
            </div>
            
            <div class="svg-container">
                <!-- OOP Inheritance SVG -->
                <svg width="600" height="250" viewBox="0 0 600 250" xmlns="http://www.w3.org/2000/svg">
                    <!-- Parent Class -->
                    <rect x="225" y="20" width="150" height="60" rx="10" fill="#667eea"/>
                    <text x="300" y="55" text-anchor="middle" fill="white" font-weight="bold">Animal (부모)</text>

                    <!-- Vertical line from parent to branch -->
                    <line x1="300" y1="80" x2="300" y2="115" stroke="var(--text-secondary)" stroke-width="2"/>
                    <!-- Horizontal branch line -->
                    <line x1="140" y1="115" x2="460" y2="115" stroke="var(--text-secondary)" stroke-width="2"/>
                    <!-- Left drop to Cat -->
                    <line x1="140" y1="115" x2="140" y2="140" stroke="var(--text-secondary)" stroke-width="2"/>
                    <!-- Right drop to Dog -->
                    <line x1="460" y1="115" x2="460" y2="140" stroke="var(--text-secondary)" stroke-width="2"/>

                    <!-- Child Classes -->
                    <rect x="80" y="140" width="120" height="80" rx="10" fill="var(--svg-green)" stroke="#4CAF50" stroke-width="3"/>
                    <text x="140" y="170" text-anchor="middle" fill="var(--svg-green-text)" font-weight="bold">Cat (자식)</text>
                    <text x="140" y="195" text-anchor="middle" fill="var(--text-secondary)" font-size="12">speak()_override</text>

                    <rect x="400" y="140" width="120" height="80" rx="10" fill="var(--svg-orange)" stroke="#ff9800" stroke-width="3"/>
                    <text x="460" y="170" text-anchor="middle" fill="var(--svg-orange-text)" font-weight="bold">Dog (자식)</text>
                    <text x="460" y="195" text-anchor="middle" fill="var(--text-secondary)" font-size="12">speak()_override</text>
                </svg>
            </div>
            <h3>Type Hints (타입 힌트)</h3>
            <p>Python 3.5에서 도입된 타입 힌트는 함수와 변수의 예상 타입을 <strong>명시적으로 선언</strong>합니다. 런타임에 강제되지 않지만, IDE의 자동완성 지원, <code>mypy</code>를 통한 정적 타입 검사, 코드 문서화 역할을 합니다. <code>typing</code> 모듈의 <code>List</code>, <code>Dict</code>, <code>Optional</code>, <code>Union</code> 등으로 복잡한 타입을 표현할 수 있습니다.</p>
            
            <div class="code-block">
<span class="keyword">def</span> <span class="function">greet</span>(name: <span class="builtin">str</span>) -> <span class="builtin">str</span>:
    <span class="keyword">return</span> <span class="string">f"안녕하세요, {name}님!"</span>

<span class="keyword">def</span> <span class="function">add_numbers</span>(a: <span class="builtin">int</span>, b: <span class="builtin">int</span>) -> <span class="builtin">int</span>:
    <span class="keyword">return</span> a + b

<span class="comment"># 복잡한 타입</span>
<span class="keyword">from</span> typing <span class="keyword">import</span> List, Dict, Optional

<span class="keyword">def</span> <span class="function">process_data</span>(
    items: List[<span class="builtin">int</span>], 
    config: Optional[Dict[<span class="builtin">str</span>, <span class="builtin">str</span>]] = None
) -> Dict[<span class="builtin">str</span>, <span class="builtin">int</span>]:
    <span class="keyword">return</span> {<span class="string">"sum"</span>: <span class="builtin">sum</span>(items), <span class="string">"count"</span>: <span class="builtin">len</span>(items)}
            </div>
            
            <h3>Data Classes</h3>
            <p>Python 3.7에서 도입된 <code>@dataclass</code> 데코레이터는 <code>__init__</code>, <code>__repr__</code>, <code>__eq__</code> 등을 <strong>자동 생성</strong>하여 데이터 저장용 클래스를 간결하게 정의합니다. <code>field()</code>로 기본값, 비교 제외 등 세밀한 설정이 가능하며, <code>frozen=True</code> 옵션으로 불변 데이터 클래스를 만들 수 있습니다.</p>
            
            <div class="code-block">
<span class="keyword">from</span> dataclasses <span class="keyword">import</span> dataclass, field

<span class="decorator">@dataclass</span>
<span class="keyword">class</span> <span class="function">User</span>:
    name: <span class="builtin">str</span>
    age: <span class="builtin">int</span>
    email: <span class="builtin">str</span> = <span class="string">"unknown@example.com"</span>
    active: <span class="builtin">bool</span> = field(default=<span class="keyword">True</span>)

<span class="comment"># 사용</span>
user = <span class="function">User</span>(<span class="string">"민준"</span>, <span class="number">25</span>)
<span class="keyword">print</span>(user)  <span class="comment"># User(name='민준', age=25, ...)</span>
            </div>
            
            <h3>NamedTuple</h3>
            <p>NamedTuple은 일반 튜플의 불변성과 인덱스 접근을 유지하면서, 필드에 <strong>이름으로 접근</strong>할 수 있는 자료형입니다. 간단한 데이터 레코드를 표현할 때 유용하며, 메모리 효율이 딕셔너리보다 좋습니다. <code>typing.NamedTuple</code>을 사용하면 타입 힌트도 추가할 수 있습니다.</p>
            
            <div class="code-block">
<span class="keyword">from</span> collections <span class="keyword">import</span> namedtuple

Point = namedtuple(<span class="string">"Point"</span>, [<span class="string">"x"</span>, <span class="string">"y"</span>])
p = Point(<span class="number">10</span>, <span class="number">20</span>)
<span class="keyword">print</span>(p.x, p.y)  <span class="comment"># 10 20</span>
<span class="keyword">print</span>(p[<span class="number">0</span>], p[<span class="number">1</span>])  <span class="comment"># 10 20</span>
            </div>
            
            <h3>Enum (열거형)</h3>
            <p>Enum은 관련된 상수들을 하나의 클래스로 그룹화하여 <strong>타입 안전한 상수 집합</strong>을 만듭니다. 매직 넘버 대신 의미 있는 이름을 사용하여 코드 가독성을 높이고, 잘못된 값 사용을 방지합니다. <code>auto()</code>로 값을 자동 할당할 수도 있습니다.</p>
            <div class="code-block">
<span class="keyword">from</span> enum <span class="keyword">import</span> Enum, auto

<span class="keyword">class</span> <span class="function">Color</span>(Enum):
    RED = <span class="number">1</span>
    GREEN = <span class="number">2</span>
    BLUE = <span class="number">3</span>

<span class="keyword">print</span>(Color.RED)  <span class="comment"># Color.RED</span>
<span class="keyword">print</span>(Color.RED.name)  <span class="comment"># RED</span>
<span class="keyword">print</span>(Color.RED.value)  <span class="comment"># 1</span>
            </div>
            
            <h3>ABC (추상 베이스 클래스)</h3>
            <p>추상 베이스 클래스(ABC)는 <code>@abstractmethod</code>로 선언된 메서드를 반드시 구현하도록 <strong>계약(contract)을 강제</strong>합니다. ABC를 직접 인스턴스화하면 에러가 발생하며, 상속받은 클래스가 추상 메서드를 구현하지 않으면 역시 인스턴스화할 수 없습니다. 인터페이스 역할을 합니다.</p>
            <div class="code-block">
<span class="keyword">from</span> abc <span class="keyword">import</span> ABC, abstractmethod

<span class="keyword">class</span> <span class="function">Shape</span>(ABC):
    <span class="decorator">@abstractmethod</span>
    <span class="keyword">def</span> <span class="function">area</span>(self):
        <span class="keyword">pass</span>

<span class="keyword">class</span> <span class="function">Circle</span>(Shape):
    <span class="keyword">def</span> <span class="function">__init__</span>(self, radius):
        self.radius = radius
    
    <span class="keyword">def</span> <span class="function">area</span>(self):
        <span class="keyword">return</span> <span class="number">3.14</span> * self.radius ** <span class="number">2</span>
            </div>
            
            <h3>Protocol (구조적 타이핑)</h3>
            <p>Python 3.8에서 도입된 <code>Protocol</code>은 ABC와 달리 <strong>명시적 상속 없이</strong> 특정 메서드/속성을 가진 객체를 타입으로 인식합니다. 이를 <strong>구조적 타이핑(Structural Typing)</strong> 또는 <strong>덕 타이핑(Duck Typing)</strong>의 정적 버전이라 합니다. Go 언어의 인터페이스와 유사한 개념입니다.</p>
            <div class="code-block">
<span class="keyword">from</span> typing <span class="keyword">import</span> Protocol

<span class="keyword">class</span> <span class="function">Drawable</span>(Protocol):
    <span class="keyword">def</span> <span class="function">draw</span>(self) -> <span class="builtin">str</span>: ...

<span class="keyword">class</span> <span class="function">Circle</span>:
    <span class="keyword">def</span> <span class="function">draw</span>(self) -> <span class="builtin">str</span>:
        <span class="keyword">return</span> <span class="string">"Circle drawn"</span>

<span class="comment"># 타입 체크에서 Drawable로 처리됨</span>
<span class="keyword">def</span> <span class="function">render</span>(shape: Drawable) -> <span class="builtin">None</span>:
    <span class="keyword">print</span>(shape.draw())
            </div>
            
            <div class="svg-container">
                <!-- OOP 고급 개념 마인드맵 SVG -->
                <svg width="700" height="300" viewBox="0 0 700 300" xmlns="http://www.w3.org/2000/svg">
                    <!-- Center -->
                    <circle cx="350" cy="150" r="50" fill="#667eea"/>
                    <text x="350" y="145" text-anchor="middle" fill="white" font-weight="bold" font-size="13">OOP</text>
                    <text x="350" y="163" text-anchor="middle" fill="rgba(255,255,255,0.8)" font-size="11">고급 개념</text>

                    <!-- 메타클래스 -->
                    <rect x="50" y="40" width="130" height="55" rx="10" fill="var(--svg-blue)" stroke="#2196F3" stroke-width="2"/>
                    <text x="115" y="65" text-anchor="middle" fill="var(--svg-blue-text)" font-weight="bold" font-size="12">메타클래스</text>
                    <text x="115" y="82" text-anchor="middle" fill="var(--text-secondary)" font-size="10">type, __new__</text>
                    <line x1="180" y1="68" x2="300" y2="135" stroke="#667eea" stroke-width="1.5"/>

                    <!-- 디스크립터 -->
                    <rect x="50" y="210" width="130" height="55" rx="10" fill="var(--svg-green)" stroke="#4CAF50" stroke-width="2"/>
                    <text x="115" y="235" text-anchor="middle" fill="var(--svg-green-text)" font-weight="bold" font-size="12">디스크립터</text>
                    <text x="115" y="252" text-anchor="middle" fill="var(--text-secondary)" font-size="10">__get__, __set__</text>
                    <line x1="180" y1="238" x2="300" y2="170" stroke="#667eea" stroke-width="1.5"/>

                    <!-- MRO / 다중상속 -->
                    <rect x="520" y="40" width="150" height="55" rx="10" fill="var(--svg-orange)" stroke="#ff9800" stroke-width="2"/>
                    <text x="595" y="65" text-anchor="middle" fill="var(--svg-orange-text)" font-weight="bold" font-size="12">다중상속 / MRO</text>
                    <text x="595" y="82" text-anchor="middle" fill="var(--text-secondary)" font-size="10">C3 선형화</text>
                    <line x1="520" y1="68" x2="400" y2="135" stroke="#667eea" stroke-width="1.5"/>

                    <!-- ABC / Protocol -->
                    <rect x="520" y="210" width="150" height="55" rx="10" fill="var(--svg-pink)" stroke="#e91e63" stroke-width="2"/>
                    <text x="595" y="235" text-anchor="middle" fill="var(--svg-pink-text)" font-weight="bold" font-size="12">ABC / Protocol</text>
                    <text x="595" y="252" text-anchor="middle" fill="var(--text-secondary)" font-size="10">추상화, 덕 타이핑</text>
                    <line x1="520" y1="238" x2="400" y2="170" stroke="#667eea" stroke-width="1.5"/>
                </svg>
            </div>

            <div class="level-guide beginner">
                <div class="level-guide-header">초급자 가이드 - 클래스를 왜, 언제 사용할까?</div>
                <div class="level-guide-content">
                    <p>클래스는 처음에 어렵게 느껴질 수 있지만, 핵심은 간단합니다:</p>
                    <ul>
                        <li><strong>클래스 = 붕어빵 틀</strong>: 틀(클래스)로 붕어빵(객체)을 찍어냅니다. 틀 하나로 여러 개의 붕어빵을 만들 수 있습니다.</li>
                        <li><strong>언제 클래스를 만드나?</strong>: 관련된 데이터(속성)와 기능(메서드)을 하나로 묶고 싶을 때입니다. 예: "학생" 데이터(이름, 성적)와 기능(성적 계산, 학년 올리기).</li>
                        <li><strong>self란?</strong>: 클래스 안에서 "나 자신"을 가리키는 참조입니다. <code>self.name</code>은 "이 객체의 이름"이라는 뜻입니다.</li>
                        <li><strong>__init__이란?</strong>: 객체가 생성될 때 자동으로 호출되는 초기화 함수입니다. 생성자(constructor)라고도 합니다.</li>
                    </ul>
                    <p><strong>팁:</strong> 처음에는 클래스 없이 함수만으로 프로그래밍해도 됩니다. 코드가 복잡해지고 관련 데이터와 함수가 많아질 때 클래스 도입을 고려하세요.</p>
                </div>
            </div>

            <div class="level-guide intermediate">
                <div class="level-guide-header">중급자 가이드 - OOP 설계 원칙(SOLID)</div>
                <div class="level-guide-content">
                    <p>유지보수 가능한 코드를 위한 SOLID 원칙:</p>
                    <ul>
                        <li><strong>S - 단일 책임(SRP)</strong>: 클래스는 하나의 이유로만 변경되어야 합니다. "사용자 인증"과 "이메일 전송"을 같은 클래스에 넣지 마세요.</li>
                        <li><strong>O - 개방-폐쇄(OCP)</strong>: 확장에는 열려있고, 수정에는 닫혀있어야 합니다. 새 기능 추가 시 기존 코드를 수정하지 않고 상속/합성으로 확장하세요.</li>
                        <li><strong>L - 리스코프 치환(LSP)</strong>: 자식 클래스는 부모 클래스를 대체할 수 있어야 합니다.</li>
                        <li><strong>I - 인터페이스 분리(ISP)</strong>: 사용하지 않는 메서드에 의존하지 않도록 인터페이스를 분리하세요.</li>
                        <li><strong>D - 의존성 역전(DIP)</strong>: 구체 클래스가 아닌 추상(ABC/Protocol)에 의존하세요.</li>
                    </ul>
                    <p><strong>실무 팁:</strong> 파이썬에서는 "상속보다 합성(Composition over Inheritance)"을 선호합니다. 다중 상속의 복잡성을 피하고 Mixin 패턴을 활용하세요.</p>
                </div>
            </div>

            <div class="level-guide advanced">
                <div class="level-guide-header">고급자 가이드 - 메타클래스와 디스크립터</div>
                <div class="level-guide-content">
                    <p>파이썬 OOP의 깊은 내부 메커니즘:</p>
                    <ul>
                        <li><strong>메타클래스(Metaclass)</strong>: 클래스의 클래스입니다. <code>class MyMeta(type):</code>로 정의하며, 클래스 생성 과정을 제어합니다. <code>__new__</code>에서 클래스를 생성하고, <code>__init__</code>에서 초기화하며, <code>__init_subclass__</code>는 3.6+에서 더 간단한 대안을 제공합니다.</li>
                        <li><strong>디스크립터(Descriptor)</strong>: <code>__get__</code>, <code>__set__</code>, <code>__delete__</code>를 구현한 객체로, 속성 접근을 가로챕니다. <code>@property</code>, <code>@classmethod</code>, <code>@staticmethod</code>가 모두 디스크립터로 구현되어 있습니다.</li>
                        <li><strong>__new__ vs __init__</strong>: <code>__new__</code>는 인스턴스를 생성(메모리 할당)하고, <code>__init__</code>은 생성된 인스턴스를 초기화합니다. 불변 객체(tuple, str 등)를 커스터마이즈할 때 <code>__new__</code>를 오버라이드해야 합니다.</li>
                        <li><strong>__init_subclass__(3.6+)</strong>: 메타클래스 없이 서브클래스 생성을 후킹할 수 있습니다. 플러그인 시스템, 자동 등록 등에 유용합니다.</li>
                        <li><strong>__class_getitem__(3.7+)</strong>: <code>MyClass[int]</code>처럼 클래스를 제네릭하게 사용할 수 있게 해주며, <code>typing.Generic</code>의 기반입니다.</li>
                    </ul>
                </div>
            </div>
        </section>

        <section id="exception">
            <h2>7. 예외 처리 (Exception Handling)</h2>
            <span class="level-badge level-beginner">초급</span>
            <span class="level-badge level-intermediate">중급</span>

            <p>
                예외(Exception)는 프로그램 실행 중 발생하는 오류 상황을 나타내는 객체입니다.
                파이썬의 <strong>예외 처리 메커니즘</strong>을 사용하면 오류가 발생하더라도 프로그램이 비정상적으로 종료되지 않고, 적절한 복구 로직을 수행한 뒤 계속 실행할 수 있습니다.
                파이썬은 <code>ZeroDivisionError</code>, <code>TypeError</code>, <code>ValueError</code>, <code>FileNotFoundError</code> 등 <strong>60개 이상의 내장 예외 클래스</strong>를 제공하며,
                이들은 모두 <code>BaseException</code>을 최상위 부모로 하는 <strong>계층 구조</strong>를 이룹니다.
                <code>try-except-else-finally</code> 구문으로 예외를 처리하고, <code>raise</code>로 의도적으로 예외를 발생시킬 수 있습니다.
            </p>

            <div class="svg-container">
                <!-- 예외 계층 구조 다이어그램 -->
                <svg width="600" height="220" viewBox="0 0 600 220" xmlns="http://www.w3.org/2000/svg">
                    <!-- BaseException -->
                    <rect x="220" y="10" width="160" height="35" rx="8" fill="#9C27B0" stroke="#7B1FA2" stroke-width="2"/>
                    <text x="300" y="33" text-anchor="middle" fill="white" font-weight="bold" font-size="13">BaseException</text>

                    <line x1="300" y1="45" x2="300" y2="65" stroke="var(--text-secondary)" stroke-width="1.5"/>

                    <!-- Exception -->
                    <rect x="220" y="65" width="160" height="35" rx="8" fill="#667eea" stroke="#4a5ae0" stroke-width="2"/>
                    <text x="300" y="88" text-anchor="middle" fill="white" font-weight="bold" font-size="13">Exception</text>

                    <!-- 분기선 -->
                    <line x1="300" y1="100" x2="300" y2="120" stroke="var(--text-secondary)" stroke-width="1.5"/>
                    <line x1="80" y1="120" x2="520" y2="120" stroke="var(--text-secondary)" stroke-width="1.5"/>

                    <!-- ValueError -->
                    <line x1="80" y1="120" x2="80" y2="140" stroke="var(--text-secondary)" stroke-width="1.5"/>
                    <rect x="20" y="140" width="120" height="30" rx="6" fill="var(--svg-orange)" stroke="#ff9800" stroke-width="1.5"/>
                    <text x="80" y="160" text-anchor="middle" fill="var(--svg-orange-text)" font-size="11" font-weight="bold">ValueError</text>

                    <!-- TypeError -->
                    <line x1="190" y1="120" x2="190" y2="140" stroke="var(--text-secondary)" stroke-width="1.5"/>
                    <rect x="130" y="140" width="120" height="30" rx="6" fill="var(--svg-blue)" stroke="#2196F3" stroke-width="1.5"/>
                    <text x="190" y="160" text-anchor="middle" fill="var(--svg-blue-text)" font-size="11" font-weight="bold">TypeError</text>

                    <!-- KeyError -->
                    <line x1="300" y1="120" x2="300" y2="140" stroke="var(--text-secondary)" stroke-width="1.5"/>
                    <rect x="240" y="140" width="120" height="30" rx="6" fill="var(--svg-green)" stroke="#4CAF50" stroke-width="1.5"/>
                    <text x="300" y="160" text-anchor="middle" fill="var(--svg-green-text)" font-size="11" font-weight="bold">KeyError</text>

                    <!-- IOError -->
                    <line x1="410" y1="120" x2="410" y2="140" stroke="var(--text-secondary)" stroke-width="1.5"/>
                    <rect x="350" y="140" width="120" height="30" rx="6" fill="var(--svg-pink)" stroke="#e91e63" stroke-width="1.5"/>
                    <text x="410" y="160" text-anchor="middle" fill="var(--svg-pink-text)" font-size="11" font-weight="bold">OSError</text>

                    <!-- CustomError -->
                    <line x1="520" y1="120" x2="520" y2="140" stroke="var(--text-secondary)" stroke-width="1.5"/>
                    <rect x="460" y="140" width="120" height="30" rx="6" fill="var(--svg-gray)" stroke="var(--border)" stroke-width="1.5"/>
                    <text x="520" y="160" text-anchor="middle" fill="var(--text-secondary)" font-size="11" font-weight="bold">사용자 정의</text>

                    <!-- FileNotFoundError (OSError 하위) -->
                    <line x1="410" y1="170" x2="410" y2="185" stroke="var(--text-secondary)" stroke-width="1"/>
                    <rect x="340" y="185" width="140" height="25" rx="5" fill="var(--svg-pink)" stroke="#e91e63" stroke-width="1"/>
                    <text x="410" y="202" text-anchor="middle" fill="var(--svg-pink-text)" font-size="10">FileNotFoundError</text>
                </svg>
            </div>
            
            <h3>try-except 구조</h3>
            <p><code>try</code> 블록에서 예외가 발생하면 해당 예외 타입과 일치하는 <code>except</code> 블록이 실행됩니다. 예외를 잡지 않으면 프로그램이 비정상 종료됩니다. <code>except Exception as e</code>로 예외 객체를 변수에 바인딩하여 에러 메시지를 확인할 수 있습니다.</p>
            <div class="code-block">
<span class="keyword">try</span>:
    result = <span class="number">10</span> / <span class="number">0</span>
<span class="keyword">except</span> ZeroDivisionError:
    <span class="keyword">print</span>(<span class="string">"0으로 나눌 수 없습니다!"</span>)
            </div>
            
            <h3>여러 예외 처리</h3>
            <p>여러 <code>except</code> 절을 사용하여 예외 타입별로 다른 처리를 할 수 있습니다. <code>else</code> 블록은 예외가 발생하지 않았을 때만 실행되고, <code>finally</code> 블록은 예외 발생 여부와 관계없이 <strong>항상 실행</strong>됩니다. <code>finally</code>는 파일 닫기, 리소스 해제 등 정리 작업에 사용합니다.</p>
            <div class="code-block">
<span class="keyword">try</span>:
    num = <span class="builtin">int</span>(<span class="string">"abc"</span>)
<span class="keyword">except</span> ValueError:
    <span class="keyword">print</span>(<span class="string">"값 오류 발생"</span>)
<span class="keyword">except</span> TypeError:
    <span class="keyword">print</span>(<span class="string">"타입 오류 발생"</span>)
<span class="keyword">finally</span>:
    <span class="keyword">print</span>(<span class="string">"항상 실행"</span>)
            </div>
            
            <h3>사용자 정의 예외</h3>
            <p><code>Exception</code> 클래스를 상속하여 애플리케이션에 맞는 커스텀 예외를 만들 수 있습니다. 도메인별로 예외 계층을 설계하면 호출 코드에서 세밀한 에러 처리가 가능합니다. <code>raise</code> 키워드로 예외를 직접 발생시키며, <code>raise ... from ...</code>으로 예외 체이닝도 가능합니다.</p>
            <div class="code-block">
<span class="keyword">class</span> <span class="function">CustomError</span>(Exception):
    <span class="keyword">def</span> <span class="function">__init__</span>(self, message):
        self.message = message
        <span class="keyword">super</span>().__init__(self.message)

<span class="keyword">raise</span> <span class="function">CustomError</span>(<span class="string">"사용자 정의 오류"</span>)
            </div>
            
            <div class="svg-container">
                <svg width="600" height="200" viewBox="0 0 600 200" xmlns="http://www.w3.org/2000/svg">
                    <!-- try -->
                    <rect x="20" y="30" width="120" height="50" rx="10" fill="#4CAF50"/>
                    <text x="80" y="60" text-anchor="middle" fill="white" font-weight="bold">try 블록</text>

                    <!-- try → triangle -->
                    <line x1="140" y1="55" x2="175" y2="55" stroke="var(--text-secondary)" stroke-width="2"/>

                    <!-- exception check -->
                    <polygon points="175,35 245,35 210,80" fill="#FF9800"/>
                    <text x="210" y="60" text-anchor="middle" fill="white" font-size="11">예외?</text>

                    <!-- triangle → except -->
                    <line x1="245" y1="55" x2="275" y2="55" stroke="#4CAF50" stroke-width="2"/>

                    <!-- except -->
                    <rect x="275" y="30" width="130" height="50" rx="10" fill="#2196F3"/>
                    <text x="340" y="60" text-anchor="middle" fill="white" font-weight="bold">except 블록</text>

                    <!-- except → finally -->
                    <line x1="405" y1="55" x2="440" y2="55" stroke="var(--text-secondary)" stroke-width="2"/>

                    <!-- finally -->
                    <rect x="440" y="30" width="100" height="50" rx="10" fill="#9C27B0"/>
                    <text x="490" y="60" text-anchor="middle" fill="white" font-weight="bold">finally</text>

                    <!-- error path (red) -->
                    <line x1="210" y1="80" x2="210" y2="150" stroke="#f44336" stroke-width="2"/>
                    <line x1="210" y1="150" x2="340" y2="150" stroke="#f44336" stroke-width="2"/>
                </svg>
            </div>

            <div class="level-guide beginner">
                <div class="level-guide-header">초급자 가이드 - 예외 처리가 필요한 이유</div>
                <div class="level-guide-content">
                    <p>프로그램은 예상치 못한 상황에서 멈출 수 있습니다. 예외 처리는 이런 상황을 대비하는 안전장치입니다:</p>
                    <ul>
                        <li><strong>사용자 입력 오류</strong>: 숫자를 입력해야 하는데 문자를 입력하면 <code>ValueError</code>가 발생합니다.</li>
                        <li><strong>파일이 없을 때</strong>: 존재하지 않는 파일을 열려고 하면 <code>FileNotFoundError</code>가 발생합니다.</li>
                        <li><strong>0으로 나누기</strong>: <code>10 / 0</code>은 <code>ZeroDivisionError</code>를 일으킵니다.</li>
                    </ul>
                    <p><strong>핵심 패턴:</strong> "시도(try)해보고, 실패(except)하면 대안을 실행한다"가 기본입니다. 처음에는 <code>try-except</code>만 기억하면 충분합니다!</p>
                    <p><strong>주의:</strong> <code>except:</code>처럼 예외 타입을 지정하지 않으면 모든 예외를 잡아 디버깅이 어려워집니다. 가능하면 구체적인 예외 타입을 명시하세요.</p>
                </div>
            </div>

            <div class="level-guide intermediate">
                <div class="level-guide-header">중급자 가이드 - 예외 처리 모범 사례</div>
                <div class="level-guide-content">
                    <p>실무에서의 예외 처리 가이드라인:</p>
                    <ul>
                        <li><strong>EAFP vs LBYL</strong>: 파이썬은 "허락을 구하기보다 용서를 구하는(EAFP)" 스타일을 선호합니다. <code>if key in dict:</code>(LBYL) 대신 <code>try: dict[key] except KeyError:</code>(EAFP)를 사용하세요.</li>
                        <li><strong>else 블록 활용</strong>: <code>else</code>는 예외가 발생하지 않았을 때만 실행됩니다. try 블록을 최소화하고, 성공 시 로직을 else에 넣으면 어디서 예외가 발생했는지 명확해집니다.</li>
                        <li><strong>예외 체이닝</strong>: <code>raise NewError() from original_error</code>로 원인 예외를 보존합니다. <code>__cause__</code> 속성으로 원인을 추적할 수 있습니다.</li>
                        <li><strong>logging 활용</strong>: 예외 발생 시 <code>logging.exception("메시지")</code>를 사용하면 스택 트레이스가 자동으로 기록됩니다.</li>
                        <li><strong>contextlib.suppress</strong>: 특정 예외를 무시할 때 <code>with suppress(FileNotFoundError): os.remove("temp.txt")</code>가 try-except보다 간결합니다.</li>
                    </ul>
                </div>
            </div>

            <div class="level-guide advanced">
                <div class="level-guide-header">고급자 가이드 - 예외의 내부 구조와 고급 패턴</div>
                <div class="level-guide-content">
                    <p>예외 시스템의 고급 활용법:</p>
                    <ul>
                        <li><strong>ExceptionGroup (3.11+)</strong>: <code>ExceptionGroup</code>으로 여러 예외를 동시에 발생시키고, <code>except*</code> 구문으로 선택적으로 처리할 수 있습니다. 비동기 프로그래밍에서 여러 작업의 예외를 한꺼번에 처리할 때 유용합니다.</li>
                        <li><strong>sys.exc_info()</strong>: 현재 처리 중인 예외의 타입, 값, 트레이스백을 튜플로 반환합니다. 예외 정보를 세밀하게 조작하거나 로깅할 때 사용합니다.</li>
                        <li><strong>traceback 모듈</strong>: <code>traceback.format_exc()</code>로 스택 트레이스를 문자열로 얻고, <code>traceback.print_exc()</code>로 출력합니다. 커스텀 에러 리포팅에 활용됩니다.</li>
                        <li><strong>예외 계층 설계</strong>: 라이브러리를 설계할 때 기본 예외 클래스를 만들고(<code>class MyLibError(Exception)</code>), 세부 예외를 파생시킵니다. 사용자가 <code>except MyLibError:</code>로 모든 라이브러리 예외를 잡을 수 있습니다.</li>
                        <li><strong>__traceback__ 관리</strong>: 예외 객체의 <code>__traceback__</code> 속성은 트레이스백 객체를 참조합니다. 메모리 누수를 방지하려면 <code>del e.__traceback__</code> 또는 <code>raise e from None</code>을 사용하세요.</li>
                    </ul>
                </div>
            </div>
        </section>

        <section id="modules">
            <h2>8. 모듈과 패키지 (Modules & Packages)</h2>
            <span class="level-badge level-beginner">초급</span>
            <span class="level-badge level-intermediate">중급</span>

            <p>
                <strong>모듈(Module)</strong>은 파이썬 코드(함수, 클래스, 변수 등)가 담긴 <code>.py</code> 파일 하나를 의미합니다.
                <strong>패키지(Package)</strong>는 관련 모듈들을 디렉터리 구조로 묶어 체계적으로 관리하는 방법입니다.
                파이썬은 <strong>"배터리 포함(Batteries Included)"</strong> 철학에 따라 <code>os</code>, <code>sys</code>, <code>json</code>, <code>datetime</code>, <code>pathlib</code> 등
                300개 이상의 표준 라이브러리 모듈을 제공하며, <strong>PyPI(Python Package Index)</strong>를 통해 50만 개 이상의 서드파티 패키지를 <code>pip</code>로 쉽게 설치할 수 있습니다.
                이러한 방대한 생태계가 파이썬의 강력한 경쟁력입니다.
            </p>
            
            <h3>모듈 가져오기</h3>
            <p><code>import</code> 문으로 모듈을 가져옵니다. <code>import 모듈</code>은 전체 모듈을 가져오고, <code>from 모듈 import 함수</code>는 특정 항목만 가져옵니다. <code>as</code>를 사용하면 별칭을 지정할 수 있어 코드를 간결하게 만듭니다. <code>from 모듈 import *</code>는 이름 충돌 위험이 있으므로 일반적으로 권장되지 않습니다.</p>
            <div class="code-block">
<span class="comment"># 전체 모듈 가져오기</span>
<span class="keyword">import</span> math

<span class="keyword">print</span>(math.pi)        <span class="comment"># 3.141592653589793</span>
<span class="keyword">print</span>(math.<span class="function">sqrt</span>(<span class="number">16</span>))  <span class="comment"># 4.0</span>

<span class="comment"># 특정 함수만 가져오기</span>
<span class="keyword">from</span> math <span class="keyword">import</span> pi, sqrt

<span class="keyword">print</span>(<span class="function">sqrt</span>(<span class="number">25</span>))  <span class="comment"># 5.0</span>

<span class="comment"># 별칭 사용</span>
<span class="keyword">import</span> numpy <span class="keyword">as</span> np
<span class="keyword">import</span> pandas <span class="keyword">as</span> pd
            </div>
            
            <h3>표준 라이브러리 모듈</h3>
            <p>파이썬은 "배터리 포함(Batteries Included)" 철학에 따라 방대한 <strong>표준 라이브러리</strong>를 제공합니다. 별도 설치 없이 바로 사용할 수 있는 주요 모듈들입니다.</p>
            <div class="feature-grid">
                <div class="feature-card">
                    <h4>📅 datetime</h4>
                    <p>날짜와 시간 처리</p>
                </div>
                <div class="feature-card">
                    <h4>🔢 random</h4>
                    <p>랜덤 숫자 생성</p>
                </div>
                <div class="feature-card">
                    <h4>📊 json</h4>
                    <p>JSON 데이터 처리</p>
                </div>
                <div class="feature-card">
                    <h4>🌐 urllib</h4>
                    <p>네트워크 요청</p>
                </div>
            </div>
            
            <h3>주요 내장 함수 (Built-in Functions)</h3>
            <p>파이썬은 별도 import 없이 어디서든 사용 가능한 <strong>내장 함수(built-in functions)</strong>를 약 70개 이상 제공합니다. 데이터 변환, 입출력, 반복 처리 등 프로그래밍의 기본 작업을 담당하는 핵심 도구입니다.</p>
            <table class="comparison-table">
                <tr><th>함수</th><th>설명</th></tr>
                <tr><td>print()</td><td>출력</td></tr>
                <tr><td>input()</td><td>입력</td></tr>
                <tr><td>len()</td><td>길이</td></tr>
                <tr><td>range()</td><td>범위 생성</td></tr>
                <tr><td>enumerate()</td><td>인덱스와 값</td></tr>
                <tr><td>zip()</td><td>여러 시퀀스 병합</td></tr>
                <tr><td>map()</td><td>함수 적용</td></tr>
                <tr><td>filter()</td><td>조건 필터링</td></tr>
                <tr><td>sorted()</td><td>정렬</td></tr>
                <tr><td>reversed()</td><td>역순</td></tr>
                <tr><td>sum(), min(), max()</td><td>합계, 최소, 최대</td></tr>
                <tr><td>abs()</td><td>절대값</td></tr>
                <tr><td>round()</td><td>반올림</td></tr>
                <tr><td>type()</td><td>타입 확인</td></tr>
                <tr><td>isinstance()</td><td>타입 확인</td></tr>
                <tr><td>dir()</td><td>속성 목록</td></tr>
                <tr><td>help()</td><td>도움말</td></tr>
            </table>
            
            <h3>사용자 정의 모듈</h3>
            <p>모든 <code>.py</code> 파일은 모듈로 사용할 수 있습니다. 다른 파일에서 <code>import</code>하면 해당 파일의 함수, 클래스, 변수를 사용할 수 있습니다. <code>if __name__ == "__main__":</code> 구문을 사용하면 모듈이 직접 실행될 때만 특정 코드가 실행되도록 할 수 있습니다.</p>
            <div class="code-block">
<span class="comment"># mymodule.py</span>
<span class="keyword">def</span> <span class="function">greet</span>(name):
    <span class="keyword">return</span> <span class="string">f"안녕하세요, {name}!"</span>

<span class="comment"># main.py</span>
<span class="keyword">import</span> mymodule

<span class="keyword">print</span>(mymodule.<span class="function">greet</span>(<span class="string">"민준"</span>))
            </div>
            
            <h3>패키지 설치 (pip)</h3>
            <p><code>pip</code>는 파이썬의 공식 패키지 관리자로, <strong>PyPI(Python Package Index)</strong>에서 30만 개 이상의 패키지를 설치할 수 있습니다. <code>requirements.txt</code> 파일로 프로젝트의 의존성을 관리하며, <code>pip freeze > requirements.txt</code>로 현재 설치된 패키지 목록을 내보낼 수 있습니다.</p>
            <div class="code-block">
<span class="comment"># 패키지 설치</span>
pip install numpy pandas matplotlib

<span class="comment"># 특정 버전</span>
pip install numpy==1.24.0

<span class="comment">#requirements.txt 사용</span>
pip install -r requirements.txt

<span class="comment"># 패키지 목록</span>
pip list

<span class="comment"># 패키지 검색</span>
pip search "keyword"

<span class="comment"># 패키지 제거</span>
pip uninstall package_name
            </div>
            
            <h3>가상 환경 (Virtual Environment)</h3>
            <p>가상 환경은 프로젝트마다 <strong>독립된 파이썬 패키지 공간</strong>을 만들어 의존성 충돌을 방지합니다. 프로젝트 A가 Django 3.x, 프로젝트 B가 Django 4.x를 사용하더라도 각각의 가상 환경에서 충돌 없이 실행할 수 있습니다. <code>venv</code>는 파이썬 3.3부터 표준 라이브러리에 포함되어 있습니다.</p>
            <div class="code-block">
<span class="comment"># venv 생성</span>
python -m venv myenv

<span class="comment"># 활성화 (Windows)</span>
myenv\Scripts\activate

<span class="comment"># 활성화 (Linux/Mac)</span>
source myenv/bin/activate

<span class="comment"># 비활성화</span>
deactivate
            </div>
            
            <h3>주요 표준 라이브러리</h3>
            <p>파이썬의 표준 라이브러리는 시스템 상호작용, 병렬 처리, 파일 관리, 로깅 등 실무에서 자주 필요한 기능을 포괄합니다. 다음은 가장 많이 사용되는 표준 라이브러리 모듈입니다.</p>
            <div class="feature-grid">
                <div class="feature-card">
                    <h4>sys</h4>
                    <p>시스템 매개변수 및 함수. 인터프리터와 직접 상호작용합니다.</p>
                </div>
                <div class="feature-card">
                    <h4>os</h4>
                    <p>운영체제 상호작용</p>
                </div>
                <div class="feature-card">
                    <h4>subprocess</h4>
                    <p>프로세스 실행</p>
                </div>
                <div class="feature-card">
                    <h4>threading</h4>
                    <p>스레드 기반 병렬처리</p>
                </div>
                <div class="feature-card">
                    <h4>multiprocessing</h4>
                    <p>프로세스 기반 병렬처리</p>
                </div>
                <div class="feature-card">
                    <h4>pathlib</h4>
                    <p>경로 객체 지향 처리</p>
                </div>
                <div class="feature-card">
                    <h4>argparse</h4>
                    <p>명령행 인자 파싱</p>
                </div>
                <div class="feature-card">
                    <h4>logging</h4>
                    <p>로깅 프레임워크</p>
                </div>
                <div class="feature-card">
                    <h4>tempfile</h4>
                    <p>임시 파일/디렉토리</p>
                </div>
                <div class="feature-card">
                    <h4>shutil</h4>
                    <p>고수준 파일 operations</p>
                </div>
            </div>
            
            <div class="svg-container">
                <svg width="600" height="180" viewBox="0 0 600 180" xmlns="http://www.w3.org/2000/svg">
                    <rect x="50" y="50" width="150" height="80" rx="10" fill="var(--svg-blue)" stroke="#2196F3" stroke-width="2"/>
                    <text x="125" y="80" text-anchor="middle" font-weight="bold" fill="var(--text-primary)">mypackage/</text>
                    <text x="125" y="105" text-anchor="middle" fill="var(--text-secondary)" font-size="12">패키지 폴더</text>

                    <rect x="220" y="20" width="120" height="40" rx="5" fill="var(--svg-green)" stroke="#4CAF50"/>
                    <text x="280" y="45" text-anchor="middle" fill="var(--text-primary)">__init__.py</text>

                    <rect x="220" y="70" width="120" height="40" rx="5" fill="var(--svg-orange)" stroke="#ff9800"/>
                    <text x="280" y="95" text-anchor="middle" fill="var(--text-primary)">module1.py</text>

                    <rect x="220" y="120" width="120" height="40" rx="5" fill="var(--svg-pink)" stroke="#e91e63"/>
                    <text x="280" y="145" text-anchor="middle" fill="var(--text-primary)">module2.py</text>

                    <line x1="170" y1="90" x2="220" y2="40" stroke="#667eea" stroke-width="2"/>
                    <line x1="170" y1="90" x2="220" y2="90" stroke="#667eea" stroke-width="2"/>
                    <line x1="170" y1="90" x2="220" y2="140" stroke="#667eea" stroke-width="2"/>
                </svg>
            </div>

            <div class="level-guide beginner">
                <div class="level-guide-header">초급자 가이드 - 모듈과 패키지를 쉽게 이해하기</div>
                <div class="level-guide-content">
                    <p>모듈과 패키지를 일상에 비유하면:</p>
                    <ul>
                        <li><strong>모듈 = 도구 상자</strong>: 다른 사람이 만든 기능(도구)을 가져다 쓰는 것입니다. <code>import math</code>하면 수학 관련 함수들을 모두 사용할 수 있습니다.</li>
                        <li><strong>pip = 앱 스토어</strong>: 전 세계 개발자들이 만든 패키지를 무료로 설치할 수 있는 저장소입니다.</li>
                        <li><strong>가상 환경 = 작업 폴더</strong>: 프로젝트마다 독립된 공간을 만들어 패키지 버전 충돌을 방지합니다.</li>
                    </ul>
                    <p><strong>if __name__ == "__main__": 이해하기</strong>: 이 코드는 "이 파일이 직접 실행될 때만 아래 코드를 실행해라"라는 뜻입니다. 다른 파일에서 import할 때는 실행되지 않습니다. 모든 스크립트의 실행 진입점에 사용합니다.</p>
                </div>
            </div>

            <div class="level-guide intermediate">
                <div class="level-guide-header">중급자 가이드 - 프로젝트 구조와 의존성 관리</div>
                <div class="level-guide-content">
                    <p>실무 프로젝트의 구조와 의존성 관리 전략:</p>
                    <ul>
                        <li><strong>프로젝트 레이아웃</strong>: <code>src/</code> 레이아웃이 모범 사례입니다. <code>src/mypackage/</code>에 소스코드를, <code>tests/</code>에 테스트를, 루트에 <code>pyproject.toml</code>을 배치합니다.</li>
                        <li><strong>pyproject.toml</strong>: PEP 517/518에 따라 <code>setup.py</code>를 대체하는 현대적 프로젝트 설정 파일입니다. 빌드 시스템, 의존성, 도구 설정을 하나의 파일에 통합합니다.</li>
                        <li><strong>의존성 관리 도구</strong>: <code>pip + requirements.txt</code>가 기본이지만, <code>poetry</code>는 의존성 해결과 패키징을 통합하고, <code>uv</code>는 Rust로 작성되어 초고속 설치를 제공합니다.</li>
                        <li><strong>상대 vs 절대 import</strong>: 패키지 내에서 <code>from . import module</code>(상대 import)을 사용하면 패키지 이름 변경 시에도 안전합니다. 실행 스크립트에서는 절대 import를 사용합니다.</li>
                    </ul>
                </div>
            </div>

            <div class="level-guide advanced">
                <div class="level-guide-header">고급자 가이드 - import 시스템의 내부 동작</div>
                <div class="level-guide-content">
                    <p>파이썬 import 시스템의 내부 메커니즘:</p>
                    <ul>
                        <li><strong>import 과정</strong>: (1) <code>sys.modules</code> 캐시 확인 → (2) <code>sys.meta_path</code>의 finder 검색 → (3) <code>sys.path</code> 경로에서 모듈 찾기 → (4) 모듈 로딩 및 실행 → (5) <code>sys.modules</code>에 캐싱</li>
                        <li><strong>커스텀 Importer</strong>: <code>importlib.abc.MetaPathFinder</code>와 <code>importlib.abc.Loader</code>를 구현하면 데이터베이스, 네트워크, ZIP 파일 등에서 모듈을 로드할 수 있습니다.</li>
                        <li><strong>순환 import</strong>: A가 B를 import하고 B가 A를 import하면 순환 참조가 발생합니다. 해결법: (1) import를 함수 내부로 이동, (2) 공통 모듈 분리, (3) 구조 재설계</li>
                        <li><strong>__all__</strong>: 모듈에 <code>__all__ = ["func1", "Class1"]</code>을 정의하면 <code>from module import *</code>에서 내보낼 항목을 제한합니다.</li>
                        <li><strong>namespace package</strong>: <code>__init__.py</code> 없이도 패키지를 만들 수 있습니다(PEP 420). 여러 디렉토리에 분산된 패키지를 하나로 합칠 때 사용합니다.</li>
                    </ul>
                </div>
            </div>
        </section>

        <section id="fileio">
            <h2>9. 파일 입출력 (File I/O)</h2>
            <span class="level-badge level-beginner">초급</span>
            <span class="level-badge level-intermediate">중급</span>

            <p>
                파일 입출력(File I/O)은 프로그램의 데이터를 <strong>디스크에 영구적으로 저장</strong>하고, 저장된 데이터를 <strong>다시 읽어오는</strong> 핵심 기능입니다.
                프로그램이 종료되면 메모리의 데이터는 사라지지만, 파일에 기록한 데이터는 유지됩니다.
                파이썬은 <code>open()</code> 내장 함수와 <code>with</code> 컨텍스트 매니저를 통해 안전하고 간결한 파일 처리를 지원하며,
                텍스트 파일뿐 아니라 JSON, CSV, 바이너리 파일, pickle 직렬화 등 다양한 형식을 다룰 수 있습니다.
                Python 3.4 이후에는 <code>pathlib</code> 모듈로 경로를 객체 지향적으로 다루는 방법도 제공합니다.
            </p>

            <div class="svg-container">
                <!-- 파일 입출력 흐름 다이어그램 -->
                <svg width="650" height="200" viewBox="0 0 650 200" xmlns="http://www.w3.org/2000/svg">
                    <defs>
                        <marker id="arrow-fileio" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                            <polygon points="0 0, 10 3.5, 0 7" fill="#667eea"/>
                        </marker>
                    </defs>

                    <!-- Python 프로그램 -->
                    <rect x="20" y="55" width="130" height="70" rx="12" fill="#667eea" stroke="#4a5ae0" stroke-width="2"/>
                    <text x="85" y="85" text-anchor="middle" fill="white" font-weight="bold" font-size="13">Python</text>
                    <text x="85" y="105" text-anchor="middle" fill="rgba(255,255,255,0.8)" font-size="11">프로그램</text>

                    <!-- 쓰기 화살표 -->
                    <line x1="150" y1="75" x2="225" y2="75" stroke="#4CAF50" stroke-width="2.5" marker-end="url(#arrow-fileio)"/>
                    <text x="188" y="67" text-anchor="middle" fill="#4CAF50" font-size="11" font-weight="bold">write</text>

                    <!-- 읽기 화살표 -->
                    <line x1="225" y1="110" x2="150" y2="110" stroke="#2196F3" stroke-width="2.5" marker-end="url(#arrow-fileio)"/>
                    <text x="188" y="130" text-anchor="middle" fill="#2196F3" font-size="11" font-weight="bold">read</text>

                    <!-- open() 함수 박스 -->
                    <rect x="230" y="55" width="110" height="70" rx="10" fill="var(--svg-orange)" stroke="#ff9800" stroke-width="2"/>
                    <text x="285" y="85" text-anchor="middle" fill="var(--svg-orange-text)" font-weight="bold" font-size="13">open()</text>
                    <text x="285" y="105" text-anchor="middle" fill="var(--text-secondary)" font-size="10">파일 핸들러</text>

                    <!-- 화살표 to 파일 -->
                    <line x1="340" y1="90" x2="395" y2="90" stroke="var(--text-secondary)" stroke-width="2" marker-end="url(#arrow-fileio)"/>

                    <!-- 파일 아이콘 형태 -->
                    <path d="M405,40 L470,40 L500,65 L500,140 Q500,145 495,145 L405,145 Q400,145 400,140 L400,45 Q400,40 405,40 Z" fill="var(--svg-blue)" stroke="#2196F3" stroke-width="2"/>
                    <path d="M470,40 L470,60 Q470,65 475,65 L500,65" fill="var(--svg-blue)" stroke="#2196F3" stroke-width="1.5"/>
                    <text x="450" y="85" text-anchor="middle" fill="var(--svg-blue-text)" font-weight="bold" font-size="13">파일</text>
                    <text x="450" y="105" text-anchor="middle" fill="var(--text-secondary)" font-size="10">.txt .json</text>
                    <text x="450" y="120" text-anchor="middle" fill="var(--text-secondary)" font-size="10">.csv .pkl</text>

                    <!-- with문 설명 -->
                    <rect x="530" y="60" width="100" height="55" rx="8" fill="var(--svg-green)" stroke="#4CAF50" stroke-width="1.5"/>
                    <text x="580" y="82" text-anchor="middle" fill="var(--svg-green-text)" font-weight="bold" font-size="11">with 문</text>
                    <text x="580" y="100" text-anchor="middle" fill="var(--text-secondary)" font-size="10">자동 close()</text>

                    <!-- 레이블 -->
                    <text x="325" y="175" text-anchor="middle" fill="var(--text-muted)" font-size="12">파일은 열기(open) → 읽기/쓰기 → 닫기(close) 순서로 처리</text>
                </svg>
            </div>
            
            <h3>파일 읽기</h3>
            <p>파일 읽기는 <code>open()</code> 함수로 파일을 열고 <code>read()</code>, <code>readline()</code>, <code>readlines()</code> 메서드로 내용을 가져옵니다. <code>with</code> 문을 사용하면 파일이 자동으로 닫히므로 리소스 누수를 방지할 수 있습니다. 한글 파일은 <code>encoding="utf-8"</code>을 명시하는 것이 안전합니다.</p>
            <div class="code-block">
<span class="comment"># 전체 읽기</span>
<span class="keyword">with</span> <span class="builtin">open</span>(<span class="string">"file.txt"</span>, <span class="string">"r"</span>, encoding=<span class="string">"utf-8"</span>) <span class="keyword">as</span> f:
    content = f.read()
    <span class="keyword">print</span>(content)

<span class="comment"># 줄 단위 읽기</span>
<span class="keyword">with</span> <span class="builtin">open</span>(<span class="string">"file.txt"</span>, <span class="string">"r"</span>) <span class="keyword">as</span> f:
    <span class="keyword">for</span> line <span class="keyword">in</span> f:
        <span class="keyword">print</span>(line.strip())

<span class="comment"># readlines()로 목록 가져오기</span>
<span class="keyword">with</span> <span class="builtin">open</span>(<span class="string">"file.txt"</span>) <span class="keyword">as</span> f:
    lines = f.readlines()

<span class="comment"># seek()로 위치 이동</span>
<span class="keyword">with</span> <span class="builtin">open</span>(<span class="string">"file.txt"</span>) <span class="keyword">as</span> f:
    f.seek(<span class="number">0</span>)  <span class="comment"># 처음으로</span>
    <span class="keyword">print</span>(f.read(<span class="number">10</span>))  <span class="comment"># 첫 10자</span>
            </div>
            
            <h3>파일 쓰기</h3>
            <p><code>"w"</code> 모드는 파일을 새로 생성하거나 기존 내용을 덮어쓰고, <code>"a"</code> 모드는 기존 내용 끝에 추가합니다. <code>write()</code>는 문자열 하나를 쓰고, <code>writelines()</code>는 문자열 리스트를 한꺼번에 씁니다. 줄바꿈은 자동 추가되지 않으므로 필요 시 <code>\n</code>을 직접 포함해야 합니다.</p>
            <div class="code-block">
<span class="comment"># 새 파일 작성 (w: overwrite, a: append)</span>
<span class="keyword">with</span> <span class="builtin">open</span>(<span class="string">"output.txt"</span>, <span class="string">"w"</span>, encoding=<span class="string">"utf-8"</span>) <span class="keyword">as</span> f:
    f.write(<span class="string">"첫 번째 줄\n"</span>)
    f.write(<span class="string">"두 번째 줄\n"</span>)

<span class="comment"># 여러 줄 쓰기</span>
lines = [<span class="string">"줄 1"</span>, <span class="string">"줄 2"</span>, <span class="string">"줄 3"</span>]
<span class="keyword">with</span> <span class="builtin">open</span>(<span class="string">"output.txt"</span>, <span class="string">"w"</span>) <span class="keyword">as</span> f:
    f.writelines(<span class="string">"</span><span class="keyword">\n</span><span class="string">"</span>.join(lines))
            </div>
            
            <h3>파일 모드 (Modes)</h3>
            <p><code>open()</code> 함수의 두 번째 인자로 파일 모드를 지정합니다. 모드를 조합하여 사용할 수 있으며(예: <code>"rb"</code>는 바이너리 읽기), 기본값은 텍스트 읽기(<code>"rt"</code>)입니다.</p>
            <table class="comparison-table">
                <tr><th>모드</th><th>설명</th></tr>
                <tr><td>r</td><td>읽기 (기본)</td></tr>
                <tr><td>w</td><td>쓰기 (덮어쓰기)</td></tr>
                <tr><td>a</td><td>추가 (끝에)</td></tr>
                <tr><td>r+</td><td>읽기+쓰기</td></tr>
                <tr><td>w+</td><td>읽기+쓰기 (덮어쓰기)</td></tr>
                <tr><td>a+</td><td>읽기+추가</td></tr>
                <tr><td>b</td><td>바이너리 모드</td></tr>
                <tr><td>t</td><td>텍스트 모드 (기본)</td></tr>
            </table>
            
            <h3>pickle (객체 직렬화)</h3>
            <p><code>pickle</code>은 파이썬 객체를 바이트 스트림으로 변환(<strong>직렬화</strong>)하여 파일에 저장하고, 나중에 다시 파이썬 객체로 복원(<strong>역직렬화</strong>)합니다. 리스트, 딕셔너리, 클래스 인스턴스 등 거의 모든 파이썬 객체를 저장할 수 있지만, 신뢰할 수 없는 출처의 pickle 파일은 보안 위험이 있으므로 주의해야 합니다.</p>
            <div class="code-block">
<span class="keyword">import</span> pickle

<span class="comment"># 객체 저장</span>
data = {<span class="string">"name"</span>: <span class="string">"민준"</span>, <span class="string">"age"</span>: <span class="number">25</span>}
<span class="keyword">with</span> <span class="builtin">open</span>(<span class="string">"data.pkl"</span>, <span class="string">"wb"</span>) <span class="keyword">as</span> f:
    pickle.dump(data, f)

<span class="comment"># 객체 읽기</span>
<span class="keyword">with</span> <span class="builtin">open</span>(<span class="string">"data.pkl"</span>, <span class="string">"rb"</span>) <span class="keyword">as</span> f:
    loaded_data = pickle.load(f)
            </div>
            
            <h3>pathlib (객체 지향 경로)</h3>
            <p>Python 3.4에서 도입된 <code>pathlib</code>은 파일 경로를 <strong>객체 지향적</strong>으로 다룹니다. <code>/</code> 연산자로 경로를 결합하고, 메서드 체이닝으로 파일 존재 확인, 읽기/쓰기, 패턴 검색 등을 간결하게 수행합니다. <code>os.path</code>보다 직관적이며 현대 파이썬에서 권장됩니다.</p>
            <div class="code-block">
<span class="keyword">from</span> pathlib <span class="keyword">import</span> Path

p = Path(<span class="string">"myproject"</span>)

<span class="comment"># 경로 생성</span>
(p / <span class="string">"src"</span> / <span class="string">"main.py"</span>)

<span class="comment"># 파일 존재 확인</span>
p.exists()
p.is_file()
p.is_dir()

<span class="comment">#.glob()로 파일 찾기</span>
<span class="keyword">for</span> f <span class="keyword">in</span> Path(<span class="string">"."</span>).glob(<span class="string">"*.py"</span>):
    <span class="keyword">print</span>(f)

<span class="comment"># 파일 읽기</span>
content = Path(<span class="string">"file.txt"</span>).read_text()

<span class="comment"># 파일 쓰기</span>
Path(<span class="string">"new.txt"</span>).write_text(<span class="string">"Hello"</span>)
            </div>
            
            <h3>tempfile (임시 파일)</h3>
            <p><code>tempfile</code> 모듈은 시스템의 임시 디렉토리에 <strong>안전하게 임시 파일/디렉토리를 생성</strong>합니다. <code>with</code> 문과 함께 사용하면 블록 종료 시 자동으로 삭제되어 정리 걱정이 없습니다. 파일명 충돌을 자동으로 방지합니다.</p>
            <div class="code-block">
<span class="keyword">import</span> tempfile

<span class="comment"># 임시 파일</span>
<span class="keyword">with</span> tempfile.NamedTemporaryFile(mode=<span class="string">"w"</span>, delete=<span class="keyword">False</span>) <span class="keyword">as</span> f:
    f.write(<span class="string">"임시 내용"</span>)
    temp_name = f.name

<span class="comment"># 임시 디렉토리</span>
<span class="keyword">with</span> tempfile.TemporaryDirectory() <span class="keyword">as</span> tmpdir:
    <span class="keyword">print</span>(tmpdir)
            </div>
            
            <h3>JSON 파일 처리</h3>
            <p>JSON(JavaScript Object Notation)은 웹 API, 설정 파일 등에서 가장 널리 사용되는 데이터 교환 형식입니다. <code>json.dump()</code>로 파일에 쓰고, <code>json.load()</code>로 읽습니다. <code>ensure_ascii=False</code>를 지정하면 한글이 유니코드 이스케이프 없이 그대로 저장됩니다.</p>
            <div class="code-block">
<span class="keyword">import</span> json

<span class="comment"># 쓰기</span>
data = {<span class="string">"name"</span>: <span class="string">"민준"</span>, <span class="string">"age"</span>: <span class="number">25</span>}
<span class="keyword">with</span> <span class="builtin">open</span>(<span class="string">"data.json"</span>, <span class="string">"w"</span>) <span class="keyword">as</span> f:
    json.dump(data, f, ensure_ascii=False, indent=<span class="number">2</span>)

<span class="comment"># 읽기</span>
<span class="keyword">with</span> <span class="builtin">open</span>(<span class="string">"data.json"</span>, <span class="string">"r"</span>) <span class="keyword">as</span> f:
    data = json.load(f)
            </div>
            
            <h3>CSV 파일 처리</h3>
            <p>CSV(Comma-Separated Values)는 표 형태의 데이터를 텍스트로 저장하는 형식으로, 엑셀이나 데이터베이스와의 데이터 교환에 널리 사용됩니다. <code>csv.writer</code>/<code>csv.reader</code>로 기본 읽기/쓰기를, <code>csv.DictWriter</code>/<code>csv.DictReader</code>로 헤더 기반 처리를 할 수 있습니다.</p>
            <div class="code-block">
<span class="keyword">import</span> csv

<span class="comment"># CSV 쓰기</span>
<span class="keyword">with</span> <span class="builtin">open</span>(<span class="string">"data.csv"</span>, <span class="string">"w"</span>, newline=<span class="string">""</span>, encoding=<span class="string">"utf-8"</span>) <span class="keyword">as</span> f:
    writer = csv.writer(f)
    writer.writerow([<span class="string">"이름"</span>, <span class="string">"나이"</span>])
    writer.writerow([<span class="string">"민준"</span>, <span class="number">25</span>])
    writer.writerow([<span class="string">"서연"</span>, <span class="number">23</span>])

<span class="comment"># CSV 읽기</span>
<span class="keyword">with</span> <span class="builtin">open</span>(<span class="string">"data.csv"</span>, <span class="string">"r"</span>, encoding=<span class="string">"utf-8"</span>) <span class="keyword">as</span> f:
    reader = csv.reader(f)
    <span class="keyword">for</span> row <span class="keyword">in</span> reader:
        <span class="keyword">print</span>(row)
            </div>
            
            <div class="tip-box">
                <strong>💡 팁:</strong> 항상 <code>with</code>문을 사용하여 파일을 다루세요. 파일이 자동으로 닫힙니다.
            </div>

            <div class="level-guide beginner">
                <div class="level-guide-header">초급자 가이드 - 파일 다루기의 기본 패턴</div>
                <div class="level-guide-content">
                    <p>파일 작업에서 가장 중요한 3가지 패턴:</p>
                    <ul>
                        <li><strong>반드시 with문 사용</strong>: <code>with open("파일") as f:</code> 패턴은 파일을 안전하게 열고 닫습니다. <code>with</code> 없이 <code>f = open("파일")</code>로 열면, 예외 발생 시 파일이 닫히지 않아 데이터 손실이 생길 수 있습니다.</li>
                        <li><strong>인코딩 명시</strong>: 한글이 포함된 파일은 반드시 <code>encoding="utf-8"</code>을 지정하세요. 지정하지 않으면 운영체제 기본 인코딩이 사용되어 Windows에서 한글 깨짐이 발생합니다.</li>
                        <li><strong>파일 모드 구분</strong>: <code>"r"</code>(읽기), <code>"w"</code>(쓰기, 기존 내용 삭제!), <code>"a"</code>(추가, 기존 내용 유지). <code>"w"</code> 모드는 기존 파일을 완전히 덮어쓰므로 주의하세요!</li>
                    </ul>
                </div>
            </div>

            <div class="level-guide intermediate">
                <div class="level-guide-header">중급자 가이드 - 실무 파일 처리 패턴</div>
                <div class="level-guide-content">
                    <p>실무에서 자주 사용하는 파일 처리 패턴과 주의사항:</p>
                    <ul>
                        <li><strong>대용량 파일 처리</strong>: <code>for line in f:</code>는 한 줄씩 읽어 메모리 효율적입니다. <code>f.read()</code>는 전체 내용을 메모리에 올리므로 대용량 파일에서는 피하세요.</li>
                        <li><strong>pathlib 우선 사용</strong>: <code>os.path</code> 대신 <code>pathlib.Path</code>를 사용하세요. <code>Path("dir") / "file.txt"</code>로 경로를 결합하고, <code>.read_text()</code>, <code>.write_text()</code>로 간결하게 읽기/쓰기할 수 있습니다.</li>
                        <li><strong>원자적 쓰기</strong>: 파일 쓰기 중 프로그램이 중단되면 데이터가 손상될 수 있습니다. 임시 파일에 먼저 쓴 후 <code>os.replace()</code>로 이름을 바꾸면 안전합니다.</li>
                        <li><strong>구조화된 데이터</strong>: 단순 텍스트보다 JSON(설정 파일, API), CSV(표 데이터), YAML(설정 파일), TOML(프로젝트 설정)을 목적에 맞게 선택하세요.</li>
                    </ul>
                </div>
            </div>

            <div class="level-guide advanced">
                <div class="level-guide-header">고급자 가이드 - 고성능 파일 I/O</div>
                <div class="level-guide-content">
                    <p>대규모 데이터를 효율적으로 처리하기 위한 고급 I/O 기법:</p>
                    <ul>
                        <li><strong>mmap (메모리 매핑)</strong>: <code>mmap.mmap()</code>은 파일을 메모리에 매핑하여 랜덤 접근 성능을 극대화합니다. 수 GB 파일에서 특정 위치의 데이터를 빠르게 읽을 때 유용합니다.</li>
                        <li><strong>io.BufferedReader/Writer</strong>: 버퍼 크기를 조절하여 I/O 성능을 최적화합니다. SSD에서는 더 큰 버퍼(예: 1MB)가 효율적입니다.</li>
                        <li><strong>aiofiles</strong>: asyncio와 함께 비동기 파일 I/O를 수행합니다. 많은 파일을 동시에 처리할 때 이벤트 루프를 블로킹하지 않습니다.</li>
                        <li><strong>orjson / ujson</strong>: 표준 <code>json</code> 모듈보다 3-10배 빠른 JSON 처리를 제공합니다. 대량의 JSON 데이터를 다룰 때 유용합니다.</li>
                        <li><strong>Parquet / HDF5</strong>: 대규모 데이터 분석에서는 CSV 대신 Apache Parquet(컬럼 기반, 압축)이나 HDF5(계층적 데이터)를 사용하면 10-100배 빠른 읽기/쓰기가 가능합니다.</li>
                    </ul>
                </div>
            </div>
        </section>

        <section id="regex">
            <h2>10. 정규표현식 (Regular Expressions)</h2>
            <span class="level-badge level-intermediate">중급</span>
            <span class="level-badge level-advanced">고급</span>
            
            <p>정규표현식(regex)은 문자열 패턴을 정의하는 특수한 표기법으로, 데이터 검증, 텍스트 검색/치환, 로그 파싱 등에 널리 사용됩니다. 파이썬의 <code>re</code> 모듈이 정규표현식 기능을 제공하며, 패턴 문자열은 <code>r"..."</code>(raw string)로 작성하여 백슬래시 이스케이프 문제를 방지합니다.</p>

            <h3>기본 매칭</h3>
            <p><code>re.search()</code>는 문자열 전체에서 패턴을 검색하고, <code>re.match()</code>는 문자열의 <strong>시작 부분</strong>에서만 매칭합니다. 매칭에 성공하면 Match 객체를 반환하고, 실패하면 <code>None</code>을 반환합니다.</p>
            <div class="code-block">
<span class="keyword">import</span> re

<span class="comment"># 매칭 여부 확인</span>
pattern = <span class="string">r"\d+"</span>
text = <span class="string">"내 번호는 010-1234-5678입니다"</span>

<span class="keyword">if</span> re.search(pattern, text):
    <span class="keyword">print</span>(<span class="string">"숫자 발견!"</span>)
            </div>
            
            <h3>패턴 매칭 함수</h3>
            <p><code>re</code> 모듈은 다양한 매칭 함수를 제공합니다. <code>findall()</code>은 모든 매칭을 리스트로 반환하고, <code>sub()</code>은 매칭된 부분을 대체하며, <code>split()</code>은 패턴을 기준으로 문자열을 분할합니다. <code>compile()</code>로 패턴을 미리 컴파일하면 반복 사용 시 성능이 향상됩니다.</p>
            <div class="code-block">
<span class="comment"># findall: 모든 매칭 찾기</span>
result = re.findall(r<span class="string">"\d+"</span>, <span class="string">"123 abc 456 def 789"</span>)
<span class="keyword">print</span>(result)  <span class="comment"># ['123', '456', '789']</span>

<span class="comment"># sub: 대체</span>
new_text = re.sub(r<span class="string">"\d+"</span>, <span class="string">"X"</span>, <span class="string">"123 abc 456"</span>)
<span class="keyword">print</span>(new_text)  <span class="comment"># X abc X</span>

<span class="comment"># split: 분리</span>
words = re.split(r<span class="string">"\s+"</span>, <span class="string">"hello   world  python"</span>)
<span class="keyword">print</span>(words)  <span class="comment"># ['hello', 'world', 'python']</span>
            </div>
            
            <h3>자주 사용하는 패턴</h3>
            <p>정규표현식의 핵심 메타문자들입니다. 소문자(<code>\d</code>, <code>\w</code>, <code>\s</code>)는 해당 문자를 매칭하고, 대문자(<code>\D</code>, <code>\W</code>, <code>\S</code>)는 그 반대를 매칭합니다. <code>{n,m}</code>으로 반복 횟수를 정밀하게 지정할 수 있습니다.</p>
            <table class="comparison-table">
                <tr><th>패턴</th><th>의미</th><th>예시</th></tr>
                <tr><td><code>\d</code></td><td>숫자</td><td>0-9</td></tr>
                <tr><td><code>\w</code></td><td>단어 문자</td><td>a-z, A-Z, 0-9, _</td></tr>
                <tr><td><code>\s</code></td><td>공백</td><td>스페이스, 탭, 줄바꿈</td></tr>
                <tr><td><code>.</code></td><td>모든 문자</td><td>줄바꿈 제외</td></tr>
                <tr><td><code>*</code></td><td>0회 이상</td><td>ab* = a, ab, abb...</td></tr>
                <tr><td><code>+</code></td><td>1회 이상</td><td>ab+ = ab, abb...</td></tr>
                <tr><td><code>?</code></td><td>0회 또는 1회</td><td>ab? = a, ab</td></tr>
                <tr><td><code>^</code></td><td>시작</td><td>^hello</td></tr>
                <tr><td><code>$</code></td><td>끝</td><td>world$</td></tr>
            </table>
            
            <h3>이메일 검증 예제</h3>
            <p>정규표현식의 실전 활용 예시입니다. <code>^</code>와 <code>$</code>로 문자열 전체가 패턴에 맞는지 확인합니다. 실제 서비스에서는 <code>email-validator</code> 같은 전용 라이브러리 사용이 더 안정적입니다.</p>
            <div class="code-block">
email_pattern = <span class="string">r"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$"</span>

emails = [<span class="string">"test@example.com"</span>, <span class="string">"invalid-email"</span>, <span class="string">"user@domain.co.kr"</span>]
<span class="keyword">for</span> email <span class="keyword">in</span> emails:
    <span class="keyword">if</span> re.match(email_pattern, email):
        <span class="keyword">print</span>(<span class="string">f"{email}: 유효함"</span>)
    <span class="keyword">else</span>:
        <span class="keyword">print</span>(<span class="string">f"{email}: 무효함"</span>)
            </div>

            <div class="svg-container">
                <!-- 정규표현식 패턴 구조 시각화 -->
                <svg width="700" height="280" viewBox="0 0 700 280" xmlns="http://www.w3.org/2000/svg">
                    <!-- 제목 -->
                    <text x="350" y="25" text-anchor="middle" fill="var(--text-primary)" font-weight="bold" font-size="14">정규표현식 패턴 구조 예시: \d{3}-\d{4}-\d{4}</text>

                    <!-- 입력 문자열 -->
                    <text x="350" y="55" text-anchor="middle" fill="var(--text-secondary)" font-size="12">입력: "010-1234-5678"</text>

                    <!-- 패턴 박스들 -->
                    <!-- \d{3} -->
                    <rect x="80" y="75" width="120" height="55" rx="8" fill="var(--svg-blue)" stroke="#2196F3" stroke-width="2"/>
                    <text x="140" y="98" text-anchor="middle" fill="var(--svg-blue-text)" font-weight="bold" font-size="13">\d{3}</text>
                    <text x="140" y="118" text-anchor="middle" fill="var(--text-secondary)" font-size="10">숫자 3자리</text>

                    <!-- 매칭 표시 010 -->
                    <rect x="95" y="140" width="90" height="28" rx="5" fill="#4CAF50" opacity="0.2" stroke="#4CAF50" stroke-width="1"/>
                    <text x="140" y="160" text-anchor="middle" fill="var(--svg-green-text)" font-weight="bold" font-size="14">010</text>

                    <!-- 하이픈 리터럴 -->
                    <rect x="230" y="75" width="60" height="55" rx="8" fill="var(--svg-gray)" stroke="var(--border)" stroke-width="2"/>
                    <text x="260" y="98" text-anchor="middle" fill="var(--text-primary)" font-weight="bold" font-size="16">-</text>
                    <text x="260" y="118" text-anchor="middle" fill="var(--text-secondary)" font-size="10">리터럴</text>

                    <!-- 매칭 - -->
                    <text x="260" y="160" text-anchor="middle" fill="var(--text-muted)" font-size="14">-</text>

                    <!-- \d{4} 첫번째 -->
                    <rect x="320" y="75" width="120" height="55" rx="8" fill="var(--svg-orange)" stroke="#ff9800" stroke-width="2"/>
                    <text x="380" y="98" text-anchor="middle" fill="var(--svg-orange-text)" font-weight="bold" font-size="13">\d{4}</text>
                    <text x="380" y="118" text-anchor="middle" fill="var(--text-secondary)" font-size="10">숫자 4자리</text>

                    <!-- 매칭 1234 -->
                    <rect x="340" y="140" width="80" height="28" rx="5" fill="#ff9800" opacity="0.2" stroke="#ff9800" stroke-width="1"/>
                    <text x="380" y="160" text-anchor="middle" fill="var(--svg-orange-text)" font-weight="bold" font-size="14">1234</text>

                    <!-- 하이픈 -->
                    <rect x="470" y="75" width="60" height="55" rx="8" fill="var(--svg-gray)" stroke="var(--border)" stroke-width="2"/>
                    <text x="500" y="98" text-anchor="middle" fill="var(--text-primary)" font-weight="bold" font-size="16">-</text>
                    <text x="500" y="118" text-anchor="middle" fill="var(--text-secondary)" font-size="10">리터럴</text>

                    <text x="500" y="160" text-anchor="middle" fill="var(--text-muted)" font-size="14">-</text>

                    <!-- \d{4} 두번째 -->
                    <rect x="560" y="75" width="120" height="55" rx="8" fill="var(--svg-pink)" stroke="#e91e63" stroke-width="2"/>
                    <text x="620" y="98" text-anchor="middle" fill="var(--svg-pink-text)" font-weight="bold" font-size="13">\d{4}</text>
                    <text x="620" y="118" text-anchor="middle" fill="var(--text-secondary)" font-size="10">숫자 4자리</text>

                    <!-- 매칭 5678 -->
                    <rect x="580" y="140" width="80" height="28" rx="5" fill="#e91e63" opacity="0.2" stroke="#e91e63" stroke-width="1"/>
                    <text x="620" y="160" text-anchor="middle" fill="var(--svg-pink-text)" font-weight="bold" font-size="14">5678</text>

                    <!-- 결과 -->
                    <rect x="180" y="195" width="340" height="40" rx="10" fill="#4CAF50" opacity="0.15" stroke="#4CAF50" stroke-width="1.5"/>
                    <text x="350" y="220" text-anchor="middle" fill="var(--svg-green-text)" font-weight="bold" font-size="13">Match! "010-1234-5678"</text>

                    <!-- 주요 메타문자 범례 -->
                    <text x="100" y="260" fill="var(--text-secondary)" font-size="11">\d = 숫자(0-9)</text>
                    <text x="250" y="260" fill="var(--text-secondary)" font-size="11">{n} = 정확히 n회 반복</text>
                    <text x="440" y="260" fill="var(--text-secondary)" font-size="11">리터럴 = 해당 문자 그대로 매칭</text>
                </svg>
            </div>

            <div class="level-guide beginner">
                <div class="level-guide-header">초급자 가이드 - 정규표현식 첫걸음</div>
                <div class="level-guide-content">
                    <p>정규표현식이 어렵게 느껴진다면, 가장 자주 사용하는 3가지만 먼저 익히세요:</p>
                    <ul>
                        <li><strong>\d</strong> = 숫자 한 글자 (0-9). <code>\d+</code>는 "숫자 1개 이상", <code>\d{3}</code>은 "숫자 정확히 3개"</li>
                        <li><strong>\w</strong> = 글자 한 글자 (영문, 숫자, _). <code>\w+</code>는 "단어 1개 이상"</li>
                        <li><strong>.</strong> = 아무 글자 1개 (줄바꿈 제외). <code>.*</code>는 "아무 글자 0개 이상"</li>
                    </ul>
                    <p><strong>실전 예시:</strong> 전화번호 찾기는 <code>r"\d{3}-\d{4}-\d{4}"</code>, 이메일 찾기는 <code>r"\w+@\w+\.\w+"</code>로 시작할 수 있습니다.</p>
                    <p><strong>팁:</strong> <code>r"..."</code>(raw string)을 반드시 사용하세요! <code>r</code>을 빼면 <code>\n</code>이 줄바꿈으로 해석됩니다.</p>
                </div>
            </div>

            <div class="level-guide intermediate">
                <div class="level-guide-header">중급자 가이드 - 정규표현식 실전 패턴</div>
                <div class="level-guide-content">
                    <p>실무에서 빈번히 사용되는 정규표현식 패턴과 기법:</p>
                    <ul>
                        <li><strong>그룹 캡처</strong>: <code>r"(\d{3})-(\d{4})-(\d{4})"</code>에서 괄호 안 내용을 <code>match.group(1)</code>, <code>match.group(2)</code>로 개별 추출합니다.</li>
                        <li><strong>이름 붙은 그룹</strong>: <code>r"(?P&lt;area&gt;\d{3})-(?P&lt;mid&gt;\d{4})"</code>로 이름을 부여하면 <code>match.group("area")</code>로 접근할 수 있습니다.</li>
                        <li><strong>비탐욕적(non-greedy) 매칭</strong>: <code>.*</code>는 최대한 많이 매칭(탐욕적)하지만, <code>.*?</code>는 최소한만 매칭합니다. HTML 태그 추출 시 중요합니다.</li>
                        <li><strong>전방/후방 탐색</strong>: <code>(?=패턴)</code>(전방 긍정), <code>(?&lt;=패턴)</code>(후방 긍정)으로 패턴 주변을 조건으로 사용하되 결과에 포함하지 않습니다.</li>
                        <li><strong>re.compile()</strong>: 같은 패턴을 반복 사용할 때 <code>pattern = re.compile(r"...")</code>으로 미리 컴파일하면 약 30% 성능이 향상됩니다.</li>
                    </ul>
                </div>
            </div>

            <div class="level-guide advanced">
                <div class="level-guide-header">고급자 가이드 - 정규표현식 성능과 대안</div>
                <div class="level-guide-content">
                    <p>정규표현식의 성능 함정과 대안 기법:</p>
                    <ul>
                        <li><strong>재앙적 백트래킹(Catastrophic Backtracking)</strong>: <code>(a+)+$</code>같은 패턴은 "aaaaaaaaX" 입력에서 지수적 시간이 걸립니다. 중첩된 반복 한정자를 피하고, <code>regex</code> 모듈의 POSIX 매칭이나 타임아웃을 활용하세요.</li>
                        <li><strong>원자적 그룹(3rd party)</strong>: <code>regex</code> 모듈(pip install regex)은 원자적 그룹 <code>(?>...)</code>, 유니코드 프로퍼티 <code>\p{Han}</code>, 중첩 집합 등 표준 <code>re</code>보다 강력한 기능을 제공합니다.</li>
                        <li><strong>정규표현식 대안</strong>: 단순 문자열 작업은 <code>str.startswith()</code>, <code>str.endswith()</code>, <code>in</code> 연산자가 정규표현식보다 10-100배 빠릅니다. 항상 정규표현식이 필요한지 먼저 검토하세요.</li>
                        <li><strong>re.VERBOSE 플래그</strong>: <code>re.VERBOSE</code>(또는 <code>re.X</code>)를 사용하면 패턴에 줄바꿈과 주석을 넣을 수 있어 복잡한 패턴의 가독성이 크게 향상됩니다.</li>
                    </ul>
                </div>
            </div>
        </section>

        <section id="testing">
            <h2>11. 테스트 (Testing)</h2>
            <span class="level-badge level-intermediate">중급</span>
            <span class="level-badge level-advanced">고급</span>
            
            <p>테스트는 코드가 의도한 대로 동작하는지 자동으로 검증하는 코드입니다. 단위 테스트(Unit Test)는 개별 함수/메서드를 독립적으로 검증하고, 통합 테스트는 여러 컴포넌트 간의 상호작용을 검증합니다. <strong>TDD(Test-Driven Development)</strong> 방법론에서는 테스트를 먼저 작성한 후 구현 코드를 작성합니다.</p>

            <h3>단위 테스트 (unittest)</h3>
            <p><code>unittest</code>는 파이썬 표준 라이브러리에 포함된 테스트 프레임워크로, <code>TestCase</code> 클래스를 상속하여 테스트를 작성합니다. <code>assertEqual</code>, <code>assertTrue</code>, <code>assertRaises</code> 등의 단언(assert) 메서드를 제공하며, <code>setUp</code>/<code>tearDown</code>으로 테스트 전후 초기화/정리를 수행합니다.</p>
            <div class="code-block">
<span class="keyword">import</span> unittest

<span class="keyword">class</span> <span class="function">TestMathOperations</span>(unittest.TestCase):
    
    <span class="keyword">def</span> <span class="function">test_add</span>(self):
        self.assertEqual(<span class="number">2</span> + <span class="number">2</span>, <span class="number">4</span>)
    
    <span class="keyword">def</span> <span class="function">test_divide</span>(self):
        self.assertEqual(<span class="number">10</span> / <span class="number">2</span>, <span class="number">5</span>)
    
    <span class="keyword">def</span> <span class="function">test_negative</span>(self):
        self.assertTrue(<span class="number">-5</span> < <span class="number">0</span>)

<span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:
    unittest.main()
            </div>
            
            <h3>pytest 사용</h3>
            <p><code>pytest</code>는 파이썬에서 가장 인기 있는 서드파티 테스트 프레임워크입니다. <code>unittest</code>보다 간결한 문법(단순 <code>assert</code> 사용), 강력한 fixture 시스템, 풍부한 플러그인 생태계를 제공합니다. 테스트 파일은 <code>test_</code>로 시작하는 이름을 사용합니다.</p>
            <div class="code-block">
<span class="comment"># pytest 설치</span>
pip install pytest

<span class="comment"># 테스트 파일 작성 (test_*.py)</span>
<span class="comment"># test_calculator.py</span>

<span class="keyword">def</span> <span class="function">test_addition</span>():
    assert <span class="number">1</span> + <span class="number">1</span> == <span class="number">2</span>

<span class="keyword">def</span> <span class="function">test_subtraction</span>():
    assert <span class="number">5</span> - <span class="number">3</span> == <span class="number">2</span>

<span class="comment"># 실행</span>
pytest test_calculator.py -v
            </div>
            
            <h3>테스트.raises()</h3>
            <p><code>pytest.raises()</code>는 특정 예외가 발생하는지 검증하는 컨텍스트 매니저입니다. 예외가 발생하지 않거나 다른 타입의 예외가 발생하면 테스트가 실패합니다. 예외 처리 로직을 테스트할 때 필수적인 도구입니다.</p>
            <div class="code-block">
<span class="keyword">import</span> pytest

<span class="keyword">def</span> <span class="function">test_divide_by_zero</span>():
    <span class="keyword">with</span> pytest.raises(ZeroDivisionError):
        <span class="number">1</span> / <span class="number">0</span>

<span class="keyword">def</span> <span class="function">test_value_error</span>():
    <span class="keyword">with</span> pytest.raises(ValueError):
        <span class="builtin">int</span>(<span class="string">"not a number"</span>)
            </div>
            
            <h3> Fixture와 Mock</h3>
            <p><strong>Fixture</strong>는 테스트 실행 전에 필요한 데이터나 환경을 준비하는 함수입니다. <code>@pytest.fixture</code>로 정의하고 테스트 함수의 매개변수로 받습니다. <strong>Mock</strong>은 외부 의존성(DB, API 등)을 가짜 객체로 대체하여 테스트를 독립적으로 실행할 수 있게 합니다. <code>unittest.mock</code>의 <code>@patch</code> 데코레이터가 자주 사용됩니다.</p>
            <div class="code-block">
<span class="keyword">import</span> pytest
<span class="keyword">from</span> unittest.mock <span class="keyword">import</span> Mock, patch

<span class="decorator">@pytest.fixture</span>
<span class="keyword">def</span> <span class="function">sample_data</span>():
    <span class="keyword">return</span> {<span class="string">"name"</span>: <span class="string">"테스트"</span>, <span class="string">"value"</span>: <span class="number">100</span>}

<span class="keyword">def</span> <span class="function">test_with_fixture</span>(sample_data):
    assert sample_data[<span class="string">"value"</span>] == <span class="number">100</span>

<span class="decorator">@patch</span>(<span class="string">"module.function"</span>)
<span class="keyword">def</span> <span class="function">test_mock</span>(mock_func):
    mock_func.return_value = <span class="string">"mocked"</span>
    result = mock_func()
    assert result == <span class="string">"mocked"</span>
            </div>
            
            <div class="tip-box">
                <strong>💡 팁:</strong> TDD(Test-Driven Development) 방식: 테스트를 먼저 작성하고, 그 다음에 실제 코드를 구현하세요.
            </div>
            
            <div class="svg-container">
                <svg width="600" height="180" viewBox="0 0 600 180" xmlns="http://www.w3.org/2000/svg">
                    <rect x="20" y="50" width="150" height="60" rx="10" fill="#f44336"/>
                    <text x="95" y="85" text-anchor="middle" fill="white" font-weight="bold">1. 테스트 작성</text>

                    <line x1="170" y1="80" x2="210" y2="80" stroke="var(--text-secondary)" stroke-width="2" marker-end="url(#arrow3)"/>

                    <rect x="210" y="50" width="150" height="60" rx="10" fill="#FF9800"/>
                    <text x="285" y="85" text-anchor="middle" fill="white" font-weight="bold">2. 실패 확인</text>

                    <line x1="360" y1="80" x2="400" y2="80" stroke="var(--text-secondary)" stroke-width="2" marker-end="url(#arrow3)"/>

                    <rect x="400" y="50" width="150" height="60" rx="10" fill="#4CAF50"/>
                    <text x="475" y="85" text-anchor="middle" fill="white" font-weight="bold">3. 코드 구현</text>

                    <line x1="520" y1="110" x2="520" y2="140" stroke="var(--text-secondary)" stroke-width="2"/>
                    <line x1="520" y1="140" x2="95" y2="140" stroke="var(--text-secondary)" stroke-width="2"/>
                    <line x1="95" y1="140" x2="95" y2="110" stroke="var(--text-secondary)" stroke-width="2"/>

                    <defs>
                        <marker id="arrow3" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                            <polygon points="0 0, 10 3.5, 0 7" fill="var(--text-secondary)"/>
                        </marker>
                    </defs>
                </svg>
            </div>

            <div class="level-guide beginner">
                <div class="level-guide-header">초급자 가이드 - 왜 테스트를 작성해야 할까?</div>
                <div class="level-guide-content">
                    <p>테스트 코드는 처음에 "추가 작업"처럼 느껴지지만, 장기적으로 시간을 절약해줍니다:</p>
                    <ul>
                        <li><strong>자동 검증</strong>: 코드를 수정할 때마다 수동으로 확인하지 않아도 됩니다. 테스트를 실행하면 모든 기능이 정상인지 자동으로 확인됩니다.</li>
                        <li><strong>버그 방지</strong>: 한 곳을 고치면서 다른 곳이 깨지는 "회귀 버그"를 방지합니다.</li>
                        <li><strong>문서 역할</strong>: 테스트 코드를 보면 함수가 어떻게 사용되는지, 어떤 결과를 기대하는지 알 수 있습니다.</li>
                    </ul>
                    <p><strong>시작 팁:</strong> pytest로 시작하세요. <code>assert 1 + 1 == 2</code>처럼 간단한 <code>assert</code> 문만으로 테스트를 작성할 수 있습니다. 파일 이름을 <code>test_</code>로 시작하면 pytest가 자동으로 찾아 실행합니다.</p>
                </div>
            </div>

            <div class="level-guide intermediate">
                <div class="level-guide-header">중급자 가이드 - 테스트 전략과 커버리지</div>
                <div class="level-guide-content">
                    <p>효과적인 테스트를 위한 실무 전략:</p>
                    <ul>
                        <li><strong>테스트 피라미드</strong>: 단위 테스트(많이) → 통합 테스트(적당히) → E2E 테스트(적게) 비율로 작성합니다.</li>
                        <li><strong>AAA 패턴</strong>: 테스트는 Arrange(준비) → Act(실행) → Assert(검증) 구조로 작성합니다.</li>
                        <li><strong>pytest-cov</strong>: <code>pytest --cov=mypackage</code>로 테스트 커버리지를 측정합니다. 80% 이상이 일반적인 목표입니다.</li>
                        <li><strong>Parametrize</strong>: <code>@pytest.mark.parametrize("input,expected", [(1,1), (2,4)])</code>로 여러 입력에 대해 같은 테스트를 반복합니다.</li>
                        <li><strong>conftest.py</strong>: 여러 테스트 파일에서 공유하는 fixture를 <code>conftest.py</code>에 정의하면 자동으로 사용 가능합니다.</li>
                    </ul>
                </div>
            </div>

            <div class="level-guide advanced">
                <div class="level-guide-header">고급자 가이드 - 테스트 자동화와 고급 기법</div>
                <div class="level-guide-content">
                    <p>대규모 프로젝트를 위한 고급 테스트 기법:</p>
                    <ul>
                        <li><strong>Property-based Testing</strong>: <code>hypothesis</code> 라이브러리로 무작위 입력을 자동 생성하여 엣지 케이스를 발견합니다. <code>@given(st.integers())</code>로 정수 범위의 모든 값에 대해 속성을 검증합니다.</li>
                        <li><strong>Snapshot Testing</strong>: <code>syrupy</code> 또는 <code>pytest-snapshot</code>으로 복잡한 출력(JSON, HTML 등)의 스냅샷을 저장하고, 변경 사항을 자동 감지합니다.</li>
                        <li><strong>CI/CD 통합</strong>: GitHub Actions, GitLab CI에서 push마다 자동으로 <code>pytest</code>를 실행하고, 커버리지를 Codecov에 보고합니다.</li>
                        <li><strong>Mutation Testing</strong>: <code>mutmut</code>으로 소스코드를 의도적으로 변형(mutation)하여 테스트가 이를 감지하는지 확인합니다. 테스트의 품질을 측정하는 방법입니다.</li>
                        <li><strong>Test Doubles 구분</strong>: Stub(정해진 값 반환), Mock(호출 검증), Fake(간단한 구현), Spy(호출 기록)를 목적에 맞게 사용합니다.</li>
                    </ul>
                </div>
            </div>
        </section>

        <section id="data-science">
            <h2>12. 데이터 과학 도구</h2>
            <span class="level-badge level-intermediate">중급</span>
            <span class="level-badge level-advanced">고급</span>

            <p>파이썬은 데이터 과학 분야에서 가장 널리 사용되는 언어입니다. NumPy로 고성능 수치 연산을, Pandas로 데이터 조작을, Matplotlib/Seaborn으로 시각화를 수행합니다. 이 생태계는 R, MATLAB 등의 대안보다 범용성과 확장성이 뛰어나 산업 표준으로 자리잡았습니다.</p>

            <div class="svg-container">
                <!-- 데이터 과학 파이프라인 다이어그램 -->
                <svg width="750" height="180" viewBox="0 0 750 180" xmlns="http://www.w3.org/2000/svg">
                    <defs>
                        <marker id="arrow-ds" markerWidth="8" markerHeight="6" refX="8" refY="3" orient="auto">
                            <polygon points="0 0, 8 3, 0 6" fill="#667eea"/>
                        </marker>
                    </defs>

                    <!-- Step 1: 데이터 수집 -->
                    <rect x="10" y="40" width="120" height="65" rx="10" fill="var(--svg-blue)" stroke="#2196F3" stroke-width="2"/>
                    <text x="70" y="65" text-anchor="middle" fill="var(--svg-blue-text)" font-weight="bold" font-size="12">데이터 수집</text>
                    <text x="70" y="85" text-anchor="middle" fill="var(--text-secondary)" font-size="10">CSV, API, DB</text>

                    <line x1="130" y1="72" x2="150" y2="72" stroke="#667eea" stroke-width="2" marker-end="url(#arrow-ds)"/>

                    <!-- Step 2: 전처리 -->
                    <rect x="155" y="40" width="120" height="65" rx="10" fill="var(--svg-orange)" stroke="#ff9800" stroke-width="2"/>
                    <text x="215" y="65" text-anchor="middle" fill="var(--svg-orange-text)" font-weight="bold" font-size="12">전처리</text>
                    <text x="215" y="85" text-anchor="middle" fill="var(--text-secondary)" font-size="10">Pandas, NumPy</text>

                    <line x1="275" y1="72" x2="295" y2="72" stroke="#667eea" stroke-width="2" marker-end="url(#arrow-ds)"/>

                    <!-- Step 3: 탐색적 분석 -->
                    <rect x="300" y="40" width="120" height="65" rx="10" fill="var(--svg-green)" stroke="#4CAF50" stroke-width="2"/>
                    <text x="360" y="65" text-anchor="middle" fill="var(--svg-green-text)" font-weight="bold" font-size="12">탐색적 분석</text>
                    <text x="360" y="85" text-anchor="middle" fill="var(--text-secondary)" font-size="10">Matplotlib</text>

                    <line x1="420" y1="72" x2="440" y2="72" stroke="#667eea" stroke-width="2" marker-end="url(#arrow-ds)"/>

                    <!-- Step 4: 모델링 -->
                    <rect x="445" y="40" width="120" height="65" rx="10" fill="var(--svg-pink)" stroke="#e91e63" stroke-width="2"/>
                    <text x="505" y="65" text-anchor="middle" fill="var(--svg-pink-text)" font-weight="bold" font-size="12">모델링</text>
                    <text x="505" y="85" text-anchor="middle" fill="var(--text-secondary)" font-size="10">scikit-learn</text>

                    <line x1="565" y1="72" x2="585" y2="72" stroke="#667eea" stroke-width="2" marker-end="url(#arrow-ds)"/>

                    <!-- Step 5: 평가/배포 -->
                    <rect x="590" y="40" width="120" height="65" rx="10" fill="#667eea"/>
                    <text x="650" y="65" text-anchor="middle" fill="white" font-weight="bold" font-size="12">평가 / 배포</text>
                    <text x="650" y="85" text-anchor="middle" fill="rgba(255,255,255,0.8)" font-size="10">검증, 서빙</text>

                    <!-- 하단 레이블 -->
                    <text x="375" y="145" text-anchor="middle" fill="var(--text-muted)" font-size="12">데이터 과학 워크플로우 (Data Science Pipeline)</text>
                    <text x="375" y="165" text-anchor="middle" fill="var(--text-muted)" font-size="11">각 단계는 반복적(iterative)으로 수행됩니다</text>
                </svg>
            </div>

            <h3>AI 개발 환경 설정 &amp; 설치</h3>
            <p>데이터 과학과 AI 개발을 위해 필요한 핵심 패키지들을 설치합니다. GPU를 활용한 딥러닝 학습에는 CUDA 호환 GPU와 드라이버가 필요하며, 가상 환경에서 패키지를 관리하는 것이 권장됩니다.</p>
            <div class="code-block">
<span class="comment"># 필수 패키지 설치</span>
pip install numpy pandas matplotlib seaborn

<span class="comment"># scikit-learn</span>
pip install scikit-learn

<span class="comment"># TensorFlow (GPU 자동 포함)</span>
pip install tensorflow

<span class="comment"># PyTorch (https://pytorch.org 에서 플랫폼별 명령어 확인)</span>
pip install torch torchvision torchaudio

<span class="comment"># Hugging Face Transformers</span>
pip install transformers datasets

<span class="comment"># 기타 유용한 패키지</span>
pip install opencv-python pillow albumentations
            </div>
            <div class="code-block">
<span class="comment"># requirements.txt 예시</span>
numpy>=1.24.0
pandas>=2.0.0
matplotlib>=3.7.0
seaborn>=0.12.0
scikit-learn>=1.3.0
tensorflow>=2.13.0
torch>=2.0.0
transformers>=4.30.0
opencv-python>=4.8.0
            </div>
            <div class="code-block">
<span class="comment"># GPU 확인</span>
<span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf
<span class="builtin">print</span>(tf.config.list_physical_devices(<span class="string">"GPU"</span>))

<span class="keyword">import</span> torch
<span class="builtin">print</span>(torch.cuda.is_available())
<span class="builtin">print</span>(torch.cuda.get_device_name(<span class="number">0</span>))
            </div>
            
            <h3>NumPy (수치 계산)</h3>

            <p>
                NumPy(Numerical Python)는 파이썬 과학 계산의 핵심 라이브러리입니다.
                C로 구현된 다차원 배열 객체 <code>ndarray</code>를 제공하며,
                반복문 없이 벡터화 연산으로 수십~수백 배의 성능을 냅니다.
                Pandas, scikit-learn, TensorFlow, PyTorch 등 거의 모든 AI/데이터 라이브러리의 기반입니다.
            </p>

            <div class="tip-box">
                <strong>설치:</strong> <code>pip install numpy</code> &nbsp;|&nbsp;
                확인: <code>python -c "import numpy; print(numpy.__version__)"</code>
            </div>

            <h4>배열 생성 (Array Creation)</h4>
            <div class="code-block">
<span class="keyword">import</span> numpy <span class="keyword">as</span> np

<span class="comment"># 리스트/튜플에서 생성</span>
a1 = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])                    <span class="comment"># 1차원 (ndim=1)</span>
a2 = np.array([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]])              <span class="comment"># 2차원 (ndim=2)</span>
a3 = np.array([[[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]]])             <span class="comment"># 3차원 (ndim=3)</span>

<span class="comment"># 특수 배열 생성</span>
np.zeros((<span class="number">3</span>, <span class="number">4</span>))          <span class="comment"># 0으로 채운 3×4 행렬</span>
np.ones((<span class="number">2</span>, <span class="number">3</span>))           <span class="comment"># 1로 채운 2×3 행렬</span>
np.full((<span class="number">3</span>, <span class="number">3</span>), <span class="number">7</span>)        <span class="comment"># 7로 채운 3×3 행렬</span>
np.eye(<span class="number">4</span>)                  <span class="comment"># 4×4 단위 행렬(항등행렬)</span>
np.empty((<span class="number">2</span>, <span class="number">2</span>))          <span class="comment"># 초기화 없이 메모리 할당 (속도 빠름)</span>

<span class="comment"># 수열 배열</span>
np.arange(<span class="number">0</span>, <span class="number">10</span>, <span class="number">2</span>)       <span class="comment"># [0 2 4 6 8]  — range와 유사, 실수 step 가능</span>
np.linspace(<span class="number">0</span>, <span class="number">1</span>, <span class="number">5</span>)      <span class="comment"># [0.   0.25 0.5  0.75 1.]  — 균등 간격 n개</span>
np.logspace(<span class="number">0</span>, <span class="number">3</span>, <span class="number">4</span>)      <span class="comment"># [1. 10. 100. 1000.]  — 로그 균등</span>

<span class="comment"># 타입 지정</span>
np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], dtype=np.float32)   <span class="comment"># float32 (메모리 절반)</span>
np.zeros(<span class="number">5</span>, dtype=np.int64)              <span class="comment"># int64</span>
np.array([<span class="keyword">True</span>, <span class="keyword">False</span>], dtype=np.bool_)  <span class="comment"># bool</span>
            </div>

            <h4>배열 속성 (ndarray Attributes)</h4>
            <div class="code-block">
a = np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],
              [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])

a.ndim       <span class="comment"># 2          — 차원 수</span>
a.shape      <span class="comment"># (2, 3)     — (행, 열) 크기</span>
a.size       <span class="comment"># 6          — 전체 요소 수</span>
a.dtype      <span class="comment"># dtype('int64')  — 요소 데이터 타입</span>
a.itemsize   <span class="comment"># 8          — 요소 하나의 바이트 크기</span>
a.nbytes     <span class="comment"># 48         — 전체 바이트 크기 (size × itemsize)</span>
a.T          <span class="comment"># 전치 행렬 shape=(3, 2)</span>
a.real       <span class="comment"># 실수부 (복소수 배열일 때)</span>
a.imag       <span class="comment"># 허수부</span>
            </div>

            <h4>인덱싱 &amp; 슬라이싱 (Indexing &amp; Slicing)</h4>
            <div class="code-block">
a = np.array([[<span class="number">10</span>, <span class="number">20</span>, <span class="number">30</span>],
              [<span class="number">40</span>, <span class="number">50</span>, <span class="number">60</span>],
              [<span class="number">70</span>, <span class="number">80</span>, <span class="number">90</span>]])

<span class="comment"># 기본 인덱싱</span>
a[<span class="number">0</span>, <span class="number">1</span>]          <span class="comment"># 20  — (0행, 1열)</span>
a[<span class="number">-1</span>, <span class="number">-1</span>]        <span class="comment"># 90  — 마지막 요소</span>

<span class="comment"># 슬라이싱  [행 start:stop:step, 열 start:stop:step]</span>
a[<span class="number">0</span>:<span class="number">2</span>, <span class="number">1</span>:<span class="number">3</span>]       <span class="comment"># [[20,30],[50,60]]</span>
a[:, <span class="number">0</span>]           <span class="comment"># [10 40 70]  — 0번 열 전체</span>
a[<span class="number">1</span>, :]           <span class="comment"># [40 50 60]  — 1번 행 전체</span>
a[::<span class="number">2</span>, ::<span class="number">2</span>]       <span class="comment"># [[10,30],[70,90]]  — 2칸 간격</span>

<span class="comment"># 팬시 인덱싱 (Fancy Indexing) — 인덱스 목록으로 선택</span>
idx = [<span class="number">0</span>, <span class="number">2</span>]
a[idx]            <span class="comment"># [[10,20,30],[70,80,90]]  — 0행, 2행</span>
a[:, idx]         <span class="comment"># 0열, 2열 선택</span>

<span class="comment"># 불리언 인덱싱 (Boolean Indexing)</span>
mask = a > <span class="number">50</span>
a[mask]           <span class="comment"># [60 70 80 90]  — 조건 만족 요소</span>
a[a % <span class="number">20</span> == <span class="number">0</span>]   <span class="comment"># 20의 배수만</span>

<span class="comment"># 인덱스 위치 찾기</span>
np.where(a > <span class="number">50</span>)          <span class="comment"># 조건 위치 (행 배열, 열 배열) 반환</span>
np.argmax(a), np.argmin(a)  <span class="comment"># 최대/최소 위치 (flatten 기준)</span>
np.argmax(a, axis=<span class="number">0</span>)       <span class="comment"># 열별 최대값 위치</span>
            </div>

            <h4>형태 변환 (Reshaping)</h4>
            <div class="code-block">
a = np.arange(<span class="number">12</span>)    <span class="comment"># [0 1 2 ... 11]</span>

<span class="comment"># reshape — 데이터 공유(뷰), 변경 시 원본도 변경</span>
a.reshape(<span class="number">3</span>, <span class="number">4</span>)      <span class="comment"># 3행 4열</span>
a.reshape(<span class="number">2</span>, <span class="number">-1</span>)     <span class="comment"># -1은 자동 계산 → (2, 6)</span>
a.reshape(<span class="number">-1</span>, <span class="number">1</span>)     <span class="comment"># 열 벡터 (12, 1)</span>
a.reshape(<span class="number">1</span>, <span class="number">-1</span>)     <span class="comment"># 행 벡터 (1, 12)</span>

<span class="comment"># 차원 추가/제거</span>
a[np.newaxis, :]     <span class="comment"># (1, 12) — 앞에 차원 추가</span>
a[:, np.newaxis]     <span class="comment"># (12, 1) — 뒤에 차원 추가</span>
np.expand_dims(a, axis=<span class="number">0</span>)  <span class="comment"># (1, 12)</span>
np.squeeze(a.reshape(<span class="number">1</span>,<span class="number">12</span>))  <span class="comment"># 크기 1인 차원 제거 → (12,)</span>

<span class="comment"># 평탄화</span>
b = a.reshape(<span class="number">3</span>, <span class="number">4</span>)
b.ravel()            <span class="comment"># 1차원 뷰 반환 (원본 공유)</span>
b.flatten()          <span class="comment"># 1차원 복사본 반환 (독립)</span>

<span class="comment"># 전치 (Transpose)</span>
b.T                  <span class="comment"># shape (3,4) → (4,3)</span>
np.transpose(b, (<span class="number">1</span>, <span class="number">0</span>))  <span class="comment"># 축 순서 지정</span>
            </div>

            <h4>브로드캐스팅 (Broadcasting)</h4>
            <div class="tip-box">
                <strong>브로드캐스팅 규칙:</strong> 두 배열의 shape를 오른쪽에서 비교해서,
                ① 같거나 ② 한쪽이 1이면 연산 가능합니다. 크기 1인 차원이 자동으로 확장됩니다.
            </div>
            <div class="code-block">
<span class="comment"># 스칼라 브로드캐스팅</span>
a = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])
a + <span class="number">10</span>       <span class="comment"># [11 12 13]</span>
a * <span class="number">2</span>        <span class="comment"># [2 4 6]</span>

<span class="comment"># 2D ↔ 1D 브로드캐스팅</span>
m = np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],   <span class="comment"># shape (2, 3)</span>
              [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])
v = np.array([<span class="number">10</span>, <span class="number">20</span>, <span class="number">30</span>])  <span class="comment"># shape (3,) → 자동으로 (1,3)→(2,3)</span>
m + v         <span class="comment"># [[11,22,33],[14,25,36]]</span>

<span class="comment"># 열 벡터 ↔ 행 벡터</span>
col = np.array([[<span class="number">1</span>], [<span class="number">2</span>], [<span class="number">3</span>]])  <span class="comment"># shape (3, 1)</span>
row = np.array([<span class="number">10</span>, <span class="number">20</span>])          <span class="comment"># shape (2,) → (1, 2)</span>
col + row     <span class="comment"># shape (3, 2) — 외적처럼 확장</span>
<span class="comment"># [[11,21],[12,22],[13,23]]</span>

<span class="comment"># 실용: 정규화 (각 열을 평균 0으로)</span>
data = np.random.randn(<span class="number">100</span>, <span class="number">5</span>)
data -= data.mean(axis=<span class="number">0</span>)    <span class="comment"># 열별 평균 빼기</span>
data /= data.std(axis=<span class="number">0</span>)     <span class="comment"># 열별 표준편차 나누기</span>
            </div>

            <h4>수학 함수 (Math Functions)</h4>
            <div class="code-block">
a = np.array([<span class="number">1.0</span>, <span class="number">4.0</span>, <span class="number">9.0</span>, <span class="number">16.0</span>])

<span class="comment"># 기본 수학</span>
np.sqrt(a)           <span class="comment"># [1. 2. 3. 4.]</span>
np.square(a)         <span class="comment"># 제곱</span>
np.abs(np.array([-<span class="number">1</span>, <span class="number">2</span>, -<span class="number">3</span>]))   <span class="comment"># 절대값 [1 2 3]</span>
np.power(a, <span class="number">0.5</span>)    <span class="comment"># 거듭제곱 (sqrt와 동일)</span>

<span class="comment"># 지수/로그</span>
np.exp(np.array([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]))   <span class="comment"># e^x: [1. 2.718 7.389]</span>
np.log(a)            <span class="comment"># 자연로그</span>
np.log2(a)           <span class="comment"># 밑 2 로그</span>
np.log10(a)          <span class="comment"># 밑 10 로그</span>

<span class="comment"># 삼각함수 (라디안 기준)</span>
angles = np.linspace(<span class="number">0</span>, np.pi, <span class="number">5</span>)
np.sin(angles)
np.cos(angles)
np.tan(angles)
np.deg2rad(<span class="number">180</span>)     <span class="comment"># 도→라디안 (= np.pi)</span>
np.rad2deg(np.pi)   <span class="comment"># 라디안→도 (= 180.0)</span>

<span class="comment"># 반올림</span>
x = np.array([<span class="number">1.4</span>, <span class="number">1.5</span>, <span class="number">2.5</span>, <span class="number">3.6</span>])
np.round(x)          <span class="comment"># [1. 2. 2. 4.]  (은행가 반올림)</span>
np.floor(x)          <span class="comment"># [1. 1. 2. 3.]  (내림)</span>
np.ceil(x)           <span class="comment"># [2. 2. 3. 4.]  (올림)</span>
np.trunc(x)          <span class="comment"># [1. 1. 2. 3.]  (0 방향 절단)</span>

<span class="comment"># 누적 연산</span>
a = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])
np.cumsum(a)         <span class="comment"># [1 3 6 10]  — 누적 합</span>
np.cumprod(a)        <span class="comment"># [1 2 6 24]  — 누적 곱</span>
np.diff(a)           <span class="comment"># [1 1 1]     — 차분</span>
            </div>

            <h4>통계 함수 (Statistical Functions)</h4>
            <div class="code-block">
a = np.array([[<span class="number">2</span>, <span class="number">4</span>, <span class="number">6</span>],
              [<span class="number">8</span>, <span class="number">10</span>, <span class="number">12</span>]])

<span class="comment"># 기본 통계 — axis=None(전체), axis=0(열별), axis=1(행별)</span>
np.sum(a)              <span class="comment"># 42</span>
np.sum(a, axis=<span class="number">0</span>)     <span class="comment"># [10 14 18]  — 열별 합</span>
np.sum(a, axis=<span class="number">1</span>)     <span class="comment"># [12 30]     — 행별 합</span>

np.mean(a)             <span class="comment"># 7.0</span>
np.median(a)           <span class="comment"># 7.0</span>
np.std(a)              <span class="comment"># 표준편차</span>
np.var(a)              <span class="comment"># 분산</span>

np.min(a), np.max(a)   <span class="comment"># 2, 12</span>
np.ptp(a)              <span class="comment"># peak-to-peak (max-min) = 10</span>

<span class="comment"># 퍼센타일 / 분위수</span>
np.percentile(a, <span class="number">25</span>)   <span class="comment"># 1사분위수 (Q1)</span>
np.percentile(a, [<span class="number">25</span>, <span class="number">50</span>, <span class="number">75</span>])  <span class="comment"># Q1, Q2, Q3</span>
np.quantile(a, <span class="number">0.9</span>)   <span class="comment"># 90번째 백분위</span>

<span class="comment"># 상관 계수 / 공분산</span>
x = np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])
y = np.array([<span class="number">2</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">8</span>])
np.corrcoef(x, y)      <span class="comment"># 상관 계수 행렬</span>
np.cov(x, y)           <span class="comment"># 공분산 행렬</span>

<span class="comment"># 히스토그램</span>
counts, edges = np.histogram(a.ravel(), bins=<span class="number">4</span>)
            </div>

            <h4>선형대수 (Linear Algebra — np.linalg)</h4>
            <div class="code-block">
A = np.array([[<span class="number">3</span>, <span class="number">1</span>],
              [<span class="number">1</span>, <span class="number">2</span>]])
b = np.array([<span class="number">9</span>, <span class="number">8</span>])

<span class="comment"># 행렬 곱</span>
np.dot(A, A)           <span class="comment"># 행렬 곱셈 (2D 권장)</span>
A @ A                  <span class="comment"># @ 연산자 (Python 3.5+, 권장)</span>
np.matmul(A, A)        <span class="comment"># matmul (배치 연산 지원)</span>

<span class="comment"># np.linalg 함수</span>
np.linalg.det(A)       <span class="comment"># 행렬식(determinant)</span>
np.linalg.inv(A)       <span class="comment"># 역행렬</span>
np.linalg.solve(A, b)  <span class="comment"># Ax=b 연립방정식 풀기 (inv 대신 권장)</span>

np.linalg.norm(b)      <span class="comment"># 벡터 노름(크기) — L2 norm</span>
np.linalg.norm(b, <span class="number">1</span>)  <span class="comment"># L1 norm</span>
np.linalg.norm(A, <span class="string">"fro"</span>)  <span class="comment"># Frobenius norm</span>

<span class="comment"># 고유값 분해 (Eigendecomposition)</span>
eigenvalues, eigenvectors = np.linalg.eig(A)

<span class="comment"># 특이값 분해 (SVD)</span>
U, S, Vt = np.linalg.svd(A)

<span class="comment"># QR 분해 / LU 분해</span>
Q, R = np.linalg.qr(A)

<span class="comment"># 랭크 / 대각 / 대각합</span>
np.linalg.matrix_rank(A)   <span class="comment"># 행렬 랭크</span>
np.diag(A)                  <span class="comment"># 대각 요소 추출</span>
np.diag([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])         <span class="comment"># 대각 행렬 생성</span>
np.trace(A)                 <span class="comment"># 대각합 (trace)</span>
            </div>

            <h4>난수 생성 (Random — np.random)</h4>
            <div class="code-block">
rng = np.random.default_rng(seed=<span class="number">42</span>)  <span class="comment"># 권장: 새 Generator API</span>

<span class="comment"># 연속 분포</span>
rng.random((<span class="number">3</span>, <span class="number">4</span>))        <span class="comment"># [0, 1) 균등 분포</span>
rng.uniform(<span class="number">-1</span>, <span class="number">1</span>, <span class="number">5</span>)    <span class="comment"># [-1, 1) 균등 분포</span>
rng.normal(<span class="number">0</span>, <span class="number">1</span>, (<span class="number">3</span>, <span class="number">3</span>)) <span class="comment"># 정규 분포 (평균=0, 표준편차=1)</span>
rng.exponential(<span class="number">2</span>, <span class="number">10</span>)   <span class="comment"># 지수 분포</span>
rng.beta(<span class="number">2</span>, <span class="number">5</span>, <span class="number">10</span>)       <span class="comment"># 베타 분포</span>
rng.poisson(<span class="number">3</span>, <span class="number">10</span>)       <span class="comment"># 포아송 분포</span>

<span class="comment"># 이산 분포</span>
rng.integers(<span class="number">0</span>, <span class="number">10</span>, <span class="number">5</span>)   <span class="comment"># [0, 10) 정수 (구 randint)</span>
rng.choice([<span class="number">10</span>, <span class="number">20</span>, <span class="number">30</span>], <span class="number">5</span>, replace=<span class="keyword">True</span>)  <span class="comment"># 복원 추출</span>
rng.choice([<span class="number">10</span>, <span class="number">20</span>, <span class="number">30</span>], <span class="number">2</span>, replace=<span class="keyword">False</span>) <span class="comment"># 비복원 추출</span>

<span class="comment"># 셔플 / 순열</span>
arr = np.arange(<span class="number">10</span>)
rng.shuffle(arr)          <span class="comment"># 제자리 셔플 (in-place)</span>
rng.permutation(arr)      <span class="comment"># 셔플된 새 배열 반환</span>

<span class="comment"># 레거시 API (구버전 호환)</span>
np.random.seed(<span class="number">42</span>)       <span class="comment"># 재현성 고정 (전역 상태 — 비권장)</span>
np.random.rand(<span class="number">3</span>, <span class="number">3</span>)    <span class="comment"># [0,1) 균등</span>
np.random.randn(<span class="number">3</span>, <span class="number">3</span>)   <span class="comment"># 표준 정규 분포</span>
            </div>

            <h4>배열 결합 &amp; 분할 (Concatenation &amp; Splitting)</h4>
            <div class="code-block">
a = np.array([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]])
b = np.array([[<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>]])

<span class="comment"># 결합 (concatenate)</span>
np.concatenate([a, b], axis=<span class="number">0</span>)   <span class="comment"># 행 방향 → (4,2)</span>
np.concatenate([a, b], axis=<span class="number">1</span>)   <span class="comment"># 열 방향 → (2,4)</span>
np.vstack([a, b])  <span class="comment"># 행 쌓기 (axis=0), shape 달라도 열수 같으면 OK</span>
np.hstack([a, b])  <span class="comment"># 열 쌓기 (axis=1)</span>
np.dstack([a, b])  <span class="comment"># 깊이 쌓기 (axis=2)</span>

<span class="comment"># 새 축으로 쌓기</span>
np.stack([a, b], axis=<span class="number">0</span>)  <span class="comment"># → (2,2,2): 새 축(0) 생성</span>
np.stack([a, b], axis=<span class="number">2</span>)  <span class="comment"># → (2,2,2): 새 축(2) 생성</span>

<span class="comment"># 분할 (split)</span>
arr = np.arange(<span class="number">12</span>).reshape(<span class="number">4</span>, <span class="number">3</span>)
np.split(arr, <span class="number">2</span>, axis=<span class="number">0</span>)       <span class="comment"># 행 방향 2등분 → [shape(2,3), shape(2,3)]</span>
np.vsplit(arr, <span class="number">2</span>)               <span class="comment"># vsplit = split(..., axis=0)</span>
np.hsplit(arr, <span class="number">3</span>)               <span class="comment"># 열 방향 3등분 → [shape(4,1), ...]</span>
np.array_split(arr, <span class="number">3</span>, axis=<span class="number">0</span>) <span class="comment"># 불균등 분할도 가능</span>
            </div>

            <h4>정렬 &amp; 탐색 (Sorting &amp; Searching)</h4>
            <div class="code-block">
a = np.array([<span class="number">3</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">9</span>, <span class="number">2</span>, <span class="number">6</span>])

<span class="comment"># 정렬</span>
np.sort(a)              <span class="comment"># [1 1 2 3 4 5 6 9]  — 새 배열</span>
a.sort()                <span class="comment"># in-place 정렬</span>
np.sort(a)[:<span class="number">-1</span>]        <span class="comment"># 내림차순 슬라이싱</span>

<span class="comment"># 간접 정렬 (인덱스 반환)</span>
np.argsort(a)           <span class="comment"># 정렬 시 원래 인덱스 순서</span>
a[np.argsort(a)]        <span class="comment"># 정렬된 배열 (argsort 활용)</span>

<span class="comment"># 2D 정렬</span>
m = np.array([[<span class="number">3</span>,<span class="number">1</span>],[<span class="number">4</span>,<span class="number">2</span>]])
np.sort(m, axis=<span class="number">0</span>)    <span class="comment"># 열별 정렬</span>
np.sort(m, axis=<span class="number">1</span>)    <span class="comment"># 행별 정렬</span>

<span class="comment"># 탐색</span>
np.searchsorted([<span class="number">1</span>,<span class="number">3</span>,<span class="number">5</span>], <span class="number">4</span>)   <span class="comment"># 삽입 위치 → 2 (이진 탐색)</span>
np.nonzero(a)                   <span class="comment"># 0이 아닌 요소 위치</span>
np.where(a > <span class="number">4</span>, a, <span class="number">0</span>)          <span class="comment"># 조건 기반 대체</span>

<span class="comment"># 집합 연산</span>
np.unique(a)            <span class="comment"># 중복 제거 + 정렬</span>
np.unique(a, return_counts=<span class="keyword">True</span>)  <span class="comment"># 각 값의 빈도</span>
np.intersect1d([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>], [<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>])  <span class="comment"># 교집합</span>
np.union1d([<span class="number">1</span>,<span class="number">2</span>], [<span class="number">2</span>,<span class="number">3</span>])          <span class="comment"># 합집합</span>
np.setdiff1d([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>], [<span class="number">2</span>,<span class="number">3</span>])      <span class="comment"># 차집합</span>
np.isin(a, [<span class="number">1</span>,<span class="number">3</span>,<span class="number">5</span>])              <span class="comment"># 멤버십 검사 (bool 배열)</span>
            </div>

            <h4>파일 I/O</h4>
            <div class="code-block">
arr = np.arange(<span class="number">12</span>).reshape(<span class="number">3</span>, <span class="number">4</span>)

<span class="comment"># 이진 형식 (.npy / .npz) — 빠르고 정확, dtype 보존</span>
np.save(<span class="string">"array.npy"</span>, arr)               <span class="comment"># 단일 배열 저장</span>
loaded = np.load(<span class="string">"array.npy"</span>)            <span class="comment"># 불러오기</span>

np.savez(<span class="string">"data.npz"</span>, x=arr, y=arr*<span class="number">2</span>)    <span class="comment"># 여러 배열</span>
f = np.load(<span class="string">"data.npz"</span>)
f[<span class="string">"x"</span>], f[<span class="string">"y"</span>]                           <span class="comment"># 키로 접근</span>

np.savez_compressed(<span class="string">"data.npz"</span>, arr=arr) <span class="comment"># 압축 저장</span>

<span class="comment"># 텍스트 형식 (.txt / .csv) — 사람이 읽을 수 있음</span>
np.savetxt(<span class="string">"data.csv"</span>, arr, delimiter=<span class="string">","</span>, fmt=<span class="string">"%.4f"</span>)
loaded_txt = np.loadtxt(<span class="string">"data.csv"</span>, delimiter=<span class="string">","</span>)

<span class="comment"># genfromtxt — 결측치/헤더 처리 가능</span>
data = np.genfromtxt(<span class="string">"data.csv"</span>, delimiter=<span class="string">","</span>,
                      skip_header=<span class="number">1</span>, filling_values=<span class="number">0</span>)
            </div>

            <h4>벡터화 &amp; 성능 최적화</h4>
            <div class="code-block">
<span class="comment"># np.vectorize — 스칼라 함수를 배열 함수로 래핑</span>
<span class="keyword">def</span> <span class="function">my_func</span>(x):
    <span class="keyword">return</span> x ** <span class="number">2</span> + <span class="number">1</span> <span class="keyword">if</span> x > <span class="number">0</span> <span class="keyword">else</span> <span class="number">0</span>

vfunc = np.vectorize(my_func)
vfunc(np.array([-<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>]))    <span class="comment"># [0, 0, 5, 10]</span>

<span class="comment"># np.where — 조건 분기 (벡터화된 if-else)</span>
a = np.array([-<span class="number">3</span>, -<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">4</span>])
np.where(a > <span class="number">0</span>, a, <span class="number">0</span>)             <span class="comment"># ReLU: [0 0 0 2 4]</span>
np.where(a > <span class="number">0</span>, <span class="string">"pos"</span>, <span class="string">"non-pos"</span>)  <span class="comment"># 문자열도 가능</span>

<span class="comment"># np.select — 다중 조건</span>
conditions = [a &lt; <span class="number">0</span>, a == <span class="number">0</span>, a > <span class="number">0</span>]
choices    = [<span class="string">"neg"</span>, <span class="string">"zero"</span>, <span class="string">"pos"</span>]
np.select(conditions, choices, default=<span class="string">"?"</span>)

<span class="comment"># 메모리 레이아웃 — C order(행 우선) vs F order(열 우선)</span>
c_arr = np.ascontiguousarray(arr)   <span class="comment"># C-contiguous (행 연속)</span>
f_arr = np.asfortranarray(arr)      <span class="comment"># F-contiguous (열 연속)</span>
arr.flags                           <span class="comment"># 메모리 레이아웃 정보</span>

<span class="comment"># 뷰 vs 복사 — 메모리 공유 여부 확인</span>
view = arr[<span class="number">0</span>:<span class="number">2</span>]                     <span class="comment"># 뷰 (메모리 공유)</span>
copy = arr[<span class="number">0</span>:<span class="number">2</span>].copy()              <span class="comment"># 독립 복사본</span>
view.base <span class="keyword">is</span> arr                    <span class="comment"># True (뷰 확인)</span>
            </div>

            <h4>NumPy vs 순수 Python 성능 비교</h4>
            <table class="comparison-table">
                <tr><th>작업</th><th>순수 Python</th><th>NumPy</th><th>속도 차이</th></tr>
                <tr><td>1백만 요소 합산</td><td><code>sum(list)</code></td><td><code>np.sum(arr)</code></td><td>~10–50배 빠름</td></tr>
                <tr><td>요소별 곱셈</td><td>list comprehension</td><td>arr * arr</td><td>~20–100배 빠름</td></tr>
                <tr><td>행렬 곱</td><td>이중 for 루프</td><td>A @ B</td><td>~100배+ 빠름</td></tr>
                <tr><td>메모리 사용</td><td>int 객체 ~28B</td><td>int64 8B</td><td>~3배 적음</td></tr>
                <tr><td>조건 필터</td><td>list comprehension</td><td>arr[mask]</td><td>~10배 빠름</td></tr>
            </table>

            <div class="warning-box">
                <strong>주의:</strong> 반복문 안에서 NumPy 배열을 요소 하나씩 접근하면 오히려 느립니다.
                NumPy는 <strong>벡터화 연산</strong>으로 사용할 때 최고 성능을 발휘합니다.
                루프 대신 브로드캐스팅, <code>np.where</code>, <code>np.vectorize</code>, <code>ufunc</code>를 활용하세요.
            </div>

            <h3>Pandas (데이터 처리)</h3>

            <p>
                Pandas는 표 형태의 데이터를 다루는 파이썬의 핵심 라이브러리입니다.
                <code>Series</code>(1차원)와 <code>DataFrame</code>(2차원) 두 가지 자료구조를 중심으로,
                데이터 로딩·정제·변환·집계·시각화까지 데이터 분석의 전 과정을 지원합니다.
            </p>

            <div class="tip-box">
                <strong>설치:</strong> <code>pip install pandas</code> &nbsp;|&nbsp;
                권장: <code>pip install pandas openpyxl pyarrow</code> (Excel·Parquet 지원 포함)
            </div>

            <h4>Series — 1차원 자료구조</h4>
            <div class="code-block">
<span class="keyword">import</span> pandas <span class="keyword">as</span> pd
<span class="keyword">import</span> numpy <span class="keyword">as</span> np

<span class="comment"># 생성</span>
s = pd.Series([<span class="number">10</span>, <span class="number">20</span>, <span class="number">30</span>, <span class="number">40</span>])
s = pd.Series([<span class="number">10</span>, <span class="number">20</span>, <span class="number">30</span>], index=[<span class="string">"a"</span>, <span class="string">"b"</span>, <span class="string">"c"</span>])  <span class="comment"># 레이블 인덱스</span>
s = pd.Series({<span class="string">"x"</span>: <span class="number">1</span>, <span class="string">"y"</span>: <span class="number">2</span>, <span class="string">"z"</span>: <span class="number">3</span>})             <span class="comment"># 딕셔너리에서</span>
s = pd.Series(np.arange(<span class="number">5</span>), dtype=<span class="string">"float32"</span>)

<span class="comment"># 속성</span>
s.values          <span class="comment"># numpy 배열</span>
s.index           <span class="comment"># 인덱스</span>
s.dtype           <span class="comment"># 데이터 타입</span>
s.shape           <span class="comment"># (n,)</span>
s.name            <span class="comment"># 시리즈 이름</span>

<span class="comment"># 인덱싱</span>
s[<span class="string">"a"</span>]            <span class="comment"># 레이블 접근</span>
s[[<span class="string">"a"</span>, <span class="string">"c"</span>]]     <span class="comment"># 여러 레이블</span>
s[s > <span class="number">15</span>]         <span class="comment"># 불리언 필터</span>

<span class="comment"># 연산 — 인덱스 기준으로 정렬 후 연산 (align)</span>
s1 = pd.Series([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], index=[<span class="string">"a"</span>, <span class="string">"b"</span>, <span class="string">"c"</span>])
s2 = pd.Series([<span class="number">10</span>, <span class="number">20</span>], index=[<span class="string">"b"</span>, <span class="string">"c"</span>])
s1 + s2           <span class="comment"># a: NaN, b: 22, c: 33  (불일치 → NaN)</span>
s1.add(s2, fill_value=<span class="number">0</span>)  <span class="comment"># NaN 대신 0으로 채워 연산</span>

<span class="comment"># 유용한 메서드</span>
s.value_counts()  <span class="comment"># 값별 빈도</span>
s.unique()        <span class="comment"># 고유값 배열</span>
s.nunique()       <span class="comment"># 고유값 개수</span>
s.sort_values()   <span class="comment"># 값 기준 정렬</span>
s.apply(<span class="keyword">lambda</span> x: x ** <span class="number">2</span>)  <span class="comment"># 요소별 함수 적용</span>
s.map({<span class="number">10</span>: <span class="string">"low"</span>, <span class="number">20</span>: <span class="string">"mid"</span>, <span class="number">30</span>: <span class="string">"high"</span>})  <span class="comment"># 값 매핑</span>
            </div>

            <h4>DataFrame 생성</h4>
            <div class="code-block">
<span class="comment"># 딕셔너리 → DataFrame (가장 일반적)</span>
df = pd.DataFrame({
    <span class="string">"name"</span> : [<span class="string">"Alice"</span>, <span class="string">"Bob"</span>, <span class="string">"Charlie"</span>],
    <span class="string">"age"</span>  : [<span class="number">25</span>, <span class="number">30</span>, <span class="number">35</span>],
    <span class="string">"score"</span>: [<span class="number">85.0</span>, <span class="number">90.5</span>, <span class="number">78.3</span>],
    <span class="string">"pass"</span> : [<span class="keyword">True</span>, <span class="keyword">True</span>, <span class="keyword">False</span>]
})

<span class="comment"># 리스트 of 딕셔너리</span>
df = pd.DataFrame([
    {<span class="string">"name"</span>: <span class="string">"Alice"</span>, <span class="string">"age"</span>: <span class="number">25</span>},
    {<span class="string">"name"</span>: <span class="string">"Bob"</span>,   <span class="string">"age"</span>: <span class="number">30</span>},
])

<span class="comment"># NumPy 배열에서</span>
df = pd.DataFrame(np.random.randn(<span class="number">5</span>, <span class="number">3</span>),
                  columns=[<span class="string">"A"</span>, <span class="string">"B"</span>, <span class="string">"C"</span>],
                  index=pd.date_range(<span class="string">"2024-01"</span>, periods=<span class="number">5</span>, freq=<span class="string">"ME"</span>))

<span class="comment"># 빈 DataFrame 후 열 추가</span>
df = pd.DataFrame()
df[<span class="string">"x"</span>] = [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]

<span class="comment"># 인덱스 지정</span>
df.index.name = <span class="string">"id"</span>
            </div>

            <h4>기본 속성 &amp; 탐색</h4>
            <div class="code-block">
df.shape          <span class="comment"># (행수, 열수)</span>
df.dtypes         <span class="comment"># 각 열의 타입</span>
df.index          <span class="comment"># 행 인덱스</span>
df.columns        <span class="comment"># 열 이름 목록</span>
df.values         <span class="comment"># numpy 배열</span>
df.size           <span class="comment"># 전체 요소 수</span>
df.memory_usage(deep=<span class="keyword">True</span>)  <span class="comment"># 열별 메모리 사용량</span>

<span class="comment"># 데이터 미리보기</span>
df.head(<span class="number">5</span>)        <span class="comment"># 상위 5행 (기본값)</span>
df.tail(<span class="number">3</span>)        <span class="comment"># 하위 3행</span>
df.sample(<span class="number">5</span>)      <span class="comment"># 무작위 5행</span>
df.sample(frac=<span class="number">0.1</span>)  <span class="comment"># 10% 무작위</span>

<span class="comment"># 요약 정보</span>
df.info()          <span class="comment"># 타입·결측치·메모리</span>
df.describe()      <span class="comment"># 수치형 통계 요약 (count/mean/std/min/Q/max)</span>
df.describe(include=<span class="string">"all"</span>)   <span class="comment"># 범주형 포함</span>
df.describe(percentiles=[.<span class="number">1</span>, .<span class="number">5</span>, .<span class="number">9</span>])  <span class="comment"># 퍼센타일 지정</span>

<span class="comment"># 열 탐색</span>
df[<span class="string">"age"</span>].value_counts()     <span class="comment"># 값별 빈도</span>
df[<span class="string">"age"</span>].value_counts(normalize=<span class="keyword">True</span>)  <span class="comment"># 비율</span>
df[<span class="string">"age"</span>].nunique()          <span class="comment"># 고유값 개수</span>
df[<span class="string">"age"</span>].unique()           <span class="comment"># 고유값 배열</span>
            </div>

            <h4>인덱싱 &amp; 선택 (loc / iloc / query)</h4>
            <table class="comparison-table">
                <tr><th>방법</th><th>기준</th><th>예시</th><th>특징</th></tr>
                <tr><td><code>df["col"]</code></td><td>열 이름</td><td><code>df["age"]</code></td><td>Series 반환</td></tr>
                <tr><td><code>df[["c1","c2"]]</code></td><td>열 이름 목록</td><td><code>df[["name","age"]]</code></td><td>DataFrame 반환</td></tr>
                <tr><td><code>.loc[행, 열]</code></td><td>레이블 기반</td><td><code>df.loc[0, "age"]</code></td><td>슬라이스 끝 포함</td></tr>
                <tr><td><code>.iloc[행, 열]</code></td><td>위치(정수) 기반</td><td><code>df.iloc[0:3, 1:3]</code></td><td>슬라이스 끝 미포함</td></tr>
                <tr><td><code>.at[행, 열]</code></td><td>단일 레이블</td><td><code>df.at[0, "age"]</code></td><td>스칼라, 빠름</td></tr>
                <tr><td><code>.iat[행, 열]</code></td><td>단일 위치</td><td><code>df.iat[0, 1]</code></td><td>스칼라, 가장 빠름</td></tr>
                <tr><td><code>.query()</code></td><td>문자열 표현식</td><td><code>df.query("age > 25")</code></td><td>가독성 좋음</td></tr>
            </table>
            <div class="code-block">
<span class="comment"># loc — 레이블 기반 (끝 인덱스 포함)</span>
df.loc[<span class="number">0</span>]                       <span class="comment"># 인덱스 0인 행</span>
df.loc[<span class="number">0</span>:<span class="number">3</span>]                    <span class="comment"># 인덱스 0~3행 (3 포함)</span>
df.loc[<span class="number">0</span>, <span class="string">"age"</span>]               <span class="comment"># 스칼라</span>
df.loc[<span class="number">0</span>:<span class="number">3</span>, [<span class="string">"name"</span>, <span class="string">"score"</span>]]  <span class="comment"># 슬라이스 + 여러 열</span>
df.loc[df[<span class="string">"age"</span>] > <span class="number">25</span>]         <span class="comment"># 불리언 마스크</span>
df.loc[df[<span class="string">"age"</span>] > <span class="number">25</span>, <span class="string">"name"</span>] <span class="comment"># 조건 행 + 특정 열</span>

<span class="comment"># iloc — 위치 기반 (끝 인덱스 미포함)</span>
df.iloc[<span class="number">0</span>]                      <span class="comment"># 첫 번째 행</span>
df.iloc[<span class="number">0</span>:<span class="number">3</span>]                   <span class="comment"># 0, 1, 2행</span>
df.iloc[<span class="number">0</span>:<span class="number">3</span>, <span class="number">1</span>:<span class="number">3</span>]              <span class="comment"># 0~2행, 1~2열</span>
df.iloc[[<span class="number">0</span>, <span class="number">2</span>, <span class="number">4</span>], [<span class="number">1</span>, <span class="number">3</span>]]    <span class="comment"># 팬시 인덱싱</span>
df.iloc[:, :<span class="number">-1</span>]                 <span class="comment"># 마지막 열 제외 전체</span>

<span class="comment"># query — SQL 스타일 (변수는 @var)</span>
threshold = <span class="number">80</span>
df.query(<span class="string">"age > 25 and score >= @threshold"</span>)
df.query(<span class="string">"name in ['Alice', 'Bob']"</span>)
df.query(<span class="string">"score.between(80, 95)"</span>)

<span class="comment"># 불리언 마스크 조합</span>
mask = (df[<span class="string">"age"</span>] > <span class="number">25</span>) &amp; (df[<span class="string">"score"</span>] >= <span class="number">80</span>)
df[mask]
df[~mask]  <span class="comment"># 반전</span>
            </div>

            <h4>데이터 타입 변환</h4>
            <div class="code-block">
<span class="comment"># astype — 기본 타입 변환</span>
df[<span class="string">"age"</span>] = df[<span class="string">"age"</span>].astype(<span class="string">"int32"</span>)      <span class="comment"># 메모리 절반</span>
df[<span class="string">"score"</span>] = df[<span class="string">"score"</span>].astype(<span class="string">"float32"</span>)
df[<span class="string">"flag"</span>] = df[<span class="string">"flag"</span>].astype(<span class="builtin">bool</span>)

<span class="comment"># 수치 변환 — 오류 처리</span>
pd.to_numeric(df[<span class="string">"col"</span>], errors=<span class="string">"coerce"</span>)   <span class="comment"># 변환 실패 → NaN</span>
pd.to_numeric(df[<span class="string">"col"</span>], errors=<span class="string">"ignore"</span>)   <span class="comment"># 실패 시 원본 유지</span>
pd.to_numeric(df[<span class="string">"col"</span>], downcast=<span class="string">"integer"</span>) <span class="comment"># 가능한 작은 int로</span>

<span class="comment"># 날짜 변환</span>
df[<span class="string">"date"</span>] = pd.to_datetime(df[<span class="string">"date"</span>])
df[<span class="string">"date"</span>] = pd.to_datetime(df[<span class="string">"date"</span>], format=<span class="string">"%Y-%m-%d"</span>)
df[<span class="string">"date"</span>] = pd.to_datetime(df[<span class="string">"date"</span>], errors=<span class="string">"coerce"</span>)

<span class="comment"># 카테고리 타입 — 반복 문자열에 효율적</span>
df[<span class="string">"grade"</span>] = df[<span class="string">"grade"</span>].astype(<span class="string">"category"</span>)
df[<span class="string">"grade"</span>].cat.categories       <span class="comment"># 카테고리 목록</span>
df[<span class="string">"grade"</span>].cat.codes            <span class="comment"># 정수 코드</span>
pd.Categorical(df[<span class="string">"grade"</span>],
               categories=[<span class="string">"C"</span>,<span class="string">"B"</span>,<span class="string">"A"</span>], ordered=<span class="keyword">True</span>)  <span class="comment"># 순서 있는 카테고리</span>

<span class="comment"># 일괄 타입 최적화</span>
df = df.convert_dtypes()   <span class="comment"># Pandas 2.0+: 최적 타입 자동 추론</span>
            </div>

            <h4>결측치 처리 (Missing Data)</h4>
            <div class="code-block">
<span class="comment"># 결측치 확인</span>
df.isnull()                   <span class="comment"># 요소별 bool</span>
df.isnull().sum()             <span class="comment"># 열별 결측치 수</span>
df.isnull().sum() / <span class="builtin">len</span>(df)   <span class="comment"># 결측 비율</span>
df.notnull()                  <span class="comment"># 반대</span>

<span class="comment"># 결측치 제거</span>
df.dropna()                        <span class="comment"># 결측 있는 행 전체 제거</span>
df.dropna(axis=<span class="number">1</span>)                  <span class="comment"># 결측 있는 열 제거</span>
df.dropna(subset=[<span class="string">"name"</span>, <span class="string">"age"</span>])  <span class="comment"># 특정 열 기준</span>
df.dropna(thresh=<span class="number">3</span>)               <span class="comment"># 유효값이 3개 미만인 행 제거</span>
df.dropna(how=<span class="string">"all"</span>)              <span class="comment"># 모두 NaN인 행만 제거</span>

<span class="comment"># 결측치 채우기</span>
df.fillna(<span class="number">0</span>)                          <span class="comment"># 모든 NaN → 0</span>
df[<span class="string">"score"</span>].fillna(df[<span class="string">"score"</span>].mean()) <span class="comment"># 평균으로</span>
df[<span class="string">"score"</span>].fillna(df[<span class="string">"score"</span>].median()) <span class="comment"># 중앙값으로</span>
df[<span class="string">"grade"</span>].fillna(df[<span class="string">"grade"</span>].mode()[<span class="number">0</span>]) <span class="comment"># 최빈값으로</span>
df.fillna({<span class="string">"age"</span>: <span class="number">0</span>, <span class="string">"name"</span>: <span class="string">"unknown"</span>}) <span class="comment"># 열별 다른 값</span>
df[<span class="string">"col"</span>].ffill()   <span class="comment"># 앞 값으로 전파 (forward fill)</span>
df[<span class="string">"col"</span>].bfill()   <span class="comment"># 뒤 값으로 전파 (backward fill)</span>

<span class="comment"># 보간 (Interpolation)</span>
df[<span class="string">"price"</span>].interpolate(method=<span class="string">"linear"</span>)   <span class="comment"># 선형 보간</span>
df[<span class="string">"price"</span>].interpolate(method=<span class="string">"spline"</span>, order=<span class="number">2</span>)  <span class="comment"># 스플라인</span>
df[<span class="string">"price"</span>].interpolate(limit=<span class="number">2</span>)           <span class="comment"># 최대 2개만</span>
            </div>

            <h4>데이터 정제 &amp; 변환</h4>
            <div class="code-block">
<span class="comment"># 열/행 이름 변경</span>
df.rename(columns={<span class="string">"name"</span>: <span class="string">"Name"</span>, <span class="string">"age"</span>: <span class="string">"Age"</span>})
df.rename(index={<span class="number">0</span>: <span class="string">"first"</span>})
df.columns = df.columns.str.lower().str.replace(<span class="string">" "</span>, <span class="string">"_"</span>)  <span class="comment"># 일괄 소문자+언더스코어</span>

<span class="comment"># 열/행 추가·삭제</span>
df[<span class="string">"bonus"</span>] = df[<span class="string">"score"</span>] * <span class="number">0.1</span>            <span class="comment"># 새 열 추가</span>
df.insert(<span class="number">2</span>, <span class="string">"rank"</span>, df[<span class="string">"score"</span>].rank())   <span class="comment"># 위치 지정 삽입</span>
df.drop(columns=[<span class="string">"bonus"</span>])                 <span class="comment"># 열 삭제</span>
df.drop(index=[<span class="number">0</span>, <span class="number">2</span>])                      <span class="comment"># 행 삭제</span>
df.pop(<span class="string">"bonus"</span>)                             <span class="comment"># 열 제거 후 반환</span>

<span class="comment"># 중복 처리</span>
df.duplicated()                    <span class="comment"># 중복 행 여부 bool</span>
df.duplicated(subset=[<span class="string">"name"</span>])     <span class="comment"># 특정 열 기준</span>
df.drop_duplicates()               <span class="comment"># 중복 제거</span>
df.drop_duplicates(subset=[<span class="string">"name"</span>], keep=<span class="string">"last"</span>)  <span class="comment"># 마지막 남기기</span>

<span class="comment"># 값 치환</span>
df[<span class="string">"grade"</span>].replace(<span class="string">"A"</span>, <span class="string">"Excellent"</span>)
df[<span class="string">"grade"</span>].replace({<span class="string">"A"</span>: <span class="number">4</span>, <span class="string">"B"</span>: <span class="number">3</span>, <span class="string">"C"</span>: <span class="number">2</span>})
df.replace(np.nan, <span class="number">0</span>)             <span class="comment"># 전체 NaN → 0</span>

<span class="comment"># apply — 행/열 단위 함수 적용</span>
df[<span class="string">"score_scaled"</span>] = df[<span class="string">"score"</span>].apply(<span class="keyword">lambda</span> x: (x - <span class="number">50</span>) / <span class="number">50</span>)
df.apply(np.sum, axis=<span class="number">0</span>)          <span class="comment"># 열별 합</span>
df.apply(np.sum, axis=<span class="number">1</span>)          <span class="comment"># 행별 합</span>
df[[<span class="string">"age"</span>,<span class="string">"score"</span>]].apply(<span class="keyword">lambda</span> row: row[<span class="string">"age"</span>] * row[<span class="string">"score"</span>], axis=<span class="number">1</span>)

<span class="comment"># map — Series 요소별 매핑</span>
df[<span class="string">"grade"</span>].map({<span class="string">"A"</span>: <span class="number">4</span>, <span class="string">"B"</span>: <span class="number">3</span>, <span class="string">"C"</span>: <span class="number">2</span>})

<span class="comment"># 구간 분류</span>
pd.cut(df[<span class="string">"score"</span>], bins=[<span class="number">0</span>,<span class="number">60</span>,<span class="number">80</span>,<span class="number">100</span>], labels=[<span class="string">"F"</span>,<span class="string">"B"</span>,<span class="string">"A"</span>])
pd.qcut(df[<span class="string">"score"</span>], q=<span class="number">4</span>)          <span class="comment"># 4분위로 자동 분류</span>

<span class="comment"># 인덱스 재설정</span>
df.reset_index(drop=<span class="keyword">True</span>)         <span class="comment"># 0,1,2... 재번호</span>
df.set_index(<span class="string">"name"</span>)              <span class="comment"># 열 → 인덱스</span>
df.set_index([<span class="string">"year"</span>, <span class="string">"month"</span>])   <span class="comment"># 멀티 인덱스</span>
            </div>

            <h4>정렬 &amp; 순위</h4>
            <div class="code-block">
<span class="comment"># 값 기준 정렬</span>
df.sort_values(<span class="string">"age"</span>)                                 <span class="comment"># 오름차순</span>
df.sort_values(<span class="string">"age"</span>, ascending=<span class="keyword">False</span>)               <span class="comment"># 내림차순</span>
df.sort_values([<span class="string">"grade"</span>, <span class="string">"score"</span>],
               ascending=[<span class="keyword">True</span>, <span class="keyword">False</span>])              <span class="comment"># 복합 정렬</span>
df.sort_values(<span class="string">"score"</span>, na_position=<span class="string">"first"</span>)         <span class="comment"># NaN 앞에 배치</span>

<span class="comment"># 인덱스 기준 정렬</span>
df.sort_index()
df.sort_index(ascending=<span class="keyword">False</span>)

<span class="comment"># 순위 (rank)</span>
df[<span class="string">"rank"</span>] = df[<span class="string">"score"</span>].rank(ascending=<span class="keyword">False</span>)         <span class="comment"># 내림차순 순위</span>
df[<span class="string">"score"</span>].rank(method=<span class="string">"dense"</span>)    <span class="comment"># 동점 시 건너뜀 없음</span>
df[<span class="string">"score"</span>].rank(method=<span class="string">"min"</span>)      <span class="comment"># 동점 시 최소 순위</span>
df[<span class="string">"score"</span>].rank(pct=<span class="keyword">True</span>)          <span class="comment"># 백분위 순위 (0~1)</span>

<span class="comment"># 상위/하위 N개</span>
df.nlargest(<span class="number">5</span>, <span class="string">"score"</span>)    <span class="comment"># 상위 5개</span>
df.nsmallest(<span class="number">3</span>, <span class="string">"age"</span>)    <span class="comment"># 하위 3개</span>
            </div>

            <h4>그룹화 &amp; 집계 (GroupBy)</h4>
            <div class="code-block">
<span class="comment"># 기본 groupby</span>
grp = df.groupby(<span class="string">"grade"</span>)
grp[<span class="string">"score"</span>].mean()          <span class="comment"># 학점별 평균</span>
grp[<span class="string">"score"</span>].agg([<span class="string">"mean"</span>, <span class="string">"std"</span>, <span class="string">"count"</span>])  <span class="comment"># 여러 집계</span>

<span class="comment"># 다중 키 그룹화</span>
df.groupby([<span class="string">"dept"</span>, <span class="string">"grade"</span>])[<span class="string">"score"</span>].mean()

<span class="comment"># agg — 열별로 다른 집계 함수</span>
df.groupby(<span class="string">"grade"</span>).agg(
    avg_score=(<span class="string">"score"</span>, <span class="string">"mean"</span>),
    max_age  =(<span class="string">"age"</span>,   <span class="string">"max"</span>),
    count    =(<span class="string">"name"</span>,  <span class="string">"count"</span>)
)

<span class="comment"># transform — 원래 shape 유지 (그룹 통계 → 각 행에 브로드캐스트)</span>
df[<span class="string">"grade_avg"</span>] = df.groupby(<span class="string">"grade"</span>)[<span class="string">"score"</span>].transform(<span class="string">"mean"</span>)
df[<span class="string">"score_z"</span>]   = df.groupby(<span class="string">"grade"</span>)[<span class="string">"score"</span>].transform(
    <span class="keyword">lambda</span> x: (x - x.mean()) / x.std()  <span class="comment"># 그룹 내 z-score</span>
)

<span class="comment"># filter — 조건 만족 그룹만 남기기</span>
df.groupby(<span class="string">"grade"</span>).filter(<span class="keyword">lambda</span> g: g[<span class="string">"score"</span>].mean() >= <span class="number">80</span>)

<span class="comment"># pivot_table — 엑셀 피벗과 동일</span>
pd.pivot_table(df,
               values=<span class="string">"score"</span>,
               index=<span class="string">"dept"</span>,
               columns=<span class="string">"grade"</span>,
               aggfunc=<span class="string">"mean"</span>,
               fill_value=<span class="number">0</span>)

<span class="comment"># crosstab — 빈도 교차표</span>
pd.crosstab(df[<span class="string">"dept"</span>], df[<span class="string">"grade"</span>], margins=<span class="keyword">True</span>)
pd.crosstab(df[<span class="string">"dept"</span>], df[<span class="string">"grade"</span>],
            values=df[<span class="string">"score"</span>], aggfunc=<span class="string">"mean"</span>)
            </div>

            <h4>데이터 결합 (Merge / Join / Concat)</h4>
            <div class="code-block">
<span class="comment"># concat — 같은 구조의 DataFrame 이어 붙이기</span>
pd.concat([df1, df2])                    <span class="comment"># 행 방향 (axis=0, 기본)</span>
pd.concat([df1, df2], ignore_index=<span class="keyword">True</span>) <span class="comment"># 인덱스 재번호</span>
pd.concat([df1, df2], axis=<span class="number">1</span>)           <span class="comment"># 열 방향</span>
pd.concat([df1, df2], join=<span class="string">"inner"</span>)    <span class="comment"># 공통 열만</span>

<span class="comment"># merge — SQL JOIN과 동일 개념</span>
pd.merge(df_left, df_right, on=<span class="string">"id"</span>)                 <span class="comment"># INNER JOIN</span>
pd.merge(df_left, df_right, on=<span class="string">"id"</span>, how=<span class="string">"left"</span>)     <span class="comment"># LEFT JOIN</span>
pd.merge(df_left, df_right, on=<span class="string">"id"</span>, how=<span class="string">"right"</span>)    <span class="comment"># RIGHT JOIN</span>
pd.merge(df_left, df_right, on=<span class="string">"id"</span>, how=<span class="string">"outer"</span>)    <span class="comment"># FULL OUTER JOIN</span>
pd.merge(df_left, df_right,
         left_on=<span class="string">"user_id"</span>, right_on=<span class="string">"id"</span>)            <span class="comment"># 다른 열 이름</span>
pd.merge(df_left, df_right, on=[<span class="string">"year"</span>, <span class="string">"month"</span>])    <span class="comment"># 복합 키</span>
pd.merge(df_left, df_right, on=<span class="string">"id"</span>,
         suffixes=(<span class="string">"_left"</span>, <span class="string">"_right"</span>))               <span class="comment"># 중복 열명 접미사</span>

<span class="comment"># join — 인덱스 기준 병합 (merge의 편의 래퍼)</span>
df1.join(df2, how=<span class="string">"left"</span>)
df1.join(df2, lsuffix=<span class="string">"_l"</span>, rsuffix=<span class="string">"_r"</span>)
            </div>

            <h4>시계열 (Time Series)</h4>
            <div class="code-block">
<span class="comment"># DatetimeIndex 생성</span>
dates = pd.date_range(<span class="string">"2024-01-01"</span>, periods=<span class="number">12</span>, freq=<span class="string">"ME"</span>)  <span class="comment"># 월말</span>
dates = pd.date_range(<span class="string">"2024-01-01"</span>, <span class="string">"2024-12-31"</span>, freq=<span class="string">"D"</span>) <span class="comment"># 일별</span>
dates = pd.bdate_range(<span class="string">"2024-01-01"</span>, periods=<span class="number">10</span>)             <span class="comment"># 영업일</span>

<span class="comment"># dt 접근자 — datetime 열 속성</span>
df[<span class="string">"date"</span>] = pd.to_datetime(df[<span class="string">"date"</span>])
df[<span class="string">"year"</span>]    = df[<span class="string">"date"</span>].dt.year
df[<span class="string">"month"</span>]   = df[<span class="string">"date"</span>].dt.month
df[<span class="string">"weekday"</span>] = df[<span class="string">"date"</span>].dt.day_name()
df[<span class="string">"quarter"</span>] = df[<span class="string">"date"</span>].dt.quarter
df[<span class="string">"is_month_end"</span>] = df[<span class="string">"date"</span>].dt.is_month_end

<span class="comment"># resample — 시간 단위 리샘플링</span>
ts = df.set_index(<span class="string">"date"</span>)[<span class="string">"price"</span>]
ts.resample(<span class="string">"ME"</span>).mean()      <span class="comment"># 월별 평균 (다운샘플링)</span>
ts.resample(<span class="string">"D"</span>).ffill()     <span class="comment"># 일별로 확장 (업샘플링, 앞 값으로)</span>
ts.resample(<span class="string">"QE"</span>).agg({<span class="string">"price"</span>: [<span class="string">"mean"</span>, <span class="string">"max"</span>]})  <span class="comment"># 분기별 집계</span>

<span class="comment"># rolling / expanding — 이동 통계</span>
ts.rolling(window=<span class="number">7</span>).mean()        <span class="comment"># 7일 이동 평균</span>
ts.rolling(window=<span class="number">7</span>, min_periods=<span class="number">1</span>).std()  <span class="comment"># 최소 1개부터 계산</span>
ts.expanding().mean()               <span class="comment"># 누적 평균</span>
ts.ewm(span=<span class="number">7</span>).mean()              <span class="comment"># 지수 가중 이동 평균</span>

<span class="comment"># shift / diff — 시차 &amp; 변화량</span>
ts.shift(<span class="number">1</span>)            <span class="comment"># 1기간 뒤로 (lag)</span>
ts.shift(<span class="number">-1</span>)           <span class="comment"># 1기간 앞으로 (lead)</span>
ts.diff(<span class="number">1</span>)             <span class="comment"># 1기간 차분</span>
ts.pct_change()         <span class="comment"># 전기 대비 변화율</span>
            </div>

            <h4>문자열 처리 (str 접근자)</h4>
            <div class="code-block">
s = df[<span class="string">"name"</span>]   <span class="comment"># 문자열 Series</span>

<span class="comment"># 검색 &amp; 판별</span>
s.str.contains(<span class="string">"li"</span>, case=<span class="keyword">False</span>)    <span class="comment"># 대소문자 무시 포함 여부</span>
s.str.startswith(<span class="string">"A"</span>)               <span class="comment"># 시작 여부</span>
s.str.endswith(<span class="string">"e"</span>)                 <span class="comment"># 끝 여부</span>
s.str.match(<span class="string">r"^[A-Z]"</span>)              <span class="comment"># 정규식 매치</span>
s.str.fullmatch(<span class="string">r"[A-Za-z]+"</span>)       <span class="comment"># 전체 일치</span>

<span class="comment"># 변환</span>
s.str.upper()                         <span class="comment"># 대문자</span>
s.str.lower()                         <span class="comment"># 소문자</span>
s.str.strip()                         <span class="comment"># 양쪽 공백 제거</span>
s.str.replace(<span class="string">" "</span>, <span class="string">"_"</span>, regex=<span class="keyword">False</span>) <span class="comment"># 치환</span>
s.str.replace(<span class="string">r"\s+"</span>, <span class="string">"_"</span>, regex=<span class="keyword">True</span>) <span class="comment"># 정규식 치환</span>

<span class="comment"># 분리 &amp; 추출</span>
s.str.split(<span class="string">"_"</span>)                     <span class="comment"># 분리 → 리스트</span>
s.str.split(<span class="string">"_"</span>, expand=<span class="keyword">True</span>)      <span class="comment"># DataFrame으로 확장</span>
s.str.split(<span class="string">"_"</span>).str[<span class="number">0</span>]             <span class="comment"># 첫 번째 요소</span>
s.str.extract(<span class="string">r"(\d+)"</span>)              <span class="comment"># 정규식 캡처 그룹</span>

<span class="comment"># 길이 &amp; 카운트</span>
s.str.len()                           <span class="comment"># 문자열 길이</span>
s.str.count(<span class="string">"a"</span>)                     <span class="comment"># 특정 문자 개수</span>
s.str.zfill(<span class="number">5</span>)                        <span class="comment"># 앞에 0 채우기</span>
            </div>

            <h4>파일 I/O</h4>
            <div class="code-block">
<span class="comment"># CSV</span>
df = pd.read_csv(<span class="string">"data.csv"</span>,
                 encoding=<span class="string">"utf-8"</span>,
                 index_col=<span class="string">"id"</span>,
                 parse_dates=[<span class="string">"date"</span>],
                 dtype={<span class="string">"age"</span>: <span class="string">"int32"</span>},
                 na_values=[<span class="string">"-"</span>, <span class="string">"N/A"</span>, <span class="string">"?"</span>],
                 chunksize=<span class="number">10_000</span>)       <span class="comment"># 대용량: 청크 단위 읽기</span>
df.to_csv(<span class="string">"out.csv"</span>, index=<span class="keyword">False</span>, encoding=<span class="string">"utf-8-sig"</span>)  <span class="comment"># BOM for Excel</span>

<span class="comment"># Excel (openpyxl 필요)</span>
df = pd.read_excel(<span class="string">"data.xlsx"</span>, sheet_name=<span class="string">"Sheet1"</span>, header=<span class="number">1</span>)
df.to_excel(<span class="string">"out.xlsx"</span>, index=<span class="keyword">False</span>, sheet_name=<span class="string">"Result"</span>)

<span class="comment"># 여러 시트를 한 파일에 쓰기</span>
<span class="keyword">with</span> pd.ExcelWriter(<span class="string">"report.xlsx"</span>, engine=<span class="string">"openpyxl"</span>) <span class="keyword">as</span> writer:
    df1.to_excel(writer, sheet_name=<span class="string">"Summary"</span>, index=<span class="keyword">False</span>)
    df2.to_excel(writer, sheet_name=<span class="string">"Detail"</span>,  index=<span class="keyword">False</span>)

<span class="comment"># JSON</span>
df = pd.read_json(<span class="string">"data.json"</span>, orient=<span class="string">"records"</span>)
df.to_json(<span class="string">"out.json"</span>, orient=<span class="string">"records"</span>, force_ascii=<span class="keyword">False</span>)

<span class="comment"># Parquet — 컬럼형 이진, 대용량에 권장 (pyarrow 필요)</span>
df = pd.read_parquet(<span class="string">"data.parquet"</span>)
df.to_parquet(<span class="string">"out.parquet"</span>, compression=<span class="string">"snappy"</span>)

<span class="comment"># SQL (SQLAlchemy)</span>
<span class="keyword">from</span> sqlalchemy <span class="keyword">import</span> create_engine
engine = create_engine(<span class="string">"sqlite:///mydb.db"</span>)
df = pd.read_sql(<span class="string">"SELECT * FROM users WHERE age > 20"</span>, engine)
df.to_sql(<span class="string">"result"</span>, engine, if_exists=<span class="string">"replace"</span>, index=<span class="keyword">False</span>)

<span class="comment"># 대용량 CSV 청크 처리</span>
chunks = pd.read_csv(<span class="string">"big.csv"</span>, chunksize=<span class="number">50_000</span>)
result = pd.concat(
    chunk[chunk[<span class="string">"age"</span>] > <span class="number">25</span>] <span class="keyword">for</span> chunk <span class="keyword">in</span> chunks
)
            </div>

            <h4>성능 최적화</h4>
            <div class="code-block">
<span class="comment"># 1. dtype 다운캐스팅 — 메모리 대폭 절감</span>
df[<span class="string">"age"</span>]   = pd.to_numeric(df[<span class="string">"age"</span>],   downcast=<span class="string">"integer"</span>)  <span class="comment"># int64→int8</span>
df[<span class="string">"score"</span>] = pd.to_numeric(df[<span class="string">"score"</span>], downcast=<span class="string">"float"</span>)    <span class="comment"># float64→float32</span>
df[<span class="string">"grade"</span>] = df[<span class="string">"grade"</span>].astype(<span class="string">"category"</span>)                  <span class="comment"># 반복 문자열</span>

<span class="comment"># 2. iterrows 대신 벡터화</span>
<span class="comment"># 느림 (절대 금지):</span>
<span class="keyword">for</span> idx, row <span class="keyword">in</span> df.iterrows():
    df.at[idx, <span class="string">"bonus"</span>] = row[<span class="string">"score"</span>] * <span class="number">0.1</span>
<span class="comment"># 빠름:</span>
df[<span class="string">"bonus"</span>] = df[<span class="string">"score"</span>] * <span class="number">0.1</span>

<span class="comment"># 3. inplace=True — Pandas 2.0+ 에서 더 이상 성능 이점 없음, 지양 권장</span>
<span class="comment"># 구버전 관용:</span>
df.dropna(inplace=<span class="keyword">True</span>)
<span class="comment"># 권장 (재할당):</span>
df = df.dropna()

<span class="comment"># 4. copy vs view — SettingWithCopyWarning 방지</span>
subset = df[df[<span class="string">"age"</span>] > <span class="number">25</span>].copy()   <span class="comment"># 명시적 복사</span>
subset[<span class="string">"bonus"</span>] = <span class="number">100</span>               <span class="comment"># 안전하게 수정 가능</span>

<span class="comment"># 5. pipe — 메서드 체인 가독성</span>
result = (
    df
    .dropna(subset=[<span class="string">"score"</span>])
    .query(<span class="string">"age >= 20"</span>)
    .assign(bonus=<span class="keyword">lambda</span> x: x[<span class="string">"score"</span>] * <span class="number">0.1</span>)
    .groupby(<span class="string">"grade"</span>)
    .agg(avg=(<span class="string">"score"</span>, <span class="string">"mean"</span>))
    .reset_index()
)
            </div>

            <h4>Pandas vs SQL 대응표</h4>
            <table class="comparison-table">
                <tr><th>SQL</th><th>Pandas</th></tr>
                <tr><td><code>SELECT col FROM t</code></td><td><code>df["col"]</code></td></tr>
                <tr><td><code>SELECT * FROM t WHERE age &gt; 25</code></td><td><code>df.query("age > 25")</code></td></tr>
                <tr><td><code>ORDER BY score DESC</code></td><td><code>df.sort_values("score", ascending=False)</code></td></tr>
                <tr><td><code>GROUP BY grade</code></td><td><code>df.groupby("grade")</code></td></tr>
                <tr><td><code>COUNT(*)</code></td><td><code>df.groupby("grade").size()</code></td></tr>
                <tr><td><code>INNER JOIN</code></td><td><code>pd.merge(df1, df2, on="id")</code></td></tr>
                <tr><td><code>LEFT JOIN</code></td><td><code>pd.merge(df1, df2, on="id", how="left")</code></td></tr>
                <tr><td><code>UNION ALL</code></td><td><code>pd.concat([df1, df2])</code></td></tr>
                <tr><td><code>DISTINCT</code></td><td><code>df.drop_duplicates()</code></td></tr>
                <tr><td><code>LIMIT 10</code></td><td><code>df.head(10)</code></td></tr>
            </table>

            <div class="warning-box">
                <strong>Pandas 2.0 주요 변경:</strong>
                <ul>
                    <li><code>inplace=True</code>는 복사를 방지하지 않습니다 — 재할당(<code>df = df.method()</code>) 권장</li>
                    <li>Copy-on-Write(CoW) 기본 활성화 예정 — <code>.copy()</code>를 명시적으로 사용</li>
                    <li><code>freq="M"</code> → <code>freq="ME"</code> (월말), <code>"QE"</code> (분기말) 등 별칭 변경</li>
                </ul>
            </div>

            <h3>데이터 전처리 핵심</h3>
            <p>데이터 전처리는 머신러닝 파이프라인에서 가장 중요한 단계로, 모델 성능의 80% 이상을 좌우합니다. <strong>표준화(Z-score)</strong>는 평균 0, 표준편차 1로 변환하고, <strong>정규화(Min-Max)</strong>는 0~1 범위로 스케일링합니다. <strong>원핫 인코딩</strong>은 범주형 변수를 수치로 변환하며, <strong>데이터 증강(Data Augmentation)</strong>은 학습 데이터를 인위적으로 확장하여 과적합을 방지합니다.</p>
            <div class="code-block">
<span class="keyword">import</span> numpy <span class="keyword">as</span> np
<span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler, MinMaxScaler, OneHotEncoder

<span class="comment"># 표준화 (Z-score)</span>
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

<span class="comment"># 정규화 (0-1)</span>
minmax = MinMaxScaler()
X_normalized = minmax.fit_transform(X)

<span class="comment"># 원-핫 인코딩</span>
encoder = OneHotEncoder(sparse_output=<span class="keyword">False</span>)
X_encoded = encoder.fit_transform(X categorical.reshape(<span class="number">-1</span>, <span class="number">1</span>))

<span class="comment"># 결측치 처리</span>
<span class="comment"># 평균/중앙값 대체</span>
from sklearn.impute import SimpleImputer
imputer = SimpleImputer(strategy=<span class="string">"mean"</span>)
X_imputed = imputer.fit_transform(X)

<span class="comment"># 데이터 증강 (이미지)</span>
<span class="keyword">from</span> tensorflow.keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator
datagen = ImageDataGenerator(
    rotation_range=<span class="number">20</span>,
    width_shift_range=<span class="number">0.2</span>,
    height_shift_range=<span class="number">0.2</span>,
    horizontal_flip=<span class="keyword">True</span>
)
            </div>
            
            <h3>Matplotlib (시각화)</h3>

            <p>
                Matplotlib은 파이썬의 대표적인 시각화 라이브러리로, 선 그래프·막대·산점도·히스토그램·3D 플롯 등
                거의 모든 유형의 차트를 지원합니다. 두 가지 인터페이스가 있으며, 복잡한 레이아웃에는
                <strong>OOP 방식</strong>(fig, ax)을 권장합니다.
            </p>

            <div class="tip-box">
                <strong>설치:</strong> <code>pip install matplotlib</code> &nbsp;|&nbsp;
                Jupyter: <code>%matplotlib inline</code> 또는 <code>%matplotlib widget</code>
            </div>

            <h4>pyplot vs OOP 인터페이스</h4>
            <table class="comparison-table">
                <tr><th>구분</th><th>pyplot (MATLAB 스타일)</th><th>OOP (권장)</th></tr>
                <tr><td>생성</td><td><code>plt.figure()</code></td><td><code>fig, ax = plt.subplots()</code></td></tr>
                <tr><td>플롯</td><td><code>plt.plot(x, y)</code></td><td><code>ax.plot(x, y)</code></td></tr>
                <tr><td>레이블</td><td><code>plt.xlabel("X")</code></td><td><code>ax.set_xlabel("X")</code></td></tr>
                <tr><td>범례</td><td><code>plt.legend()</code></td><td><code>ax.legend()</code></td></tr>
                <tr><td>저장</td><td><code>plt.savefig("f.png")</code></td><td><code>fig.savefig("f.png")</code></td></tr>
                <tr><td>적합한 경우</td><td>빠른 탐색, 단일 차트</td><td>복잡한 레이아웃, 재사용</td></tr>
            </table>

            <h4>Figure &amp; Axes 구조</h4>
            <div class="code-block">
<span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt
<span class="keyword">import</span> numpy <span class="keyword">as</span> np

<span class="comment"># Figure: 전체 캔버스 / Axes: 개별 좌표계(차트 한 개)</span>
fig, ax = plt.subplots(figsize=(<span class="number">8</span>, <span class="number">5</span>))  <span class="comment"># 단일 Axes</span>

<span class="comment"># Figure 속성</span>
fig.set_size_inches(<span class="number">10</span>, <span class="number">6</span>)
fig.set_dpi(<span class="number">150</span>)
fig.suptitle(<span class="string">"전체 제목"</span>, fontsize=<span class="number">16</span>, fontweight=<span class="string">"bold"</span>)

<span class="comment"># Axes 속성 (set_* 메서드로 일괄 설정 가능)</span>
ax.set_title(<span class="string">"차트 제목"</span>, fontsize=<span class="number">14</span>)
ax.set_xlabel(<span class="string">"X축 레이블"</span>)
ax.set_ylabel(<span class="string">"Y축 레이블"</span>)
ax.set_xlim(<span class="number">0</span>, <span class="number">10</span>)
ax.set_ylim(-<span class="number">1</span>, <span class="number">1</span>)
ax.set_xscale(<span class="string">"log"</span>)         <span class="comment"># 로그 스케일</span>
ax.grid(<span class="keyword">True</span>, linestyle=<span class="string">"--"</span>, alpha=<span class="number">0.5</span>)
ax.set_aspect(<span class="string">"equal"</span>)       <span class="comment"># 가로세로 비율 1:1</span>

<span class="comment"># 여러 속성 한 번에</span>
ax.set(title=<span class="string">"제목"</span>, xlabel=<span class="string">"X"</span>, ylabel=<span class="string">"Y"</span>, xlim=(<span class="number">0</span>,<span class="number">10</span>))

plt.tight_layout()  <span class="comment"># 레이아웃 자동 조정 (겹침 방지)</span>
plt.show()
            </div>

            <h4>선 그래프 (Line Plot)</h4>
            <div class="code-block">
x = np.linspace(<span class="number">0</span>, <span class="number">2</span> * np.pi, <span class="number">200</span>)
fig, ax = plt.subplots(figsize=(<span class="number">10</span>, <span class="number">4</span>))

<span class="comment"># 기본 — label은 legend()에서 표시</span>
ax.plot(x, np.sin(x), label=<span class="string">"sin"</span>)
ax.plot(x, np.cos(x), label=<span class="string">"cos"</span>)

<span class="comment"># 스타일 지정</span>
ax.plot(x, np.sin(x),
        color=<span class="string">"#E63946"</span>,      <span class="comment"># HEX, 이름("red"), RGB튜플 모두 가능</span>
        linewidth=<span class="number">2.5</span>,        <span class="comment"># 선 굵기</span>
        linestyle=<span class="string">"--"</span>,       <span class="comment"># 선 스타일: -, --, -., :</span>
        marker=<span class="string">"o"</span>,           <span class="comment"># 마커: o, s, ^, *, +, x, D</span>
        markersize=<span class="number">5</span>,
        markevery=<span class="number">10</span>,         <span class="comment"># 10개마다 마커 표시</span>
        alpha=<span class="number">0.8</span>,            <span class="comment"># 투명도 0~1</span>
        label=<span class="string">"sin (styled)"</span>)

<span class="comment"># 단축 포맷 문자열  "색상마커선스타일"</span>
ax.plot(x, np.cos(x), <span class="string">"g^--"</span>)   <span class="comment"># 초록 삼각 점선</span>
ax.plot(x, -np.sin(x), <span class="string">"rs:"</span>)   <span class="comment"># 빨강 사각 점선</span>

<span class="comment"># 음영 영역</span>
ax.fill_between(x, np.sin(x), <span class="number">0</span>,
                where=np.sin(x) > <span class="number">0</span>,
                alpha=<span class="number">0.2</span>, color=<span class="string">"blue"</span>, label=<span class="string">"양수 영역"</span>)

<span class="comment"># 수평/수직 보조선</span>
ax.axhline(y=<span class="number">0</span>,   color=<span class="string">"black"</span>, linewidth=<span class="number">0.8</span>)   <span class="comment"># 수평선</span>
ax.axvline(x=np.pi, color=<span class="string">"gray"</span>, linestyle=<span class="string">":"</span>)    <span class="comment"># 수직선</span>
ax.axhspan(<span class="number">0.5</span>, <span class="number">1.0</span>, alpha=<span class="number">0.1</span>, color=<span class="string">"green"</span>)      <span class="comment"># 수평 영역</span>

ax.legend(loc=<span class="string">"upper right"</span>)  <span class="comment"># 범례 위치</span>
plt.show()
            </div>

            <h4>산점도 (Scatter Plot)</h4>
            <div class="code-block">
rng = np.random.default_rng(<span class="number">42</span>)
x = rng.normal(<span class="number">0</span>, <span class="number">1</span>, <span class="number">200</span>)
y = x * <span class="number">0.8</span> + rng.normal(<span class="number">0</span>, <span class="number">0.5</span>, <span class="number">200</span>)
colors = rng.uniform(<span class="number">0</span>, <span class="number">1</span>, <span class="number">200</span>)  <span class="comment"># 색상 값 (컬러맵 매핑)</span>
sizes  = rng.uniform(<span class="number">20</span>, <span class="number">200</span>, <span class="number">200</span>)  <span class="comment"># 마커 크기</span>

fig, ax = plt.subplots()
sc = ax.scatter(x, y,
                c=colors,          <span class="comment"># 색상 배열 또는 단색</span>
                cmap=<span class="string">"viridis"</span>,   <span class="comment"># 컬러맵</span>
                s=sizes,           <span class="comment"># 마커 크기</span>
                alpha=<span class="number">0.7</span>,
                edgecolors=<span class="string">"white"</span>,
                linewidths=<span class="number">0.5</span>)

fig.colorbar(sc, ax=ax, label=<span class="string">"값"</span>)  <span class="comment"># 컬러바</span>

<span class="comment"># 추세선 (회귀선)</span>
z = np.polyfit(x, y, <span class="number">1</span>)
p = np.poly1d(z)
ax.plot(np.sort(x), p(np.sort(x)), <span class="string">"r--"</span>, linewidth=<span class="number">2</span>, label=<span class="string">"추세선"</span>)
ax.legend()
plt.show()
            </div>

            <h4>막대 그래프 (Bar Chart)</h4>
            <div class="code-block">
categories = [<span class="string">"Python"</span>, <span class="string">"Java"</span>, <span class="string">"C++"</span>, <span class="string">"JS"</span>, <span class="string">"Go"</span>]
values_2023 = [<span class="number">32</span>, <span class="number">17</span>, <span class="number">13</span>, <span class="number">14</span>, <span class="number">9</span>]
values_2024 = [<span class="number">35</span>, <span class="number">16</span>, <span class="number">12</span>, <span class="number">15</span>, <span class="number">11</span>]

fig, axes = plt.subplots(<span class="number">1</span>, <span class="number">3</span>, figsize=(<span class="number">14</span>, <span class="number">4</span>))

<span class="comment"># ① 단순 막대</span>
x = np.arange(<span class="builtin">len</span>(categories))
axes[<span class="number">0</span>].bar(categories, values_2024,
            color=<span class="string">"steelblue"</span>, edgecolor=<span class="string">"white"</span>, width=<span class="number">0.6</span>)
axes[<span class="number">0</span>].set_title(<span class="string">"단순 막대"</span>)

<span class="comment"># ② 그룹 막대</span>
w = <span class="number">0.35</span>
axes[<span class="number">1</span>].bar(x - w/<span class="number">2</span>, values_2023, w, label=<span class="string">"2023"</span>, color=<span class="string">"#457b9d"</span>)
axes[<span class="number">1</span>].bar(x + w/<span class="number">2</span>, values_2024, w, label=<span class="string">"2024"</span>, color=<span class="string">"#e63946"</span>)
axes[<span class="number">1</span>].set_xticks(x)
axes[<span class="number">1</span>].set_xticklabels(categories)
axes[<span class="number">1</span>].legend()
axes[<span class="number">1</span>].set_title(<span class="string">"그룹 막대"</span>)

<span class="comment"># ③ 수평 막대</span>
axes[<span class="number">2</span>].barh(categories, values_2024, color=<span class="string">"coral"</span>)
axes[<span class="number">2</span>].set_title(<span class="string">"수평 막대"</span>)

<span class="comment"># 막대 위에 값 표시</span>
<span class="keyword">for</span> ax, vals <span class="keyword">in</span> zip(axes[:<span class="number">2</span>], [values_2024, values_2024]):
    <span class="keyword">for</span> bar <span class="keyword">in</span> ax.patches:
        ax.text(bar.get_x() + bar.get_width()/<span class="number">2</span>,
                bar.get_height() + <span class="number">0.3</span>,
                <span class="builtin">str</span>(<span class="builtin">int</span>(bar.get_height())),
                ha=<span class="string">"center"</span>, va=<span class="string">"bottom"</span>, fontsize=<span class="number">9</span>)

plt.tight_layout()
plt.show()
            </div>

            <h4>히스토그램 &amp; KDE (분포)</h4>
            <div class="code-block">
rng = np.random.default_rng(<span class="number">0</span>)
data1 = rng.normal(<span class="number">0</span>, <span class="number">1</span>, <span class="number">1000</span>)
data2 = rng.normal(<span class="number">3</span>, <span class="number">1.5</span>, <span class="number">600</span>)

fig, axes = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">12</span>, <span class="number">4</span>))

<span class="comment"># 기본 히스토그램</span>
axes[<span class="number">0</span>].hist(data1,
             bins=<span class="number">40</span>,               <span class="comment"># 구간 수, 또는 "auto","fd","scott"</span>
             density=<span class="keyword">True</span>,          <span class="comment"># 정규화 (면적=1)</span>
             alpha=<span class="number">0.6</span>,
             color=<span class="string">"steelblue"</span>,
             edgecolor=<span class="string">"white"</span>,
             label=<span class="string">"그룹A"</span>)
axes[<span class="number">0</span>].hist(data2, bins=<span class="number">40</span>, density=<span class="keyword">True</span>, alpha=<span class="number">0.6</span>,
             color=<span class="string">"coral"</span>, edgecolor=<span class="string">"white"</span>, label=<span class="string">"그룹B"</span>)

<span class="comment"># 정규 분포 PDF 오버레이</span>
<span class="keyword">from</span> scipy.stats <span class="keyword">import</span> norm
xr = np.linspace(-<span class="number">4</span>, <span class="number">8</span>, <span class="number">300</span>)
axes[<span class="number">0</span>].plot(xr, norm.pdf(xr, <span class="number">0</span>, <span class="number">1</span>), <span class="string">"b-"</span>, linewidth=<span class="number">2</span>)
axes[<span class="number">0</span>].legend()
axes[<span class="number">0</span>].set_title(<span class="string">"히스토그램 (density=True)"</span>)

<span class="comment"># 2D 히스토그램</span>
x2 = rng.normal(<span class="number">0</span>, <span class="number">1</span>, <span class="number">3000</span>)
y2 = x2 * <span class="number">0.7</span> + rng.normal(<span class="number">0</span>, <span class="number">0.5</span>, <span class="number">3000</span>)
h = axes[<span class="number">1</span>].hist2d(x2, y2, bins=<span class="number">40</span>, cmap=<span class="string">"Blues"</span>)
fig.colorbar(h[<span class="number">3</span>], ax=axes[<span class="number">1</span>], label=<span class="string">"빈도"</span>)
axes[<span class="number">1</span>].set_title(<span class="string">"2D 히스토그램"</span>)

plt.tight_layout()
plt.show()
            </div>

            <h4>박스 플롯 &amp; 바이올린 플롯</h4>
            <div class="code-block">
rng = np.random.default_rng(<span class="number">1</span>)
data = [rng.normal(mu, <span class="number">1</span>, <span class="number">100</span>) <span class="keyword">for</span> mu <span class="keyword">in</span> [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]]
labels = [<span class="string">"A"</span>, <span class="string">"B"</span>, <span class="string">"C"</span>, <span class="string">"D"</span>]

fig, (ax1, ax2) = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">12</span>, <span class="number">5</span>))

<span class="comment"># 박스 플롯 — Q1/Q2/Q3, 수염(1.5IQR), 이상치</span>
bp = ax1.boxplot(data,
                 labels=labels,
                 patch_artist=<span class="keyword">True</span>,      <span class="comment"># 박스 채우기</span>
                 notch=<span class="keyword">True</span>,             <span class="comment"># 중앙값 노치</span>
                 showfliers=<span class="keyword">True</span>,         <span class="comment"># 이상치 표시</span>
                 medianprops=dict(color=<span class="string">"red"</span>, linewidth=<span class="number">2</span>))
colors = [<span class="string">"#a8dadc"</span>, <span class="string">"#457b9d"</span>, <span class="string">"#1d3557"</span>, <span class="string">"#e63946"</span>]
<span class="keyword">for</span> patch, color <span class="keyword">in</span> zip(bp[<span class="string">"boxes"</span>], colors):
    patch.set_facecolor(color)
ax1.set_title(<span class="string">"박스 플롯"</span>)

<span class="comment"># 바이올린 플롯 — 분포 모양까지 시각화</span>
vp = ax2.violinplot(data, positions=range(<span class="number">1</span>, <span class="number">5</span>),
                    showmeans=<span class="keyword">True</span>,
                    showmedians=<span class="keyword">True</span>,
                    showextrema=<span class="keyword">True</span>)
<span class="keyword">for</span> body <span class="keyword">in</span> vp[<span class="string">"bodies"</span>]:
    body.set_alpha(<span class="number">0.7</span>)
ax2.set_xticks(range(<span class="number">1</span>, <span class="number">5</span>))
ax2.set_xticklabels(labels)
ax2.set_title(<span class="string">"바이올린 플롯"</span>)

plt.tight_layout()
plt.show()
            </div>

            <h4>파이 &amp; 도넛 차트</h4>
            <div class="code-block">
sizes   = [<span class="number">35</span>, <span class="number">25</span>, <span class="number">20</span>, <span class="number">15</span>, <span class="number">5</span>]
labels  = [<span class="string">"Python"</span>, <span class="string">"Java"</span>, <span class="string">"C++"</span>, <span class="string">"JS"</span>, <span class="string">"기타"</span>]
explode = (<span class="number">0.05</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>)   <span class="comment"># 첫 조각 강조</span>
colors  = [<span class="string">"#3776ab"</span>, <span class="string">"#e76f51"</span>, <span class="string">"#2a9d8f"</span>, <span class="string">"#e9c46a"</span>, <span class="string">"#adb5bd"</span>]

fig, (ax1, ax2) = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">12</span>, <span class="number">5</span>))

<span class="comment"># 파이 차트</span>
wedges, texts, autotexts = ax1.pie(
    sizes,
    labels=labels,
    explode=explode,
    colors=colors,
    autopct=<span class="string">"%1.1f%%"</span>,       <span class="comment"># 퍼센트 표시 형식</span>
    startangle=<span class="number">90</span>,           <span class="comment"># 시작 각도</span>
    counterclock=<span class="keyword">False</span>,      <span class="comment"># 시계 방향</span>
    shadow=<span class="keyword">True</span>
)
<span class="keyword">for</span> at <span class="keyword">in</span> autotexts:
    at.set_fontsize(<span class="number">9</span>)
ax1.set_title(<span class="string">"파이 차트"</span>)

<span class="comment"># 도넛 차트 — wedgeprops로 구멍</span>
ax2.pie(sizes, labels=labels, colors=colors, autopct=<span class="string">"%1.1f%%"</span>,
        startangle=<span class="number">90</span>, counterclock=<span class="keyword">False</span>,
        wedgeprops=dict(width=<span class="number">0.6</span>, edgecolor=<span class="string">"white"</span>))
ax2.text(<span class="number">0</span>, <span class="number">0</span>, <span class="string">"언어\n점유율"</span>, ha=<span class="string">"center"</span>, va=<span class="string">"center"</span>, fontsize=<span class="number">13</span>)
ax2.set_title(<span class="string">"도넛 차트"</span>)

plt.tight_layout()
plt.show()
            </div>

            <h4>히트맵 &amp; 등고선 (Heatmap &amp; Contour)</h4>
            <div class="code-block">
<span class="comment"># 상관 행렬 히트맵</span>
<span class="keyword">import</span> pandas <span class="keyword">as</span> pd
rng = np.random.default_rng(<span class="number">0</span>)
df = pd.DataFrame(rng.normal(<span class="number">0</span>, <span class="number">1</span>, (<span class="number">100</span>, <span class="number">5</span>)), columns=<span class="builtin">list</span>(<span class="string">"ABCDE"</span>))
corr = df.corr()

fig, (ax1, ax2) = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">13</span>, <span class="number">5</span>))

im = ax1.imshow(corr, cmap=<span class="string">"coolwarm"</span>, vmin=-<span class="number">1</span>, vmax=<span class="number">1</span>)
fig.colorbar(im, ax=ax1)

<span class="comment"># 각 셀에 값 표시</span>
<span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="builtin">len</span>(corr)):
    <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="builtin">len</span>(corr)):
        ax1.text(j, i, <span class="string">f"</span>{corr.iloc[i,j]:.2f}<span class="string">"</span>,
                 ha=<span class="string">"center"</span>, va=<span class="string">"center"</span>, fontsize=<span class="number">8</span>)
ax1.set_xticks(range(<span class="builtin">len</span>(corr)))
ax1.set_yticks(range(<span class="builtin">len</span>(corr)))
ax1.set_xticklabels(corr.columns)
ax1.set_yticklabels(corr.columns)
ax1.set_title(<span class="string">"상관 행렬 히트맵"</span>)

<span class="comment"># 등고선 플롯</span>
xg, yg = np.meshgrid(np.linspace(-<span class="number">3</span>, <span class="number">3</span>, <span class="number">100</span>),
                      np.linspace(-<span class="number">3</span>, <span class="number">3</span>, <span class="number">100</span>))
z = np.sin(xg) * np.cos(yg)

cf = ax2.contourf(xg, yg, z, levels=<span class="number">20</span>, cmap=<span class="string">"RdBu_r"</span>)
ax2.contour(xg, yg, z, levels=<span class="number">10</span>, colors=<span class="string">"black"</span>, linewidths=<span class="number">0.5</span>)
fig.colorbar(cf, ax=ax2)
ax2.set_title(<span class="string">"등고선 플롯"</span>)

plt.tight_layout()
plt.show()
            </div>

            <h4>서브플롯 레이아웃 (Subplots Layout)</h4>
            <div class="code-block">
<span class="comment"># ① subplots — 균일 그리드</span>
fig, axes = plt.subplots(<span class="number">2</span>, <span class="number">3</span>, figsize=(<span class="number">14</span>, <span class="number">8</span>),
                         sharex=<span class="keyword">True</span>,   <span class="comment"># X축 공유</span>
                         sharey=<span class="keyword">False</span>,
                         constrained_layout=<span class="keyword">True</span>)  <span class="comment"># tight_layout 대안</span>
axes[<span class="number">0</span>, <span class="number">0</span>].set_title(<span class="string">"(0,0)"</span>)  <span class="comment"># [행, 열] 접근</span>
axes.flat[<span class="number">3</span>].set_title(<span class="string">"index 3"</span>)  <span class="comment"># 1D 인덱스</span>
<span class="keyword">for</span> ax <span class="keyword">in</span> axes.ravel():           <span class="comment"># 전체 순회</span>
    ax.plot(np.random.randn(<span class="number">50</span>))

<span class="comment"># ② subplot_mosaic — 문자 레이아웃 (Matplotlib 3.3+)</span>
layout = [
    [<span class="string">"A"</span>, <span class="string">"A"</span>, <span class="string">"B"</span>],
    [<span class="string">"C"</span>, <span class="string">"D"</span>, <span class="string">"B"</span>],
]
fig, axd = plt.subplot_mosaic(layout, figsize=(<span class="number">12</span>, <span class="number">6</span>),
                               constrained_layout=<span class="keyword">True</span>)
axd[<span class="string">"A"</span>].set_title(<span class="string">"A — 가로 2칸"</span>)
axd[<span class="string">"B"</span>].set_title(<span class="string">"B — 세로 2칸"</span>)

<span class="comment"># ③ GridSpec — 세밀한 비율 제어</span>
<span class="keyword">from</span> matplotlib.gridspec <span class="keyword">import</span> GridSpec
fig = plt.figure(figsize=(<span class="number">12</span>, <span class="number">6</span>))
gs  = GridSpec(<span class="number">2</span>, <span class="number">3</span>, figure=fig, hspace=<span class="number">0.4</span>, wspace=<span class="number">0.3</span>)
ax_top  = fig.add_subplot(gs[<span class="number">0</span>, :])        <span class="comment"># 0행 전체</span>
ax_bl   = fig.add_subplot(gs[<span class="number">1</span>, :<span class="number">2</span>])       <span class="comment"># 1행 0~1열</span>
ax_br   = fig.add_subplot(gs[<span class="number">1</span>, <span class="number">2</span>])        <span class="comment"># 1행 2열</span>
ax_top.set_title(<span class="string">"넓은 상단 차트"</span>)
            </div>

            <h4>텍스트 &amp; 주석 (Text &amp; Annotation)</h4>
            <div class="code-block">
fig, ax = plt.subplots(figsize=(<span class="number">9</span>, <span class="number">5</span>))
x = np.linspace(<span class="number">0</span>, <span class="number">10</span>, <span class="number">100</span>)
ax.plot(x, np.sin(x))

<span class="comment"># 텍스트 (좌표계 기준)</span>
ax.text(<span class="number">1.5</span>, <span class="number">0.9</span>, <span class="string">"피크 근처"</span>,
        fontsize=<span class="number">11</span>, color=<span class="string">"red"</span>,
        ha=<span class="string">"center"</span>, va=<span class="string">"bottom"</span>,
        fontweight=<span class="string">"bold"</span>)

<span class="comment"># 텍스트 (Figure 비율 기준 — 0~1)</span>
fig.text(<span class="number">0.5</span>, <span class="number">0.01</span>, <span class="string">"출처: 예시 데이터"</span>,
         ha=<span class="string">"center"</span>, fontsize=<span class="number">8</span>, color=<span class="string">"gray"</span>)

<span class="comment"># 화살표 주석</span>
ax.annotate(<span class="string">"최대값"</span>,
            xy=(np.pi/<span class="number">2</span>, <span class="number">1.0</span>),       <span class="comment"># 화살표 끝(가리키는 곳)</span>
            xytext=(<span class="number">2.5</span>, <span class="number">0.6</span>),         <span class="comment"># 텍스트 위치</span>
            fontsize=<span class="number">11</span>,
            arrowprops=dict(
                arrowstyle=<span class="string">"->"</span>,
                color=<span class="string">"darkred"</span>,
                lw=<span class="number">1.5</span>
            ))

<span class="comment"># 수식 (LaTeX)</span>
ax.set_title(<span class="string">r"$f(x) = \sin(x)$"</span>, fontsize=<span class="number">14</span>)
ax.text(<span class="number">7</span>, <span class="number">0.5</span>, <span class="string">r"$\frac{d}{dx}\sin x = \cos x$"</span>, fontsize=<span class="number">12</span>)

<span class="comment"># 테두리 박스 텍스트</span>
ax.text(<span class="number">5</span>, -<span class="number">0.8</span>, <span class="string">"박스 텍스트"</span>,
        bbox=dict(boxstyle=<span class="string">"round,pad=0.3"</span>,
                  facecolor=<span class="string">"wheat"</span>, alpha=<span class="number">0.8</span>))
plt.show()
            </div>

            <h4>축 &amp; 눈금 설정</h4>
            <div class="code-block">
fig, axes = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">12</span>, <span class="number">4</span>))

<span class="comment"># 로그 스케일</span>
x = np.logspace(<span class="number">0</span>, <span class="number">4</span>, <span class="number">50</span>)
axes[<span class="number">0</span>].semilogy(x, x**<span class="number">2</span>)           <span class="comment"># Y축 로그</span>
axes[<span class="number">0</span>].set_xscale(<span class="string">"log"</span>)            <span class="comment"># X축도 로그</span>
axes[<span class="number">0</span>].set_title(<span class="string">"로그-로그 스케일"</span>)

<span class="comment"># 눈금 커스터마이징</span>
ax = axes[<span class="number">1</span>]
x2 = np.linspace(<span class="number">0</span>, <span class="number">2</span>*np.pi, <span class="number">100</span>)
ax.plot(x2, np.sin(x2))

<span class="comment"># 주 눈금</span>
ax.set_xticks([<span class="number">0</span>, np.pi/<span class="number">2</span>, np.pi, <span class="number">3</span>*np.pi/<span class="number">2</span>, <span class="number">2</span>*np.pi])
ax.set_xticklabels([<span class="string">"0"</span>, <span class="string">r"$\pi/2$"</span>, <span class="string">r"$\pi$"</span>, <span class="string">r"$3\pi/2$"</span>, <span class="string">r"$2\pi$"</span>])
ax.tick_params(axis=<span class="string">"x"</span>, labelsize=<span class="number">12</span>, rotation=<span class="number">0</span>)

<span class="comment"># 보조 눈금</span>
<span class="keyword">from</span> matplotlib.ticker <span class="keyword">import</span> MultipleLocator, FuncFormatter
ax.xaxis.set_minor_locator(MultipleLocator(np.pi/<span class="number">4</span>))
ax.yaxis.set_major_formatter(FuncFormatter(<span class="keyword">lambda</span> v, _: <span class="string">f"</span>{v:.1f}<span class="string">"</span>))

<span class="comment"># 그리드</span>
ax.grid(<span class="keyword">True</span>, which=<span class="string">"major"</span>, linestyle=<span class="string">"-"</span>,  alpha=<span class="number">0.5</span>)
ax.grid(<span class="keyword">True</span>, which=<span class="string">"minor"</span>, linestyle=<span class="string">":"</span>,  alpha=<span class="number">0.3</span>)
ax.set_title(<span class="string">"눈금 커스터마이징"</span>)

plt.tight_layout()
plt.show()
            </div>

            <h4>스타일 &amp; 테마 (Style &amp; rcParams)</h4>
            <div class="code-block">
<span class="comment"># 사용 가능한 스타일 목록</span>
<span class="builtin">print</span>(plt.style.available)
<span class="comment"># 주요: "seaborn-v0_8", "ggplot", "fivethirtyeight",</span>
<span class="comment">#       "dark_background", "bmh", "Solarize_Light2"</span>

<span class="comment"># 스타일 적용 (전역)</span>
plt.style.use(<span class="string">"seaborn-v0_8-whitegrid"</span>)

<span class="comment"># 블록 안에서만 임시 적용</span>
<span class="keyword">with</span> plt.style.context(<span class="string">"dark_background"</span>):
    fig, ax = plt.subplots()
    ax.plot(np.random.randn(<span class="number">50</span>))
    plt.show()

<span class="comment"># rcParams — 전역 기본값 설정</span>
plt.rcParams.update({
    <span class="string">"font.family"</span>    : <span class="string">"Malgun Gothic"</span>,  <span class="comment"># 한글 폰트 (Windows)</span>
    <span class="string">"font.size"</span>      : <span class="number">11</span>,
    <span class="string">"axes.titlesize"</span> : <span class="number">14</span>,
    <span class="string">"axes.labelsize"</span> : <span class="number">12</span>,
    <span class="string">"lines.linewidth"</span>: <span class="number">2</span>,
    <span class="string">"figure.dpi"</span>     : <span class="number">120</span>,
    <span class="string">"axes.unicode_minus"</span>: <span class="keyword">False</span>,  <span class="comment"># 한글 폰트 마이너스 깨짐 방지</span>
})

<span class="comment"># 한글 폰트 (macOS/Linux)</span>
<span class="keyword">import</span> matplotlib.font_manager <span class="keyword">as</span> fm
<span class="comment"># fm.findSystemFonts(fontpaths=None)  # 설치 폰트 목록</span>
plt.rcParams[<span class="string">"font.family"</span>] = <span class="string">"NanumGothic"</span>   <span class="comment"># macOS 예시</span>

<span class="comment"># 설정 초기화</span>
plt.rcdefaults()
            </div>

            <h4>컬러맵 (Colormap)</h4>
            <div class="code-block">
<span class="comment"># 주요 컬러맵 분류</span>
<span class="comment"># 순차형: viridis, plasma, inferno, magma, Blues, Reds, YlOrRd</span>
<span class="comment"># 발산형: coolwarm, RdBu, bwr, seismic, PiYG</span>
<span class="comment"># 정성형: tab10, tab20, Set1, Set2, Set3, Paired, Accent</span>
<span class="comment"># 반전:   viridis_r, Blues_r  (뒤에 _r)</span>

<span class="comment"># 컬러맵에서 색상 추출</span>
cmap = plt.get_cmap(<span class="string">"tab10"</span>)
colors = [cmap(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5</span>)]  <span class="comment"># 5가지 색상</span>

<span class="comment"># 정규화 (Normalize)</span>
<span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> Normalize, LogNorm, BoundaryNorm
norm = Normalize(vmin=<span class="number">0</span>, vmax=<span class="number">100</span>)     <span class="comment"># 선형</span>
norm = LogNorm(vmin=<span class="number">1</span>, vmax=<span class="number">10000</span>)    <span class="comment"># 로그</span>
norm = BoundaryNorm([<span class="number">0</span>,<span class="number">30</span>,<span class="number">70</span>,<span class="number">100</span>], ncolors=<span class="number">3</span>)  <span class="comment"># 구간별</span>

<span class="comment"># ScalarMappable — colorbar 독립 추가</span>
<span class="keyword">import</span> matplotlib.cm <span class="keyword">as</span> cm
sm = cm.ScalarMappable(cmap=<span class="string">"viridis"</span>, norm=Normalize(<span class="number">0</span>, <span class="number">1</span>))
sm.set_array([])
fig.colorbar(sm, ax=ax, label=<span class="string">"값"</span>)
            </div>

            <h4>3D 플롯</h4>
            <div class="code-block">
<span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D  <span class="comment"># noqa (import 필요)</span>

fig = plt.figure(figsize=(<span class="number">14</span>, <span class="number">5</span>))

<span class="comment"># ① 3D 곡면 플롯</span>
ax1 = fig.add_subplot(<span class="number">131</span>, projection=<span class="string">"3d"</span>)
xg, yg = np.meshgrid(np.linspace(-<span class="number">3</span>, <span class="number">3</span>, <span class="number">60</span>),
                      np.linspace(-<span class="number">3</span>, <span class="number">3</span>, <span class="number">60</span>))
zg = np.sin(np.sqrt(xg**<span class="number">2</span> + yg**<span class="number">2</span>))
surf = ax1.plot_surface(xg, yg, zg,
                         cmap=<span class="string">"viridis"</span>, alpha=<span class="number">0.9</span>,
                         rstride=<span class="number">2</span>, cstride=<span class="number">2</span>)
fig.colorbar(surf, ax=ax1, shrink=<span class="number">0.6</span>)
ax1.set_title(<span class="string">"3D 곡면"</span>)

<span class="comment"># ② 3D 산점도</span>
ax2 = fig.add_subplot(<span class="number">132</span>, projection=<span class="string">"3d"</span>)
rng = np.random.default_rng(<span class="number">0</span>)
xs, ys, zs = rng.normal(<span class="number">0</span>, <span class="number">1</span>, (<span class="number">3</span>, <span class="number">200</span>))
ax2.scatter(xs, ys, zs, c=zs, cmap=<span class="string">"plasma"</span>, s=<span class="number">20</span>, alpha=<span class="number">0.7</span>)
ax2.set_title(<span class="string">"3D 산점도"</span>)

<span class="comment"># ③ 3D 막대</span>
ax3 = fig.add_subplot(<span class="number">133</span>, projection=<span class="string">"3d"</span>)
xpos = [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]
ypos = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]
zpos = np.zeros(<span class="number">6</span>)
dz   = rng.integers(<span class="number">5</span>, <span class="number">20</span>, <span class="number">6</span>)
ax3.bar3d(xpos, ypos, zpos, <span class="number">0.8</span>, <span class="number">0.8</span>, dz, color=<span class="string">"steelblue"</span>, alpha=<span class="number">0.8</span>)
ax3.set_title(<span class="string">"3D 막대"</span>)

plt.tight_layout()
plt.show()
            </div>

            <h4>파일 저장 (savefig)</h4>
            <div class="code-block">
fig, ax = plt.subplots()
ax.plot([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])

<span class="comment"># 기본 저장 — 확장자가 형식 결정</span>
fig.savefig(<span class="string">"chart.png"</span>)
fig.savefig(<span class="string">"chart.pdf"</span>)
fig.savefig(<span class="string">"chart.svg"</span>)   <span class="comment"># 벡터 (웹/인쇄에 좋음)</span>

<span class="comment"># 고품질 PNG</span>
fig.savefig(<span class="string">"chart_hq.png"</span>,
            dpi=<span class="number">300</span>,                 <span class="comment"># 해상도 (화면 72~96, 인쇄 300+)</span>
            bbox_inches=<span class="string">"tight"</span>,    <span class="comment"># 여백 자동 조정 (필수)</span>
            pad_inches=<span class="number">0.1</span>,         <span class="comment"># 테두리 여백</span>
            facecolor=<span class="string">"white"</span>,      <span class="comment"># 배경색</span>
            transparent=<span class="keyword">False</span>)       <span class="comment"># 투명 배경</span>

<span class="comment"># 투명 PNG (배경 없음)</span>
fig.savefig(<span class="string">"chart_transparent.png"</span>, dpi=<span class="number">150</span>,
            bbox_inches=<span class="string">"tight"</span>, transparent=<span class="keyword">True</span>)

<span class="comment"># 메모리 버퍼로 (웹 서버 응답 등)</span>
<span class="keyword">import</span> io
buf = io.BytesIO()
fig.savefig(buf, format=<span class="string">"png"</span>, dpi=<span class="number">150</span>, bbox_inches=<span class="string">"tight"</span>)
buf.seek(<span class="number">0</span>)
image_bytes = buf.getvalue()   <span class="comment"># bytes 객체</span>

plt.close(fig)  <span class="comment"># 메모리 해제 (루프·서버에서 필수)</span>
            </div>

            <h4>Seaborn 연계 (통계 시각화)</h4>
            <div class="code-block">
<span class="comment"># pip install seaborn</span>
<span class="keyword">import</span> seaborn <span class="keyword">as</span> sns

<span class="comment"># Seaborn은 Matplotlib 위에 구축 — ax 인자로 위치 제어</span>
fig, axes = plt.subplots(<span class="number">2</span>, <span class="number">2</span>, figsize=(<span class="number">12</span>, <span class="number">10</span>))

df = sns.load_dataset(<span class="string">"penguins"</span>)  <span class="comment"># 내장 데이터셋</span>

<span class="comment"># 분포 + KDE</span>
sns.histplot(df[<span class="string">"flipper_length_mm"</span>].dropna(),
             kde=<span class="keyword">True</span>, ax=axes[<span class="number">0</span>,<span class="number">0</span>])

<span class="comment"># 범주별 박스</span>
sns.boxplot(x=<span class="string">"species"</span>, y=<span class="string">"body_mass_g"</span>, data=df,
            palette=<span class="string">"Set2"</span>, ax=axes[<span class="number">0</span>,<span class="number">1</span>])

<span class="comment"># 산점도 + 회귀선</span>
sns.regplot(x=<span class="string">"flipper_length_mm"</span>, y=<span class="string">"body_mass_g"</span>,
            data=df, scatter_kws={<span class="string">"alpha"</span>:<span class="number">0.4</span>}, ax=axes[<span class="number">1</span>,<span class="number">0</span>])

<span class="comment"># 히트맵 (상관 행렬)</span>
num_df = df.select_dtypes(include=<span class="string">"number"</span>)
sns.heatmap(num_df.corr(), annot=<span class="keyword">True</span>, fmt=<span class="string">".2f"</span>,
            cmap=<span class="string">"coolwarm"</span>, ax=axes[<span class="number">1</span>,<span class="number">1</span>])

plt.tight_layout()
plt.show()
            </div>

            <h4>주요 차트 선택 가이드</h4>
            <table class="comparison-table">
                <tr><th>목적</th><th>차트 유형</th><th>주요 함수</th></tr>
                <tr><td>시간에 따른 추이</td><td>선 그래프</td><td><code>ax.plot()</code></td></tr>
                <tr><td>두 변수 관계</td><td>산점도</td><td><code>ax.scatter()</code></td></tr>
                <tr><td>범주별 수치 비교</td><td>막대 그래프</td><td><code>ax.bar() / ax.barh()</code></td></tr>
                <tr><td>분포 형태</td><td>히스토그램 / KDE</td><td><code>ax.hist()</code></td></tr>
                <tr><td>분포 요약 + 이상치</td><td>박스 / 바이올린</td><td><code>ax.boxplot() / ax.violinplot()</code></td></tr>
                <tr><td>비율 구성</td><td>파이 / 도넛</td><td><code>ax.pie()</code></td></tr>
                <tr><td>행렬 / 상관관계</td><td>히트맵</td><td><code>ax.imshow() / sns.heatmap()</code></td></tr>
                <tr><td>지리 / 연속 표면</td><td>등고선</td><td><code>ax.contourf()</code></td></tr>
                <tr><td>3차원 데이터</td><td>3D 곡면 / 산점도</td><td><code>ax.plot_surface()</code></td></tr>
            </table>

            <div class="level-guide beginner">
                <div class="level-guide-header">초급자 가이드 - 데이터 과학 시작하기</div>
                <div class="level-guide-content">
                    <p>데이터 과학은 어렵게 느껴질 수 있지만, 단계적으로 접근하면 됩니다:</p>
                    <ul>
                        <li><strong>Jupyter Notebook</strong>: 코드를 한 줄씩 실행하고 결과를 바로 볼 수 있는 대화형 환경입니다. <code>pip install jupyter</code> 후 <code>jupyter notebook</code>으로 시작하세요.</li>
                        <li><strong>학습 순서</strong>: NumPy(배열 다루기) → Pandas(표 데이터 다루기) → Matplotlib(그래프 그리기) 순서로 학습하는 것이 좋습니다.</li>
                        <li><strong>NumPy = 빠른 계산기</strong>: 파이썬 리스트보다 수십 배 빠른 수치 계산을 제공합니다. <code>import numpy as np; arr = np.array([1, 2, 3])</code>로 시작하세요.</li>
                        <li><strong>Pandas = 엑셀 on 파이썬</strong>: CSV 파일을 읽고, 필터링하고, 집계하는 작업을 코드로 합니다. <code>import pandas as pd; df = pd.read_csv("data.csv")</code></li>
                    </ul>
                    <p><strong>팁:</strong> Google Colab을 사용하면 설치 없이 브라우저에서 바로 데이터 과학을 시작할 수 있습니다.</p>
                </div>
            </div>

            <div class="level-guide intermediate">
                <div class="level-guide-header">중급자 가이드 - 데이터 분석 워크플로우</div>
                <div class="level-guide-content">
                    <p>실무 데이터 분석의 표준 워크플로우:</p>
                    <ul>
                        <li><strong>1. 데이터 수집</strong>: <code>pd.read_csv()</code>, <code>pd.read_sql()</code>, API 호출 등으로 데이터를 가져옵니다.</li>
                        <li><strong>2. 탐색적 데이터 분석(EDA)</strong>: <code>df.describe()</code>, <code>df.info()</code>, <code>df.corr()</code>로 데이터의 특성을 파악합니다.</li>
                        <li><strong>3. 전처리</strong>: 결측치 처리(<code>fillna()</code>, <code>dropna()</code>), 이상치 제거, 스케일링(<code>StandardScaler</code>), 인코딩(<code>LabelEncoder</code>, <code>OneHotEncoder</code>)을 수행합니다.</li>
                        <li><strong>4. 시각화</strong>: Seaborn의 <code>heatmap()</code>, <code>pairplot()</code>으로 패턴을 시각적으로 탐색합니다.</li>
                        <li><strong>메모리 최적화</strong>: <code>df.astype({"col": "int32"})</code>로 타입을 다운캐스트하면 메모리를 50-80% 절약합니다. <code>category</code> 타입은 반복 문자열에 효과적입니다.</li>
                    </ul>
                </div>
            </div>

            <div class="level-guide advanced">
                <div class="level-guide-header">고급자 가이드 - 대규모 데이터 처리</div>
                <div class="level-guide-content">
                    <p>Pandas의 한계를 넘어서는 대규모 데이터 처리 기법:</p>
                    <ul>
                        <li><strong>Polars</strong>: Rust로 작성된 차세대 DataFrame 라이브러리로, Pandas보다 5-50배 빠릅니다. Lazy evaluation과 멀티코어 병렬 처리가 기본 내장되어 있습니다.</li>
                        <li><strong>Dask</strong>: Pandas와 동일한 API로 코어 수를 넘는 대용량 데이터를 분산 처리합니다. <code>dask.dataframe</code>은 메모리를 초과하는 데이터도 처리 가능합니다.</li>
                        <li><strong>NumPy 벡터화</strong>: for 루프 대신 배열 연산을 사용하세요. <code>np.where(arr > 0, arr, 0)</code>처럼 조건부 연산도 벡터화합니다. ufunc을 직접 만들려면 <code>np.vectorize()</code> 또는 Numba <code>@vectorize</code>를 사용합니다.</li>
                        <li><strong>GPU 가속</strong>: CuPy(NumPy 호환)와 cuDF(Pandas 호환)로 NVIDIA GPU에서 연산을 수행하면 100배 이상의 속도 향상이 가능합니다.</li>
                        <li><strong>Apache Arrow</strong>: 언어 간 데이터 교환의 표준 메모리 포맷입니다. Pandas 2.0+에서 Arrow 백엔드를 사용하면 문자열 연산이 크게 빨라집니다.</li>
                    </ul>
                </div>
            </div>

        </section>

        <section id="machine-learning">
            <h2>13. 머신러닝</h2>
            <span class="level-badge level-intermediate">중급</span>
            <span class="level-badge level-advanced">고급</span>

            <p>머신러닝(Machine Learning)은 데이터로부터 패턴을 학습하여 예측이나 의사결정을 자동화하는 AI의 핵심 분야입니다. <strong>지도 학습</strong>(분류, 회귀), <strong>비지도 학습</strong>(군집화, 차원 축소), <strong>강화 학습</strong> 세 가지 범주로 나뉘며, 파이썬에서는 scikit-learn이 전통적 ML의 표준 라이브러리입니다.</p>

            <div class="svg-container">
                <!-- 머신러닝 학습 워크플로우 다이어그램 -->
                <svg width="700" height="260" viewBox="0 0 700 260" xmlns="http://www.w3.org/2000/svg">
                    <defs>
                        <marker id="arrow-ml" markerWidth="8" markerHeight="6" refX="8" refY="3" orient="auto">
                            <polygon points="0 0, 8 3, 0 6" fill="#667eea"/>
                        </marker>
                    </defs>

                    <!-- 전체 데이터 -->
                    <rect x="20" y="30" width="120" height="55" rx="10" fill="var(--svg-blue)" stroke="#2196F3" stroke-width="2"/>
                    <text x="80" y="55" text-anchor="middle" fill="var(--svg-blue-text)" font-weight="bold" font-size="12">전체 데이터</text>
                    <text x="80" y="72" text-anchor="middle" fill="var(--text-secondary)" font-size="10">Dataset</text>

                    <!-- 분할 화살표 -->
                    <line x1="140" y1="45" x2="175" y2="30" stroke="#667eea" stroke-width="1.5" marker-end="url(#arrow-ml)"/>
                    <line x1="140" y1="65" x2="175" y2="80" stroke="#667eea" stroke-width="1.5" marker-end="url(#arrow-ml)"/>

                    <!-- 훈련 데이터 -->
                    <rect x="180" y="10" width="105" height="40" rx="8" fill="var(--svg-green)" stroke="#4CAF50" stroke-width="1.5"/>
                    <text x="232" y="35" text-anchor="middle" fill="var(--svg-green-text)" font-weight="bold" font-size="11">훈련 데이터</text>

                    <!-- 테스트 데이터 -->
                    <rect x="180" y="60" width="105" height="40" rx="8" fill="var(--svg-orange)" stroke="#ff9800" stroke-width="1.5"/>
                    <text x="232" y="85" text-anchor="middle" fill="var(--svg-orange-text)" font-weight="bold" font-size="11">테스트 데이터</text>

                    <!-- 훈련 → 모델 -->
                    <line x1="285" y1="30" x2="330" y2="60" stroke="#4CAF50" stroke-width="1.5" marker-end="url(#arrow-ml)"/>

                    <!-- 모델 학습 -->
                    <rect x="335" y="40" width="130" height="55" rx="12" fill="#667eea" stroke="#4a5ae0" stroke-width="2"/>
                    <text x="400" y="63" text-anchor="middle" fill="white" font-weight="bold" font-size="13">모델 학습</text>
                    <text x="400" y="82" text-anchor="middle" fill="rgba(255,255,255,0.8)" font-size="10">fit(X_train, y_train)</text>

                    <!-- 모델 → 예측 -->
                    <line x1="465" y1="67" x2="510" y2="67" stroke="#667eea" stroke-width="2" marker-end="url(#arrow-ml)"/>

                    <!-- 예측 -->
                    <rect x="515" y="40" width="110" height="55" rx="10" fill="var(--svg-pink)" stroke="#e91e63" stroke-width="2"/>
                    <text x="570" y="63" text-anchor="middle" fill="var(--svg-pink-text)" font-weight="bold" font-size="12">예측</text>
                    <text x="570" y="82" text-anchor="middle" fill="var(--text-secondary)" font-size="10">predict(X_test)</text>

                    <!-- 테스트 → 평가 -->
                    <line x1="285" y1="80" x2="510" y2="130" stroke="#ff9800" stroke-width="1.5" stroke-dasharray="4,3"/>

                    <!-- 평가 -->
                    <rect x="515" y="110" width="110" height="55" rx="10" fill="var(--svg-green)" stroke="#4CAF50" stroke-width="2"/>
                    <text x="570" y="133" text-anchor="middle" fill="var(--svg-green-text)" font-weight="bold" font-size="12">평가</text>
                    <text x="570" y="152" text-anchor="middle" fill="var(--text-secondary)" font-size="10">score, metrics</text>

                    <!-- 예측 → 평가 -->
                    <line x1="570" y1="95" x2="570" y2="110" stroke="var(--text-secondary)" stroke-width="1.5" marker-end="url(#arrow-ml)"/>

                    <!-- 머신러닝 분류 범례 -->
                    <rect x="30" y="135" width="170" height="35" rx="6" fill="var(--svg-green)" stroke="#4CAF50" stroke-width="1"/>
                    <text x="115" y="158" text-anchor="middle" fill="var(--svg-green-text)" font-size="11" font-weight="bold">지도 학습 (Supervised)</text>
                    <text x="115" y="185" text-anchor="middle" fill="var(--text-secondary)" font-size="10">분류(Classification), 회귀(Regression)</text>

                    <rect x="220" y="135" width="170" height="35" rx="6" fill="var(--svg-orange)" stroke="#ff9800" stroke-width="1"/>
                    <text x="305" y="158" text-anchor="middle" fill="var(--svg-orange-text)" font-size="11" font-weight="bold">비지도 학습 (Unsupervised)</text>
                    <text x="305" y="185" text-anchor="middle" fill="var(--text-secondary)" font-size="10">군집화(Clustering), 차원 축소</text>

                    <rect x="410" y="135" width="170" height="35" rx="6" fill="var(--svg-pink)" stroke="#e91e63" stroke-width="1"/>
                    <text x="495" y="158" text-anchor="middle" fill="var(--svg-pink-text)" font-size="11" font-weight="bold">강화 학습 (RL)</text>
                    <text x="495" y="185" text-anchor="middle" fill="var(--text-secondary)" font-size="10">에이전트, 보상 기반 학습</text>

                    <!-- 하단 설명 -->
                    <text x="350" y="225" text-anchor="middle" fill="var(--text-muted)" font-size="12">scikit-learn의 fit → predict → score 패턴으로 통일된 머신러닝 워크플로우</text>
                </svg>
            </div>

            <h3>scikit-learn (머신러닝)</h3>

            <p>
                scikit-learn은 파이썬의 대표적인 머신러닝 라이브러리로, 분류·회귀·클러스터링·차원 축소·전처리·모델 선택 등
                전통적 ML 알고리즘을 일관된 <strong>Estimator API</strong>로 제공합니다.
                <code>fit / transform / predict</code> 세 메서드 패턴만 익히면 모든 모델을 같은 방식으로 사용할 수 있습니다.
            </p>

            <div class="tip-box">
                <strong>설치:</strong> <code>pip install scikit-learn</code> &nbsp;|&nbsp;
                버전 확인: <code>sklearn.__version__</code>
            </div>

            <h4>Estimator API 핵심 패턴</h4>
            <div class="code-block">
<span class="comment"># 모든 scikit-learn 객체는 동일한 인터페이스</span>
<span class="comment">#  fit(X, y)        — 학습 (파라미터 추정)</span>
<span class="comment">#  transform(X)     — 변환 (전처리기)</span>
<span class="comment">#  fit_transform(X) — 학습 + 변환 (훈련 데이터에만)</span>
<span class="comment">#  predict(X)       — 예측 (지도학습 모델)</span>
<span class="comment">#  predict_proba(X) — 클래스 확률 반환</span>
<span class="comment">#  score(X, y)      — 기본 평가 지표 (분류: accuracy, 회귀: R²)</span>

<span class="comment"># 중요 규칙: fit은 반드시 훈련 데이터로만, transform은 전체에 적용</span>
<span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler

scaler = StandardScaler()
X_train_sc = scaler.fit_transform(X_train)   <span class="comment"># 훈련: 평균·표준편차 학습 + 변환</span>
X_test_sc  = scaler.transform(X_test)        <span class="comment"># 테스트: 학습된 값으로만 변환</span>
<span class="comment"># ❌ X_test_sc = scaler.fit_transform(X_test)  # 데이터 누수(leakage)!</span>
            </div>

            <h4>내장 데이터셋 &amp; 데이터 분할</h4>
            <div class="code-block">
<span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> (
    load_iris,          <span class="comment"># 붓꽃 분류 (150×4, 3클래스)</span>
    load_digits,        <span class="comment"># 손글씨 숫자 (1797×64, 10클래스)</span>
    load_breast_cancer, <span class="comment"># 유방암 (569×30, 이진분류)</span>
    load_boston,        <span class="comment"># 보스턴 집값 — deprecated, 아래 대체</span>
    fetch_california_housing,  <span class="comment"># 캘리포니아 주택가 (회귀)</span>
    make_classification,       <span class="comment"># 합성 분류 데이터</span>
    make_regression,           <span class="comment"># 합성 회귀 데이터</span>
    make_blobs,                <span class="comment"># 클러스터링용 합성 데이터</span>
    make_moons, make_circles,  <span class="comment"># 비선형 경계 데이터</span>
)

<span class="comment"># 데이터 로드</span>
iris = load_iris()
X, y = iris.data, iris.target   <span class="comment"># numpy 배열</span>
iris.feature_names              <span class="comment"># ['sepal length (cm)', ...]</span>
iris.target_names               <span class="comment"># ['setosa', 'versicolor', 'virginica']</span>

<span class="comment"># 합성 데이터 생성</span>
X, y = make_classification(
    n_samples=<span class="number">1000</span>,
    n_features=<span class="number">20</span>,
    n_informative=<span class="number">10</span>,    <span class="comment"># 실제 유효 특성 수</span>
    n_redundant=<span class="number">5</span>,
    n_classes=<span class="number">3</span>,
    random_state=<span class="number">42</span>
)

<span class="comment"># 데이터 분할</span>
<span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=<span class="number">0.2</span>,        <span class="comment"># 테스트 비율 (0~1)</span>
    random_state=<span class="number">42</span>,     <span class="comment"># 재현성</span>
    stratify=y            <span class="comment"># 클래스 비율 유지 (분류에서 권장)</span>
)

<span class="comment"># 3-way 분할 (훈련 / 검증 / 테스트)</span>
X_tr, X_tmp, y_tr, y_tmp = train_test_split(X, y, test_size=<span class="number">0.3</span>, stratify=y, random_state=<span class="number">42</span>)
X_val, X_test, y_val, y_test = train_test_split(X_tmp, y_tmp, test_size=<span class="number">0.5</span>, stratify=y_tmp, random_state=<span class="number">42</span>)
            </div>

            <h4>전처리 — 스케일링 (Scaling)</h4>
            <table class="comparison-table">
                <tr><th>스케일러</th><th>변환 공식</th><th>특징 / 적합 상황</th></tr>
                <tr><td><code>StandardScaler</code></td><td>(x−μ)/σ</td><td>평균 0, 표준편차 1. 이상치에 민감. 대부분의 모델에 기본</td></tr>
                <tr><td><code>MinMaxScaler</code></td><td>(x−min)/(max−min)</td><td>[0,1] 범위. 이상치에 취약. 신경망·이미지</td></tr>
                <tr><td><code>RobustScaler</code></td><td>(x−중앙값)/IQR</td><td>이상치에 강건. 이상치 많은 데이터</td></tr>
                <tr><td><code>MaxAbsScaler</code></td><td>x/|max(x)|</td><td>[-1,1]. 희소 행렬(Sparse matrix)에 적합</td></tr>
                <tr><td><code>Normalizer</code></td><td>행 단위 L2 정규화</td><td>각 샘플을 단위 벡터로. 텍스트·코사인 유사도</td></tr>
            </table>
            <div class="code-block">
<span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> (
    StandardScaler, MinMaxScaler, RobustScaler,
    MaxAbsScaler, Normalizer, PowerTransformer, QuantileTransformer
)

<span class="comment"># PowerTransformer — 비정규 분포를 정규분포에 가깝게</span>
pt = PowerTransformer(method=<span class="string">"yeo-johnson"</span>)  <span class="comment"># 음수 허용</span>
pt = PowerTransformer(method=<span class="string">"box-cox"</span>)       <span class="comment"># 양수만</span>
X_train_pt = pt.fit_transform(X_train)

<span class="comment"># QuantileTransformer — 균등/정규 분포로 매핑</span>
qt = QuantileTransformer(output_distribution=<span class="string">"normal"</span>, random_state=<span class="number">42</span>)
X_train_qt = qt.fit_transform(X_train)
            </div>

            <h4>전처리 — 인코딩 (Encoding)</h4>
            <div class="code-block">
<span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> (
    LabelEncoder, OrdinalEncoder,
    OneHotEncoder, LabelBinarizer
)

<span class="comment"># LabelEncoder — 타깃(y) 인코딩. 순서 있는 이진 변수</span>
le = LabelEncoder()
y_enc = le.fit_transform([<span class="string">"cat"</span>, <span class="string">"dog"</span>, <span class="string">"cat"</span>, <span class="string">"fish"</span>])
<span class="comment"># → [0, 1, 0, 2]</span>
le.inverse_transform([<span class="number">0</span>, <span class="number">2</span>])   <span class="comment"># → ['cat', 'fish']</span>

<span class="comment"># OrdinalEncoder — 특성(X) 순서형 인코딩</span>
oe = OrdinalEncoder(categories=[[<span class="string">"low"</span>, <span class="string">"mid"</span>, <span class="string">"high"</span>]])
oe.fit_transform([[<span class="string">"low"</span>], [<span class="string">"high"</span>], [<span class="string">"mid"</span>]])  <span class="comment"># → [[0.],[2.],[1.]]</span>

<span class="comment"># OneHotEncoder — 명목형(순서 없는) 인코딩 (권장)</span>
ohe = OneHotEncoder(sparse_output=<span class="keyword">False</span>,       <span class="comment"># dense 배열 반환</span>
                    handle_unknown=<span class="string">"ignore"</span>,    <span class="comment"># 미지 카테고리 → 0</span>
                    drop=<span class="string">"first"</span>)               <span class="comment"># 더미 변수 함정 방지</span>
X_ohe = ohe.fit_transform(X_cat)
ohe.get_feature_names_out()                      <span class="comment"># 새 열 이름</span>
            </div>

            <h4>전처리 — 결측치 &amp; 특성 생성</h4>
            <div class="code-block">
<span class="keyword">from</span> sklearn.impute <span class="keyword">import</span> SimpleImputer, KNNImputer, IterativeImputer
<span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> PolynomialFeatures
<span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> VarianceThreshold

<span class="comment"># SimpleImputer — 통계값으로 채우기</span>
imp_mean   = SimpleImputer(strategy=<span class="string">"mean"</span>)       <span class="comment"># 수치형 (기본)</span>
imp_median = SimpleImputer(strategy=<span class="string">"median"</span>)     <span class="comment"># 이상치 있을 때</span>
imp_mode   = SimpleImputer(strategy=<span class="string">"most_frequent"</span>) <span class="comment"># 범주형</span>
imp_const  = SimpleImputer(strategy=<span class="string">"constant"</span>, fill_value=<span class="number">0</span>)

<span class="comment"># KNNImputer — K-최근접 이웃으로 추정</span>
knn_imp = KNNImputer(n_neighbors=<span class="number">5</span>)

<span class="comment"># IterativeImputer — 반복 회귀 추정 (MICE 알고리즘)</span>
<span class="keyword">from</span> sklearn.experimental <span class="keyword">import</span> enable_iterative_imputer  <span class="comment"># noqa</span>
iter_imp = IterativeImputer(max_iter=<span class="number">10</span>, random_state=<span class="number">42</span>)

<span class="comment"># PolynomialFeatures — 다항 특성 생성 (비선형 관계 포착)</span>
poly = PolynomialFeatures(degree=<span class="number">2</span>, include_bias=<span class="keyword">False</span>,
                           interaction_only=<span class="keyword">False</span>)
<span class="comment"># [a, b] → [a, b, a², ab, b²]</span>
X_poly = poly.fit_transform(X_train)
poly.get_feature_names_out([<span class="string">"x1"</span>, <span class="string">"x2"</span>])

<span class="comment"># VarianceThreshold — 분산 0인 특성(상수) 제거</span>
vt = VarianceThreshold(threshold=<span class="number">0.01</span>)
X_sel = vt.fit_transform(X)
            </div>

            <h4>지도학습 — 회귀 (Regression)</h4>
            <div class="code-block">
<span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> (
    LinearRegression,
    Ridge, Lasso, ElasticNet,   <span class="comment"># 정규화 선형 모델</span>
    HuberRegressor,             <span class="comment"># 이상치에 강건</span>
    BayesianRidge,
)
<span class="keyword">from</span> sklearn.tree     <span class="keyword">import</span> DecisionTreeRegressor
<span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> (
    RandomForestRegressor,
    GradientBoostingRegressor,
    HistGradientBoostingRegressor,  <span class="comment"># 대용량·결측치 허용</span>
    AdaBoostRegressor,
)
<span class="keyword">from</span> sklearn.svm      <span class="keyword">import</span> SVR
<span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsRegressor

<span class="comment"># 선형 회귀</span>
lr = LinearRegression(fit_intercept=<span class="keyword">True</span>)
lr.fit(X_train, y_train)
lr.coef_        <span class="comment"># 계수</span>
lr.intercept_   <span class="comment"># 절편</span>

<span class="comment"># Ridge (L2 정규화) — 다중공선성, 과적합 완화</span>
ridge = Ridge(alpha=<span class="number">1.0</span>)     <span class="comment"># alpha ↑ → 정규화 강도 ↑</span>

<span class="comment"># Lasso (L1 정규화) — 특성 선택 효과 (계수 → 0)</span>
lasso = Lasso(alpha=<span class="number">0.1</span>, max_iter=<span class="number">5000</span>)

<span class="comment"># ElasticNet (L1+L2) — Lasso와 Ridge 혼합</span>
en = ElasticNet(alpha=<span class="number">0.1</span>, l1_ratio=<span class="number">0.5</span>)

<span class="comment"># GradientBoosting — 순차 부스팅, 높은 정확도</span>
gbr = GradientBoostingRegressor(
    n_estimators=<span class="number">200</span>,
    learning_rate=<span class="number">0.05</span>,
    max_depth=<span class="number">4</span>,
    subsample=<span class="number">0.8</span>,
    random_state=<span class="number">42</span>
)
gbr.fit(X_train, y_train)
            </div>

            <h4>지도학습 — 분류 (Classification)</h4>
            <div class="code-block">
<span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression, SGDClassifier
<span class="keyword">from</span> sklearn.svm          <span class="keyword">import</span> SVC, LinearSVC
<span class="keyword">from</span> sklearn.neighbors    <span class="keyword">import</span> KNeighborsClassifier
<span class="keyword">from</span> sklearn.tree         <span class="keyword">import</span> DecisionTreeClassifier
<span class="keyword">from</span> sklearn.ensemble     <span class="keyword">import</span> (
    RandomForestClassifier,
    GradientBoostingClassifier,
    HistGradientBoostingClassifier,
    AdaBoostClassifier,
    ExtraTreesClassifier,
)
<span class="keyword">from</span> sklearn.naive_bayes  <span class="keyword">import</span> GaussianNB, MultinomialNB
<span class="keyword">from</span> sklearn.discriminant_analysis <span class="keyword">import</span> LinearDiscriminantAnalysis

<span class="comment"># 로지스틱 회귀</span>
lr = LogisticRegression(C=<span class="number">1.0</span>,             <span class="comment"># C=1/alpha (C↑ → 정규화 약해짐)</span>
                        penalty=<span class="string">"l2"</span>,        <span class="comment"># "l1","l2","elasticnet"</span>
                        solver=<span class="string">"lbfgs"</span>,      <span class="comment"># 다중분류: "lbfgs","saga"</span>
                        multi_class=<span class="string">"auto"</span>,
                        max_iter=<span class="number">1000</span>)

<span class="comment"># SVM (Support Vector Machine)</span>
svc = SVC(C=<span class="number">1.0</span>,
          kernel=<span class="string">"rbf"</span>,       <span class="comment"># "linear","poly","rbf","sigmoid"</span>
          gamma=<span class="string">"scale"</span>,     <span class="comment"># "scale"=1/(n_features*X.var())</span>
          probability=<span class="keyword">True</span>)  <span class="comment"># predict_proba 활성화 (속도 저하)</span>

<span class="comment"># K-최근접 이웃</span>
knn = KNeighborsClassifier(n_neighbors=<span class="number">5</span>,
                            weights=<span class="string">"distance"</span>,  <span class="comment"># "uniform" or "distance"</span>
                            metric=<span class="string">"minkowski"</span>)   <span class="comment"># "euclidean","manhattan"</span>

<span class="comment"># 랜덤 포레스트</span>
rf = RandomForestClassifier(
    n_estimators=<span class="number">200</span>,         <span class="comment"># 트리 수 (많을수록 안정, 느려짐)</span>
    max_depth=<span class="keyword">None</span>,           <span class="comment"># None이면 완전 성장</span>
    max_features=<span class="string">"sqrt"</span>,     <span class="comment"># 분기 시 고려 특성 수</span>
    min_samples_leaf=<span class="number">1</span>,
    class_weight=<span class="string">"balanced"</span>, <span class="comment"># 클래스 불균형 처리</span>
    n_jobs=-<span class="number">1</span>,                <span class="comment"># 모든 CPU 코어 사용</span>
    random_state=<span class="number">42</span>
)
rf.fit(X_train, y_train)
rf.feature_importances_      <span class="comment"># 특성 중요도</span>

<span class="comment"># Gradient Boosting</span>
hgb = HistGradientBoostingClassifier(
    max_iter=<span class="number">200</span>,
    learning_rate=<span class="number">0.05</span>,
    max_leaf_nodes=<span class="number">31</span>,
    min_samples_leaf=<span class="number">20</span>
)
<span class="comment"># HistGradientBoosting은 결측치(NaN)를 자체 처리</span>
            </div>

            <h4>비지도학습 — 클러스터링</h4>
            <div class="code-block">
<span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> (
    KMeans, MiniBatchKMeans,
    DBSCAN, HDBSCAN,
    AgglomerativeClustering,
    SpectralClustering,
)

<span class="comment"># K-Means</span>
km = KMeans(n_clusters=<span class="number">3</span>,
            init=<span class="string">"k-means++"</span>,  <span class="comment"># 초기 중심 선택 (수렴 빠름)</span>
            n_init=<span class="number">10</span>,          <span class="comment"># 시작 횟수 (최선 결과 반환)</span>
            max_iter=<span class="number">300</span>,
            random_state=<span class="number">42</span>)
km.fit(X)
km.labels_          <span class="comment"># 각 샘플의 클러스터 번호</span>
km.cluster_centers_ <span class="comment"># 클러스터 중심 좌표</span>
km.inertia_         <span class="comment"># Within-cluster sum of squares (낮을수록 좋음)</span>

<span class="comment"># 최적 K 찾기 — 엘보우 방법</span>
inertias = []
<span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">11</span>):
    inertias.append(KMeans(n_clusters=k, random_state=<span class="number">42</span>, n_init=<span class="number">10</span>)
                    .fit(X).inertia_)

<span class="comment"># DBSCAN — 밀도 기반, 이상치 자동 감지</span>
db = DBSCAN(eps=<span class="number">0.5</span>,         <span class="comment"># 이웃 반경</span>
            min_samples=<span class="number">5</span>,     <span class="comment"># 핵심 포인트 최소 이웃 수</span>
            metric=<span class="string">"euclidean"</span>)
db.fit(X)
db.labels_   <span class="comment"># -1 = 이상치(noise)</span>

<span class="comment"># 계층적 클러스터링</span>
agg = AgglomerativeClustering(n_clusters=<span class="number">3</span>,
                               linkage=<span class="string">"ward"</span>)  <span class="comment"># "average","complete","single"</span>
agg.fit(X)
            </div>

            <h4>비지도학습 — 차원 축소</h4>
            <div class="code-block">
<span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA, TruncatedSVD, NMF
<span class="keyword">from</span> sklearn.manifold    <span class="keyword">import</span> TSNE
<span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler

<span class="comment"># PCA (Principal Component Analysis)</span>
pca = PCA(n_components=<span class="number">2</span>)       <span class="comment"># 고정 차원 수</span>
pca = PCA(n_components=<span class="number">0.95</span>)    <span class="comment"># 분산 95% 보존에 필요한 차원 수</span>
pca = PCA(n_components=<span class="string">"mle"</span>)   <span class="comment"># MLE로 자동 결정</span>
X_pca = pca.fit_transform(StandardScaler().fit_transform(X))
pca.explained_variance_ratio_    <span class="comment"># 각 PC의 설명 분산 비율</span>
pca.components_                  <span class="comment"># 주성분 벡터 (로딩)</span>
<span class="builtin">print</span>(<span class="string">f"보존 분산: </span>{pca.explained_variance_ratio_.sum():.3f}<span class="string">"</span>)

<span class="comment"># TruncatedSVD — 희소 행렬에 적합 (PCA 대안)</span>
svd = TruncatedSVD(n_components=<span class="number">50</span>)
X_svd = svd.fit_transform(X_sparse)

<span class="comment"># t-SNE — 시각화 전용 (2D/3D), 비볼록 최적화</span>
tsne = TSNE(n_components=<span class="number">2</span>,
            perplexity=<span class="number">30</span>,        <span class="comment"># 이웃 수 목표 (5~50)</span>
            n_iter=<span class="number">1000</span>,
            learning_rate=<span class="string">"auto"</span>,
            init=<span class="string">"pca"</span>,           <span class="comment"># PCA 초기화 (안정적)</span>
            random_state=<span class="number">42</span>)
X_tsne = tsne.fit_transform(X)   <span class="comment"># fit_transform만 제공 (transform 없음)</span>
            </div>

            <h4>모델 평가 지표 (Metrics)</h4>
            <div class="code-block">
<span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> (
    <span class="comment"># 회귀</span>
    mean_squared_error, root_mean_squared_error,
    mean_absolute_error, mean_absolute_percentage_error,
    r2_score, explained_variance_score,
    <span class="comment"># 분류</span>
    accuracy_score, balanced_accuracy_score,
    precision_score, recall_score, f1_score,
    classification_report, confusion_matrix, ConfusionMatrixDisplay,
    roc_auc_score, roc_curve, average_precision_score,
    log_loss,
    <span class="comment"># 클러스터링</span>
    silhouette_score, davies_bouldin_score,
    adjusted_rand_score,
)

<span class="comment"># ─── 회귀 평가 ────────────────────────────────────────────</span>
mse  = mean_squared_error(y_test, y_pred)
rmse = root_mean_squared_error(y_test, y_pred)   <span class="comment"># sklearn 1.4+</span>
mae  = mean_absolute_error(y_test, y_pred)
mape = mean_absolute_percentage_error(y_test, y_pred)  <span class="comment"># 비율 오차</span>
r2   = r2_score(y_test, y_pred)                  <span class="comment"># 1.0 = 완벽, 음수 = 기준선 이하</span>

<span class="comment"># ─── 분류 평가 ────────────────────────────────────────────</span>
acc  = accuracy_score(y_test, y_pred)
bacc = balanced_accuracy_score(y_test, y_pred)   <span class="comment"># 클래스 불균형 시 권장</span>
prec = precision_score(y_test, y_pred, average=<span class="string">"weighted"</span>)
rec  = recall_score(y_test,  y_pred, average=<span class="string">"macro"</span>)
f1   = f1_score(y_test, y_pred, average=<span class="string">"macro"</span>)
<span class="comment"># average: "binary","micro","macro","weighted","samples"</span>

<span class="comment"># 전체 리포트</span>
<span class="builtin">print</span>(classification_report(y_test, y_pred, target_names=iris.target_names))

<span class="comment"># 혼동 행렬</span>
cm = confusion_matrix(y_test, y_pred)
ConfusionMatrixDisplay(cm, display_labels=iris.target_names).plot()

<span class="comment"># ROC-AUC (이진 분류)</span>
y_prob = clf.predict_proba(X_test)[:, <span class="number">1</span>]
auc    = roc_auc_score(y_test, y_prob)
fpr, tpr, thresholds = roc_curve(y_test, y_prob)

<span class="comment"># ROC-AUC (다중 분류)</span>
y_prob_multi = clf.predict_proba(X_test)
auc_multi = roc_auc_score(y_test, y_prob_multi, multi_class=<span class="string">"ovr"</span>, average=<span class="string">"macro"</span>)
            </div>

            <h4>교차 검증 (Cross Validation)</h4>
            <div class="code-block">
<span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> (
    cross_val_score, cross_validate,
    KFold, StratifiedKFold, RepeatedStratifiedKFold,
    LeaveOneOut, GroupKFold,
)

<span class="comment"># cross_val_score — 단일 지표</span>
scores = cross_val_score(
    RandomForestClassifier(random_state=<span class="number">42</span>), X, y,
    cv=<span class="number">5</span>,              <span class="comment"># 5-fold</span>
    scoring=<span class="string">"f1_macro"</span>,
    n_jobs=-<span class="number">1</span>
)
<span class="builtin">print</span>(<span class="string">f"F1: </span>{scores.mean():.4f}<span class="string"> ± </span>{scores.std():.4f}<span class="string">"</span>)

<span class="comment"># cross_validate — 여러 지표 + 훈련 점수</span>
cv_res = cross_validate(
    RandomForestClassifier(random_state=<span class="number">42</span>), X, y,
    cv=<span class="number">5</span>,
    scoring=[<span class="string">"accuracy"</span>, <span class="string">"f1_macro"</span>, <span class="string">"roc_auc_ovr"</span>],
    return_train_score=<span class="keyword">True</span>
)

<span class="comment"># StratifiedKFold — 클래스 비율 유지 (분류 기본 권장)</span>
skf = StratifiedKFold(n_splits=<span class="number">5</span>, shuffle=<span class="keyword">True</span>, random_state=<span class="number">42</span>)
<span class="keyword">for</span> fold, (tr_idx, val_idx) <span class="keyword">in</span> <span class="builtin">enumerate</span>(skf.split(X, y)):
    X_tr, X_val = X[tr_idx], X[val_idx]
    y_tr, y_val = y[tr_idx], y[val_idx]
    <span class="comment"># 모델 학습/평가</span>

<span class="comment"># RepeatedStratifiedKFold — k-fold를 n번 반복</span>
rskf = RepeatedStratifiedKFold(n_splits=<span class="number">5</span>, n_repeats=<span class="number">3</span>, random_state=<span class="number">42</span>)
<span class="comment"># → 총 15번 평가로 분산 감소</span>

<span class="comment"># LeaveOneOut — 소규모 데이터</span>
loo_scores = cross_val_score(clf, X, y, cv=LeaveOneOut(), scoring=<span class="string">"accuracy"</span>)
            </div>

            <h4>하이퍼파라미터 튜닝</h4>
            <div class="code-block">
<span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> (
    GridSearchCV, RandomizedSearchCV, HalvingGridSearchCV
)
<span class="keyword">from</span> scipy.stats <span class="keyword">import</span> randint, uniform, loguniform

<span class="comment"># GridSearchCV — 격자 탐색 (전수 조사)</span>
param_grid = {
    <span class="string">"n_estimators"</span> : [<span class="number">100</span>, <span class="number">200</span>, <span class="number">300</span>],
    <span class="string">"max_depth"</span>    : [<span class="keyword">None</span>, <span class="number">5</span>, <span class="number">10</span>],
    <span class="string">"max_features"</span> : [<span class="string">"sqrt"</span>, <span class="string">"log2"</span>],
}
grid = GridSearchCV(
    RandomForestClassifier(random_state=<span class="number">42</span>),
    param_grid,
    cv=<span class="number">5</span>, scoring=<span class="string">"f1_macro"</span>, n_jobs=-<span class="number">1</span>, verbose=<span class="number">1</span>
)
grid.fit(X_train, y_train)
grid.best_params_   <span class="comment"># 최적 파라미터</span>
grid.best_score_    <span class="comment"># 교차 검증 최고 점수</span>
grid.best_estimator_.predict(X_test)

<span class="comment"># RandomizedSearchCV — 무작위 탐색 (시간 절약)</span>
param_dist = {
    <span class="string">"n_estimators"</span> : randint(<span class="number">50</span>, <span class="number">500</span>),
    <span class="string">"max_depth"</span>    : [<span class="keyword">None</span>, <span class="number">5</span>, <span class="number">10</span>, <span class="number">20</span>],
    <span class="string">"max_features"</span> : uniform(<span class="number">0.1</span>, <span class="number">0.9</span>),
    <span class="string">"min_samples_leaf"</span>: randint(<span class="number">1</span>, <span class="number">10</span>),
}
rand = RandomizedSearchCV(
    RandomForestClassifier(random_state=<span class="number">42</span>),
    param_dist,
    n_iter=<span class="number">50</span>,        <span class="comment"># 시도 횟수</span>
    cv=<span class="number">5</span>, scoring=<span class="string">"f1_macro"</span>, n_jobs=-<span class="number">1</span>, random_state=<span class="number">42</span>
)
rand.fit(X_train, y_train)

<span class="comment"># HalvingGridSearchCV — 예산 절반씩 할당 (빠름, sklearn 0.24+)</span>
halving = HalvingGridSearchCV(
    RandomForestClassifier(random_state=<span class="number">42</span>), param_grid,
    cv=<span class="number">5</span>, factor=<span class="number">2</span>, resource=<span class="string">"n_samples"</span>, random_state=<span class="number">42</span>
)
            </div>

            <h4>파이프라인 (Pipeline)</h4>
            <div class="code-block">
<span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline, make_pipeline
<span class="keyword">from</span> sklearn.compose  <span class="keyword">import</span> ColumnTransformer, make_column_selector

<span class="comment"># 기본 파이프라인 — 전처리 + 모델을 하나로</span>
pipe = Pipeline([
    (<span class="string">"scaler"</span>, StandardScaler()),
    (<span class="string">"pca"</span>,    PCA(n_components=<span class="number">10</span>)),
    (<span class="string">"clf"</span>,    RandomForestClassifier(random_state=<span class="number">42</span>)),
])
pipe.fit(X_train, y_train)
pipe.predict(X_test)
pipe.score(X_test, y_test)

<span class="comment"># make_pipeline — 이름 자동 지정 (간편 버전)</span>
pipe = make_pipeline(StandardScaler(), LogisticRegression())

<span class="comment"># Pipeline + GridSearchCV — 파이프라인 파라미터 탐색</span>
param_grid = {
    <span class="string">"pca__n_components"</span>         : [<span class="number">5</span>, <span class="number">10</span>, <span class="number">20</span>],
    <span class="string">"clf__n_estimators"</span>         : [<span class="number">100</span>, <span class="number">200</span>],
    <span class="string">"clf__max_depth"</span>            : [<span class="keyword">None</span>, <span class="number">5</span>],
}   <span class="comment"># 단계명__파라미터명 형식</span>
grid_pipe = GridSearchCV(pipe, param_grid, cv=<span class="number">5</span>, n_jobs=-<span class="number">1</span>)

<span class="comment"># ColumnTransformer — 열 유형별 전처리</span>
num_features = [<span class="string">"age"</span>, <span class="string">"income"</span>, <span class="string">"score"</span>]
cat_features = [<span class="string">"gender"</span>, <span class="string">"city"</span>, <span class="string">"grade"</span>]

preprocessor = ColumnTransformer(transformers=[
    (<span class="string">"num"</span>, StandardScaler(),                      num_features),
    (<span class="string">"cat"</span>, OneHotEncoder(handle_unknown=<span class="string">"ignore"</span>), cat_features),
], remainder=<span class="string">"drop"</span>)    <span class="comment"># 나머지 열 처리: "drop","passthrough"</span>

full_pipe = Pipeline([
    (<span class="string">"prep"</span>, preprocessor),
    (<span class="string">"clf"</span>,  RandomForestClassifier(n_jobs=-<span class="number">1</span>, random_state=<span class="number">42</span>)),
])
full_pipe.fit(X_train_df, y_train)
            </div>

            <h4>특성 선택 (Feature Selection)</h4>
            <div class="code-block">
<span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> (
    SelectKBest, SelectPercentile,
    f_classif, chi2, mutual_info_classif,    <span class="comment"># 분류 점수 함수</span>
    f_regression, mutual_info_regression,    <span class="comment"># 회귀 점수 함수</span>
    RFE, RFECV,                              <span class="comment"># 재귀적 특성 제거</span>
    SelectFromModel,                         <span class="comment"># 모델 기반 선택</span>
)

<span class="comment"># 통계 기반 — 상위 K개 특성 선택</span>
skb = SelectKBest(score_func=f_classif, k=<span class="number">10</span>)
X_new = skb.fit_transform(X_train, y_train)
skb.get_support()           <span class="comment"># 선택된 특성 bool 마스크</span>
skb.scores_                 <span class="comment"># 각 특성의 점수</span>
skb.get_feature_names_out() <span class="comment"># 선택된 특성 이름 (sklearn 1.0+)</span>

<span class="comment"># RFE — 재귀적 특성 제거</span>
rfe = RFE(estimator=LogisticRegression(), n_features_to_select=<span class="number">10</span>, step=<span class="number">1</span>)
rfe.fit(X_train, y_train)
rfe.ranking_    <span class="comment"># 특성 순위 (1 = 선택됨)</span>
rfe.support_    <span class="comment"># 선택된 특성 bool</span>

<span class="comment"># RFECV — 교차 검증으로 최적 특성 수 자동 결정</span>
rfecv = RFECV(LogisticRegression(), cv=<span class="number">5</span>, scoring=<span class="string">"accuracy"</span>, n_jobs=-<span class="number">1</span>)
rfecv.fit(X_train, y_train)
rfecv.n_features_  <span class="comment"># 선택된 최적 특성 수</span>

<span class="comment"># 모델 기반 — 트리/선형모델 feature_importances_ 활용</span>
sfm = SelectFromModel(RandomForestClassifier(n_estimators=<span class="number">100</span>, random_state=<span class="number">42</span>),
                      threshold=<span class="string">"median"</span>)  <span class="comment"># 중앙값 이상 중요도만 선택</span>
sfm.fit(X_train, y_train)
X_selected = sfm.transform(X_train)
            </div>

            <h4>앙상블 (Ensemble)</h4>
            <div class="code-block">
<span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> (
    VotingClassifier, VotingRegressor,
    StackingClassifier, StackingRegressor,
    BaggingClassifier,
)

<span class="comment"># VotingClassifier — 여러 모델의 다수결 / 평균</span>
voting = VotingClassifier(estimators=[
    (<span class="string">"lr"</span>,  LogisticRegression(max_iter=<span class="number">1000</span>)),
    (<span class="string">"svc"</span>, SVC(probability=<span class="keyword">True</span>)),
    (<span class="string">"rf"</span>,  RandomForestClassifier(n_estimators=<span class="number">100</span>, random_state=<span class="number">42</span>)),
],
voting=<span class="string">"soft"</span>,    <span class="comment"># "hard"=다수결, "soft"=확률 평균 (일반적으로 성능 우수)</span>
n_jobs=-<span class="number">1</span>)
voting.fit(X_train, y_train)

<span class="comment"># StackingClassifier — 메타 학습기 (2단계)</span>
estimators = [
    (<span class="string">"lr"</span>,  LogisticRegression(max_iter=<span class="number">1000</span>)),
    (<span class="string">"rf"</span>,  RandomForestClassifier(n_estimators=<span class="number">100</span>, random_state=<span class="number">42</span>)),
    (<span class="string">"svc"</span>, SVC(probability=<span class="keyword">True</span>)),
]
stacking = StackingClassifier(
    estimators=estimators,
    final_estimator=LogisticRegression(),  <span class="comment"># 메타 학습기</span>
    cv=<span class="number">5</span>,
    passthrough=<span class="keyword">False</span>  <span class="comment"># True이면 원본 특성도 메타 학습기에 전달</span>
)

<span class="comment"># BaggingClassifier — 부트스트랩 앙상블</span>
bag = BaggingClassifier(
    estimator=DecisionTreeClassifier(),
    n_estimators=<span class="number">100</span>,
    max_samples=<span class="number">0.8</span>,   <span class="comment"># 훈련 샘플 비율</span>
    max_features=<span class="number">0.8</span>,  <span class="comment"># 특성 비율</span>
    bootstrap=<span class="keyword">True</span>,
    n_jobs=-<span class="number">1</span>,
    random_state=<span class="number">42</span>
)
            </div>

            <h4>모델 저장 &amp; 불러오기</h4>
            <div class="code-block">
<span class="keyword">import</span> joblib
<span class="keyword">import</span> pickle

<span class="comment"># joblib — sklearn 모델에 권장 (numpy 배열 효율적)</span>
joblib.dump(model, <span class="string">"model.joblib"</span>)             <span class="comment"># 저장</span>
loaded_model = joblib.load(<span class="string">"model.joblib"</span>)      <span class="comment"># 불러오기</span>
loaded_model.predict(X_test)

<span class="comment"># 압축 저장</span>
joblib.dump(model, <span class="string">"model.joblib.gz"</span>, compress=<span class="number">3</span>)

<span class="comment"># pickle — 표준 라이브러리</span>
<span class="keyword">with</span> <span class="builtin">open</span>(<span class="string">"model.pkl"</span>, <span class="string">"wb"</span>) <span class="keyword">as</span> f:
    pickle.dump(model, f)
<span class="keyword">with</span> <span class="builtin">open</span>(<span class="string">"model.pkl"</span>, <span class="string">"rb"</span>) <span class="keyword">as</span> f:
    loaded = pickle.load(f)

<span class="comment"># 전처리기 + 모델 파이프라인 통째로 저장</span>
joblib.dump(full_pipe, <span class="string">"pipeline.joblib"</span>)

<span class="comment"># 모델 메타 정보 확인</span>
<span class="builtin">print</span>(loaded_model.get_params())   <span class="comment"># 파라미터 딕셔너리</span>
            </div>

            <h4>주요 알고리즘 선택 가이드</h4>
            <table class="comparison-table">
                <tr><th>알고리즘</th><th>유형</th><th>장점</th><th>단점 / 주의</th></tr>
                <tr><td>LinearRegression / Logistic</td><td>선형</td><td>빠름, 해석 쉬움</td><td>비선형 관계 취약</td></tr>
                <tr><td>Ridge / Lasso / ElasticNet</td><td>정규화 선형</td><td>과적합 완화, 특성 선택(Lasso)</td><td>alpha 튜닝 필요</td></tr>
                <tr><td>DecisionTree</td><td>트리</td><td>해석 쉬움, 전처리 불필요</td><td>과적합 심함</td></tr>
                <tr><td>RandomForest</td><td>배깅 앙상블</td><td>안정적, 중요도 제공, 병렬화</td><td>메모리 사용량, 느린 예측</td></tr>
                <tr><td>GradientBoosting / HistGB</td><td>부스팅</td><td>높은 정확도, 결측치 허용(Hist)</td><td>튜닝 파라미터 많음</td></tr>
                <tr><td>SVM / SVC</td><td>커널</td><td>고차원 강점, 마진 최적화</td><td>대용량 느림, 확률 느림</td></tr>
                <tr><td>KNN</td><td>거리 기반</td><td>구현 간단, 파라미터 적음</td><td>예측 느림, 고차원 취약</td></tr>
                <tr><td>K-Means</td><td>클러스터링</td><td>빠름, 확장성</td><td>K 사전 지정, 구형 군집만</td></tr>
                <tr><td>DBSCAN</td><td>밀도 클러스터링</td><td>이상치 감지, K 불필요</td><td>고차원·대용량 어려움</td></tr>
                <tr><td>PCA</td><td>차원 축소</td><td>빠름, 노이즈 제거</td><td>비선형 관계 포착 불가</td></tr>
            </table>

            <h3>모델 평가 및 검증</h3>
            <p>모델의 성능을 객관적으로 측정하는 것은 ML 파이프라인의 필수 과정입니다. <strong>정확도(Accuracy)</strong>는 전체 정답률, <strong>정밀도(Precision)</strong>는 양성 예측의 정확성, <strong>재현율(Recall)</strong>은 실제 양성의 검출률을 나타냅니다. <strong>F1 Score</strong>는 정밀도와 재현율의 조화 평균이며, <strong>교차 검증(Cross Validation)</strong>은 과적합을 방지하기 위해 데이터를 여러 폴드로 나누어 반복 평가합니다.</p>
            <div class="code-block">
<span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, classification_report, roc_auc_score
)

<span class="comment"># 분류 метрик</span>
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average=<span class="string">"weighted"</span>)
recall = recall_score(y_test, y_pred, average=<span class="string">"weighted"</span>)
f1 = f1_score(y_test, y_pred, average=<span class="string">"weighted"</span>)

<span class="comment"># 혼동 행렬</span>
cm = confusion_matrix(y_test, y_pred)

<span class="comment"># 리포트</span>
<span class="keyword">print</span>(classification_report(y_test, y_pred))

<span class="comment"># ROC-AUC</span>
roc_auc = roc_auc_score(y_test, y_proba, multi_class=<span class="string">"ovr"</span>)

<span class="comment"># 교차 검증</span>
<span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score
scores = cross_val_score(model, X, y, cv=<span class="number">5</span>, scoring=<span class="string">"accuracy"</span>)
            </div>

            <div class="level-guide beginner">
                <div class="level-guide-header">초급자 가이드 - 머신러닝이란 무엇인가?</div>
                <div class="level-guide-content">
                    <p>머신러닝을 일상에 비유하면 쉽게 이해할 수 있습니다:</p>
                    <ul>
                        <li><strong>지도 학습 = 선생님이 있는 학습</strong>: 정답(라벨)이 있는 데이터로 학습합니다. 예: 스팸/정상 메일을 구분하기 위해 이미 분류된 메일 데이터로 훈련합니다.</li>
                        <li><strong>비지도 학습 = 스스로 패턴 찾기</strong>: 정답 없이 데이터의 구조를 발견합니다. 예: 고객 구매 패턴을 분석하여 비슷한 고객끼리 그룹화합니다.</li>
                        <li><strong>회귀 vs 분류</strong>: 회귀는 "집 가격은 얼마?"처럼 연속적인 숫자를 예측하고, 분류는 "스팸인가 아닌가?"처럼 카테고리를 예측합니다.</li>
                    </ul>
                    <p><strong>시작 팁:</strong> scikit-learn의 내장 데이터셋(<code>load_iris()</code>, <code>load_digits()</code>)으로 실습을 시작하세요. 3줄의 코드로 머신러닝 모델을 만들 수 있습니다!</p>
                </div>
            </div>

            <div class="level-guide intermediate">
                <div class="level-guide-header">중급자 가이드 - 모델 선택과 튜닝</div>
                <div class="level-guide-content">
                    <p>실무에서 효과적인 모델 개발 전략:</p>
                    <ul>
                        <li><strong>기준 모델(Baseline)</strong>: 복잡한 모델 전에 간단한 모델(LogisticRegression, DecisionTree)로 기준 성능을 측정하세요.</li>
                        <li><strong>교차 검증(Cross-Validation)</strong>: <code>cross_val_score()</code>로 모델의 일반화 성능을 평가합니다. k-fold 교차 검증이 표준입니다.</li>
                        <li><strong>하이퍼파라미터 튜닝</strong>: <code>GridSearchCV</code>(완전 탐색)나 <code>RandomizedSearchCV</code>(랜덤 탐색)로 최적 파라미터를 찾습니다. Optuna는 베이지안 최적화로 더 효율적입니다.</li>
                        <li><strong>파이프라인</strong>: <code>Pipeline([("scaler", StandardScaler()), ("model", SVC())])</code>로 전처리와 모델을 하나로 묶으면 데이터 누출(data leakage)을 방지합니다.</li>
                        <li><strong>특성 중요도</strong>: 트리 기반 모델의 <code>feature_importances_</code>나 SHAP 값으로 어떤 특성이 예측에 영향을 주는지 분석합니다.</li>
                    </ul>
                </div>
            </div>

            <div class="level-guide advanced">
                <div class="level-guide-header">고급자 가이드 - MLOps와 프로덕션 배포</div>
                <div class="level-guide-content">
                    <p>머신러닝 모델을 프로덕션에 배포하고 운영하기 위한 고급 전략:</p>
                    <ul>
                        <li><strong>실험 추적</strong>: MLflow, Weights & Biases(W&B)로 하이퍼파라미터, 메트릭, 모델을 체계적으로 기록하고 비교합니다.</li>
                        <li><strong>모델 서빙</strong>: FastAPI + uvicorn으로 REST API를 구축하거나, TorchServe, TensorFlow Serving으로 모델을 배포합니다. ONNX Runtime으로 프레임워크 독립적인 추론도 가능합니다.</li>
                        <li><strong>피처 스토어</strong>: Feast 등의 피처 스토어로 특성 엔지니어링을 재사용하고 학습/서빙 간 일관성을 보장합니다.</li>
                        <li><strong>모델 모니터링</strong>: 데이터 드리프트, 개념 드리프트를 감지하여 모델 성능 저하를 조기에 발견합니다. Evidently, Whylogs 등의 도구를 활용합니다.</li>
                        <li><strong>앙상블 기법</strong>: Gradient Boosting(XGBoost, LightGBM, CatBoost)은 대부분의 정형 데이터 문제에서 최고 성능을 제공합니다. 스태킹(Stacking)으로 여러 모델을 결합하면 추가 성능 향상이 가능합니다.</li>
                    </ul>
                </div>
            </div>

        </section>

        <section id="deep-learning">
            <h2>14. 딥러닝</h2>
            <span class="level-badge level-advanced">고급</span>
            <span class="level-badge level-expert">전문가</span>

            <p>딥러닝(Deep Learning)은 다층 신경망을 사용하여 데이터의 복잡한 패턴을 학습하는 머신러닝의 하위 분야입니다. 이미지 인식, 자연어 처리, 음성 인식, 생성 AI 등에서 혁신적인 성과를 이루고 있으며, TensorFlow와 PyTorch가 양대 프레임워크입니다.</p>

            <div class="svg-container">
                <!-- 신경망 구조 다이어그램 -->
                <svg width="700" height="320" viewBox="0 0 700 320" xmlns="http://www.w3.org/2000/svg">
                    <!-- 입력층 노드 -->
                    <text x="90" y="25" text-anchor="middle" fill="var(--svg-blue-text)" font-weight="bold" font-size="13">입력층</text>
                    <text x="90" y="42" text-anchor="middle" fill="var(--text-secondary)" font-size="10">Input Layer</text>
                    <circle cx="90" cy="80" r="20" fill="var(--svg-blue)" stroke="#2196F3" stroke-width="2"/>
                    <text x="90" y="85" text-anchor="middle" fill="var(--svg-blue-text)" font-size="11">x1</text>
                    <circle cx="90" cy="150" r="20" fill="var(--svg-blue)" stroke="#2196F3" stroke-width="2"/>
                    <text x="90" y="155" text-anchor="middle" fill="var(--svg-blue-text)" font-size="11">x2</text>
                    <circle cx="90" cy="220" r="20" fill="var(--svg-blue)" stroke="#2196F3" stroke-width="2"/>
                    <text x="90" y="225" text-anchor="middle" fill="var(--svg-blue-text)" font-size="11">x3</text>

                    <!-- 은닉층1 노드 -->
                    <text x="280" y="25" text-anchor="middle" fill="var(--svg-orange-text)" font-weight="bold" font-size="13">은닉층 1</text>
                    <text x="280" y="42" text-anchor="middle" fill="var(--text-secondary)" font-size="10">Hidden Layer</text>
                    <circle cx="280" cy="65" r="18" fill="var(--svg-orange)" stroke="#ff9800" stroke-width="2"/>
                    <circle cx="280" cy="120" r="18" fill="var(--svg-orange)" stroke="#ff9800" stroke-width="2"/>
                    <circle cx="280" cy="175" r="18" fill="var(--svg-orange)" stroke="#ff9800" stroke-width="2"/>
                    <circle cx="280" cy="230" r="18" fill="var(--svg-orange)" stroke="#ff9800" stroke-width="2"/>

                    <!-- 은닉층2 노드 -->
                    <text x="440" y="25" text-anchor="middle" fill="var(--svg-green-text)" font-weight="bold" font-size="13">은닉층 2</text>
                    <text x="440" y="42" text-anchor="middle" fill="var(--text-secondary)" font-size="10">Hidden Layer</text>
                    <circle cx="440" cy="90" r="18" fill="var(--svg-green)" stroke="#4CAF50" stroke-width="2"/>
                    <circle cx="440" cy="150" r="18" fill="var(--svg-green)" stroke="#4CAF50" stroke-width="2"/>
                    <circle cx="440" cy="210" r="18" fill="var(--svg-green)" stroke="#4CAF50" stroke-width="2"/>

                    <!-- 출력층 노드 -->
                    <text x="600" y="25" text-anchor="middle" fill="var(--svg-pink-text)" font-weight="bold" font-size="13">출력층</text>
                    <text x="600" y="42" text-anchor="middle" fill="var(--text-secondary)" font-size="10">Output Layer</text>
                    <circle cx="600" cy="120" r="20" fill="var(--svg-pink)" stroke="#e91e63" stroke-width="2"/>
                    <text x="600" y="125" text-anchor="middle" fill="var(--svg-pink-text)" font-size="11">y1</text>
                    <circle cx="600" cy="190" r="20" fill="var(--svg-pink)" stroke="#e91e63" stroke-width="2"/>
                    <text x="600" y="195" text-anchor="middle" fill="var(--svg-pink-text)" font-size="11">y2</text>

                    <!-- 입력 → 은닉1 연결선 -->
                    <line x1="110" y1="80" x2="262" y2="65" stroke="var(--text-muted)" stroke-width="0.8" opacity="0.5"/>
                    <line x1="110" y1="80" x2="262" y2="120" stroke="var(--text-muted)" stroke-width="0.8" opacity="0.5"/>
                    <line x1="110" y1="80" x2="262" y2="175" stroke="var(--text-muted)" stroke-width="0.8" opacity="0.5"/>
                    <line x1="110" y1="80" x2="262" y2="230" stroke="var(--text-muted)" stroke-width="0.8" opacity="0.5"/>
                    <line x1="110" y1="150" x2="262" y2="65" stroke="var(--text-muted)" stroke-width="0.8" opacity="0.5"/>
                    <line x1="110" y1="150" x2="262" y2="120" stroke="var(--text-muted)" stroke-width="0.8" opacity="0.5"/>
                    <line x1="110" y1="150" x2="262" y2="175" stroke="var(--text-muted)" stroke-width="0.8" opacity="0.5"/>
                    <line x1="110" y1="150" x2="262" y2="230" stroke="var(--text-muted)" stroke-width="0.8" opacity="0.5"/>
                    <line x1="110" y1="220" x2="262" y2="65" stroke="var(--text-muted)" stroke-width="0.8" opacity="0.5"/>
                    <line x1="110" y1="220" x2="262" y2="120" stroke="var(--text-muted)" stroke-width="0.8" opacity="0.5"/>
                    <line x1="110" y1="220" x2="262" y2="175" stroke="var(--text-muted)" stroke-width="0.8" opacity="0.5"/>
                    <line x1="110" y1="220" x2="262" y2="230" stroke="var(--text-muted)" stroke-width="0.8" opacity="0.5"/>

                    <!-- 은닉1 → 은닉2 연결선 -->
                    <line x1="298" y1="65" x2="422" y2="90" stroke="var(--text-muted)" stroke-width="0.8" opacity="0.5"/>
                    <line x1="298" y1="65" x2="422" y2="150" stroke="var(--text-muted)" stroke-width="0.8" opacity="0.5"/>
                    <line x1="298" y1="65" x2="422" y2="210" stroke="var(--text-muted)" stroke-width="0.8" opacity="0.5"/>
                    <line x1="298" y1="120" x2="422" y2="90" stroke="var(--text-muted)" stroke-width="0.8" opacity="0.5"/>
                    <line x1="298" y1="120" x2="422" y2="150" stroke="var(--text-muted)" stroke-width="0.8" opacity="0.5"/>
                    <line x1="298" y1="120" x2="422" y2="210" stroke="var(--text-muted)" stroke-width="0.8" opacity="0.5"/>
                    <line x1="298" y1="175" x2="422" y2="90" stroke="var(--text-muted)" stroke-width="0.8" opacity="0.5"/>
                    <line x1="298" y1="175" x2="422" y2="150" stroke="var(--text-muted)" stroke-width="0.8" opacity="0.5"/>
                    <line x1="298" y1="175" x2="422" y2="210" stroke="var(--text-muted)" stroke-width="0.8" opacity="0.5"/>
                    <line x1="298" y1="230" x2="422" y2="90" stroke="var(--text-muted)" stroke-width="0.8" opacity="0.5"/>
                    <line x1="298" y1="230" x2="422" y2="150" stroke="var(--text-muted)" stroke-width="0.8" opacity="0.5"/>
                    <line x1="298" y1="230" x2="422" y2="210" stroke="var(--text-muted)" stroke-width="0.8" opacity="0.5"/>

                    <!-- 은닉2 → 출력 연결선 -->
                    <line x1="458" y1="90" x2="580" y2="120" stroke="var(--text-muted)" stroke-width="0.8" opacity="0.5"/>
                    <line x1="458" y1="90" x2="580" y2="190" stroke="var(--text-muted)" stroke-width="0.8" opacity="0.5"/>
                    <line x1="458" y1="150" x2="580" y2="120" stroke="var(--text-muted)" stroke-width="0.8" opacity="0.5"/>
                    <line x1="458" y1="150" x2="580" y2="190" stroke="var(--text-muted)" stroke-width="0.8" opacity="0.5"/>
                    <line x1="458" y1="210" x2="580" y2="120" stroke="var(--text-muted)" stroke-width="0.8" opacity="0.5"/>
                    <line x1="458" y1="210" x2="580" y2="190" stroke="var(--text-muted)" stroke-width="0.8" opacity="0.5"/>

                    <!-- 하단 설명 -->
                    <text x="350" y="275" text-anchor="middle" fill="var(--text-muted)" font-size="12">다층 퍼셉트론(MLP) 구조 - 각 연결선은 학습 가능한 가중치(weight)를 가짐</text>
                    <text x="350" y="295" text-anchor="middle" fill="var(--text-muted)" font-size="11">은닉층이 깊어질수록(Deep) 더 복잡한 패턴을 학습할 수 있음</text>
                </svg>
            </div>

            <h3>TensorFlow/Keras (딥러닝)</h3>

            <p>TensorFlow는 Google이 개발한 오픈소스 딥러닝 프레임워크이며,
            Keras는 TensorFlow의 고수준 API로 모델을 직관적으로 구축·학습·배포할 수 있습니다.
            TensorFlow 2.x부터 Keras가 기본 통합되어 <code>tf.keras</code>로 사용합니다.</p>

            <div class="tip-box">
                <strong>설치:</strong> <code>pip install tensorflow</code> &nbsp;|&nbsp;
                GPU: <code>pip install tensorflow[and-cuda]</code> &nbsp;|&nbsp;
                확인: <code>python -c "import tensorflow as tf; print(tf.__version__); print(tf.config.list_physical_devices('GPU'))"</code>
            </div>

            <h4>텐서(Tensor) 기본 연산</h4>
            <div class="code-block">
<span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf
<span class="keyword">import</span> numpy <span class="keyword">as</span> np

<span class="comment"># 텐서 생성</span>
a = tf.constant([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]], dtype=tf.float32)   <span class="comment"># 불변 텐서</span>
b = tf.Variable([[<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>]], dtype=tf.float32)   <span class="comment"># 변경 가능 (학습 가중치용)</span>
z = tf.zeros([<span class="number">3</span>, <span class="number">4</span>])                                   <span class="comment"># 영행렬</span>
o = tf.ones([<span class="number">2</span>, <span class="number">3</span>])                                    <span class="comment"># 1행렬</span>
r = tf.random.normal([<span class="number">3</span>, <span class="number">3</span>], mean=<span class="number">0.0</span>, stddev=<span class="number">1.0</span>)  <span class="comment"># 정규분포 난수</span>
e = tf.eye(<span class="number">3</span>)                                           <span class="comment"># 단위행렬</span>

<span class="comment"># 기본 수학 연산 (요소별)</span>
c = a + b               <span class="comment"># tf.add(a, b)</span>
c = a * b               <span class="comment"># tf.multiply(a, b) — 요소별 곱</span>
c = a @ b               <span class="comment"># tf.matmul(a, b) — 행렬 곱</span>
c = tf.reduce_sum(a)    <span class="comment"># 전체 합  → 스칼라 10</span>
c = tf.reduce_mean(a, axis=<span class="number">0</span>)  <span class="comment"># 열 평균 → [2. 3.]</span>

<span class="comment"># Shape 조작</span>
t = tf.constant([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])
t.shape                          <span class="comment"># TensorShape([2, 3])</span>
r = tf.reshape(t, [<span class="number">3</span>, <span class="number">2</span>])       <span class="comment"># (2,3) → (3,2)</span>
r = tf.reshape(t, [-<span class="number">1</span>])          <span class="comment"># 평탄화 → (6,)</span>
r = tf.expand_dims(t, axis=<span class="number">0</span>)   <span class="comment"># (2,3) → (1,2,3) — 배치 차원 추가</span>
r = tf.squeeze(r)                <span class="comment"># 크기 1인 차원 제거</span>
r = tf.transpose(t)              <span class="comment"># 전치 (2,3) → (3,2)</span>

<span class="comment"># 타입 변환 &amp; NumPy 호환</span>
f = tf.cast(t, tf.float32)      <span class="comment"># int → float</span>
n = t.numpy()                    <span class="comment"># 텐서 → NumPy 배열</span>
t = tf.convert_to_tensor(n)     <span class="comment"># NumPy → 텐서</span>
            </div>

            <h4>Sequential API</h4>
            <div class="code-block">
<span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras
<span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers

<span class="comment"># Sequential 모델 — 레이어를 순서대로 쌓는 가장 간단한 방식</span>
model = keras.Sequential([
    layers.Dense(<span class="number">64</span>, activation=<span class="string">"relu"</span>, input_shape=(<span class="number">784</span>,)),
    layers.Dense(<span class="number">32</span>, activation=<span class="string">"relu"</span>),
    layers.Dropout(<span class="number">0.3</span>),           <span class="comment"># 과적합 방지: 30% 뉴런 비활성화</span>
    layers.Dense(<span class="number">10</span>, activation=<span class="string">"softmax"</span>)
])

model.summary()  <span class="comment"># 모델 구조 및 파라미터 수 확인</span>

<span class="comment"># add()로 레이어 추가 (동적 구성)</span>
model = keras.Sequential()
model.add(layers.Dense(<span class="number">128</span>, activation=<span class="string">"relu"</span>, input_shape=(<span class="number">784</span>,)))
model.add(layers.BatchNormalization())  <span class="comment"># 배치 정규화</span>
model.add(layers.Dense(<span class="number">64</span>, activation=<span class="string">"relu"</span>))
model.add(layers.Dropout(<span class="number">0.5</span>))
model.add(layers.Dense(<span class="number">10</span>, activation=<span class="string">"softmax"</span>))

<span class="comment"># 모델 컴파일</span>
model.compile(
    optimizer=<span class="string">"adam"</span>,
    loss=<span class="string">"sparse_categorical_crossentropy"</span>,
    metrics=[<span class="string">"accuracy"</span>]
)

<span class="comment"># 학습</span>
history = model.fit(
    X_train, y_train,
    epochs=<span class="number">10</span>,
    batch_size=<span class="number">32</span>,
    validation_split=<span class="number">0.2</span>,
    verbose=<span class="number">1</span>             <span class="comment"># 0=무출력, 1=진행바, 2=에포크 요약</span>
)

<span class="comment"># 학습 기록 활용</span>
history.history[<span class="string">"loss"</span>]          <span class="comment"># 에포크별 손실값 리스트</span>
history.history[<span class="string">"val_accuracy"</span>]  <span class="comment"># 에포크별 검증 정확도</span>

<span class="comment"># 평가 및 예측</span>
test_loss, test_acc = model.evaluate(X_test, y_test)
predictions = model.predict(X_test)   <span class="comment"># (N, 10) 확률 배열</span>
predicted_classes = tf.argmax(predictions, axis=<span class="number">1</span>)  <span class="comment"># 최대 확률 클래스</span>
            </div>

            <h4>Functional API</h4>
            <div class="code-block">
<span class="comment"># Functional API — 다중 입력/출력, 잔차 연결 등 복잡한 구조 지원</span>

<span class="comment"># 기본 사용</span>
inputs = keras.Input(shape=(<span class="number">784</span>,), name=<span class="string">"input"</span>)
x = layers.Dense(<span class="number">64</span>, activation=<span class="string">"relu"</span>)(inputs)
x = layers.Dropout(<span class="number">0.3</span>)(x)
outputs = layers.Dense(<span class="number">10</span>, activation=<span class="string">"softmax"</span>, name=<span class="string">"output"</span>)(x)
model = keras.Model(inputs=inputs, outputs=outputs)

<span class="comment"># 잔차 연결 (Residual / Skip Connection)</span>
inputs = keras.Input(shape=(<span class="number">256</span>,))
x = layers.Dense(<span class="number">256</span>, activation=<span class="string">"relu"</span>)(inputs)
x = layers.BatchNormalization()(x)
x = layers.Dense(<span class="number">256</span>, activation=<span class="string">"relu"</span>)(x)
x = layers.Add()([x, inputs])   <span class="comment"># 잔차 연결: 입력을 출력에 더함</span>
outputs = layers.Dense(<span class="number">10</span>, activation=<span class="string">"softmax"</span>)(x)
res_model = keras.Model(inputs, outputs)

<span class="comment"># 다중 입력 / 다중 출력</span>
text_input = keras.Input(shape=(<span class="number">100</span>,), name=<span class="string">"text"</span>)
meta_input = keras.Input(shape=(<span class="number">5</span>,), name=<span class="string">"meta"</span>)

x1 = layers.Dense(<span class="number">64</span>, activation=<span class="string">"relu"</span>)(text_input)
x2 = layers.Dense(<span class="number">16</span>, activation=<span class="string">"relu"</span>)(meta_input)
merged = layers.Concatenate()([x1, x2])  <span class="comment"># 특성 결합</span>
shared = layers.Dense(<span class="number">32</span>, activation=<span class="string">"relu"</span>)(merged)

category_out = layers.Dense(<span class="number">5</span>, activation=<span class="string">"softmax"</span>, name=<span class="string">"category"</span>)(shared)
score_out = layers.Dense(<span class="number">1</span>, name=<span class="string">"score"</span>)(shared)

multi_model = keras.Model(
    inputs=[text_input, meta_input],
    outputs=[category_out, score_out]
)
multi_model.compile(
    optimizer=<span class="string">"adam"</span>,
    loss={<span class="string">"category"</span>: <span class="string">"sparse_categorical_crossentropy"</span>, <span class="string">"score"</span>: <span class="string">"mse"</span>},
    loss_weights={<span class="string">"category"</span>: <span class="number">1.0</span>, <span class="string">"score"</span>: <span class="number">0.5</span>}
)
            </div>

            <h4>Model Subclassing</h4>
            <div class="code-block">
<span class="comment"># 커스텀 모델 클래스 — 최대 유연성, 연구용에 적합</span>
<span class="keyword">class</span> <span class="function">MyModel</span>(keras.Model):
    <span class="keyword">def</span> <span class="function">__init__</span>(self, num_classes=<span class="number">10</span>):
        <span class="builtin">super</span>().__init__()
        self.dense1 = layers.Dense(<span class="number">128</span>, activation=<span class="string">"relu"</span>)
        self.bn = layers.BatchNormalization()
        self.dropout = layers.Dropout(<span class="number">0.3</span>)
        self.dense2 = layers.Dense(num_classes, activation=<span class="string">"softmax"</span>)

    <span class="keyword">def</span> <span class="function">call</span>(self, inputs, training=<span class="keyword">False</span>):
        x = self.dense1(inputs)
        x = self.bn(x, training=training)   <span class="comment"># training 플래그 전달 중요</span>
        x = self.dropout(x, training=training)
        <span class="keyword">return</span> self.dense2(x)

model = MyModel(num_classes=<span class="number">10</span>)
model.compile(optimizer=<span class="string">"adam"</span>, loss=<span class="string">"sparse_categorical_crossentropy"</span>)

<span class="comment"># 커스텀 레이어</span>
<span class="keyword">class</span> <span class="function">ScaledDense</span>(layers.Layer):
    <span class="keyword">def</span> <span class="function">__init__</span>(self, units, scale=<span class="number">1.0</span>):
        <span class="builtin">super</span>().__init__()
        self.units = units
        self.scale = scale

    <span class="keyword">def</span> <span class="function">build</span>(self, input_shape):
        self.w = self.add_weight(shape=(input_shape[-<span class="number">1</span>], self.units), initializer=<span class="string">"random_normal"</span>)
        self.b = self.add_weight(shape=(self.units,), initializer=<span class="string">"zeros"</span>)

    <span class="keyword">def</span> <span class="function">call</span>(self, inputs):
        <span class="keyword">return</span> tf.matmul(inputs, self.w) * self.scale + self.b
            </div>

            <h4>주요 레이어 비교</h4>
            <table class="comparison-table">
                <tr><th>레이어</th><th>용도</th><th>주요 파라미터</th><th>입력 shape</th></tr>
                <tr><td>Dense</td><td>완전연결 (MLP)</td><td>units, activation</td><td>(batch, features)</td></tr>
                <tr><td>Conv2D</td><td>이미지 특징 추출</td><td>filters, kernel_size, strides, padding</td><td>(batch, H, W, C)</td></tr>
                <tr><td>MaxPooling2D</td><td>공간 다운샘플링</td><td>pool_size, strides</td><td>(batch, H, W, C)</td></tr>
                <tr><td>LSTM</td><td>시계열/순차 데이터</td><td>units, return_sequences, dropout</td><td>(batch, timesteps, features)</td></tr>
                <tr><td>GRU</td><td>경량 순환 레이어</td><td>units, return_sequences</td><td>(batch, timesteps, features)</td></tr>
                <tr><td>Embedding</td><td>정수→밀집 벡터 변환</td><td>input_dim, output_dim</td><td>(batch, sequence_length)</td></tr>
                <tr><td>BatchNormalization</td><td>학습 안정화, 가속</td><td>momentum, epsilon</td><td>임의</td></tr>
                <tr><td>Dropout</td><td>과적합 방지</td><td>rate (0~1)</td><td>임의</td></tr>
                <tr><td>Flatten</td><td>다차원→1차원 변환</td><td>없음</td><td>(batch, ...)</td></tr>
                <tr><td>GlobalAveragePooling2D</td><td>특성맵 평균 풀링</td><td>없음</td><td>(batch, H, W, C)</td></tr>
            </table>

            <h4>옵티마이저(Optimizer)</h4>
            <div class="code-block">
<span class="comment"># 문자열 지정 (기본 하이퍼파라미터)</span>
model.compile(optimizer=<span class="string">"adam"</span>, loss=<span class="string">"mse"</span>)

<span class="comment"># 객체로 지정 (하이퍼파라미터 커스터마이징)</span>
model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=<span class="number">1e-3</span>, weight_decay=<span class="number">1e-4</span>),
    loss=<span class="string">"mse"</span>
)

<span class="comment"># 주요 옵티마이저 비교</span>
keras.optimizers.SGD(learning_rate=<span class="number">0.01</span>, momentum=<span class="number">0.9</span>)         <span class="comment"># 안정적, 일반화 우수</span>
keras.optimizers.Adam(learning_rate=<span class="number">1e-3</span>)                        <span class="comment"># 가장 범용, 빠른 수렴</span>
keras.optimizers.AdamW(learning_rate=<span class="number">1e-3</span>, weight_decay=<span class="number">1e-4</span>)  <span class="comment"># Adam + 가중치 감쇠</span>
keras.optimizers.RMSprop(learning_rate=<span class="number">1e-3</span>)                    <span class="comment"># RNN에 적합</span>

<span class="comment"># 학습률 스케줄러</span>
lr_schedule = keras.optimizers.schedules.CosineDecay(
    initial_learning_rate=<span class="number">1e-3</span>,
    decay_steps=<span class="number">10000</span>,
    alpha=<span class="number">1e-5</span>       <span class="comment"># 최소 학습률</span>
)
optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)
            </div>

            <h4>손실 함수(Loss Function)</h4>
            <table class="comparison-table">
                <tr><th>작업</th><th>손실 함수</th><th>출력 활성화</th><th>레이블 형태</th></tr>
                <tr><td>이진 분류</td><td><code>binary_crossentropy</code></td><td>sigmoid</td><td>0 또는 1</td></tr>
                <tr><td>다중 분류 (정수 레이블)</td><td><code>sparse_categorical_crossentropy</code></td><td>softmax</td><td>0, 1, 2, ...</td></tr>
                <tr><td>다중 분류 (원핫 레이블)</td><td><code>categorical_crossentropy</code></td><td>softmax</td><td>[0,1,0,...] 원핫</td></tr>
                <tr><td>회귀</td><td><code>mse</code> (mean_squared_error)</td><td>없음 (linear)</td><td>연속값</td></tr>
                <tr><td>회귀 (이상치 강건)</td><td><code>huber</code></td><td>없음</td><td>연속값</td></tr>
                <tr><td>다중 레이블</td><td><code>binary_crossentropy</code></td><td>sigmoid</td><td>[1,0,1,...] 다중</td></tr>
            </table>
            <div class="code-block">
<span class="comment"># 커스텀 손실 함수</span>
<span class="keyword">def</span> <span class="function">custom_mse</span>(y_true, y_pred):
    <span class="keyword">return</span> tf.reduce_mean(tf.square(y_true - y_pred))

model.compile(optimizer=<span class="string">"adam"</span>, loss=custom_mse)

<span class="comment"># 클래스 가중치 (불균형 데이터)</span>
model.fit(X_train, y_train, class_weight={<span class="number">0</span>: <span class="number">1.0</span>, <span class="number">1</span>: <span class="number">5.0</span>})  <span class="comment"># 소수 클래스에 높은 가중치</span>
            </div>

            <h4>메트릭(Metrics)</h4>
            <div class="code-block">
<span class="comment"># 내장 메트릭</span>
model.compile(
    optimizer=<span class="string">"adam"</span>,
    loss=<span class="string">"sparse_categorical_crossentropy"</span>,
    metrics=[
        <span class="string">"accuracy"</span>,
        keras.metrics.Precision(name=<span class="string">"precision"</span>),
        keras.metrics.Recall(name=<span class="string">"recall"</span>),
        keras.metrics.AUC(name=<span class="string">"auc"</span>),
    ]
)

<span class="comment"># 커스텀 메트릭</span>
<span class="keyword">class</span> <span class="function">F1Score</span>(keras.metrics.Metric):
    <span class="keyword">def</span> <span class="function">__init__</span>(self, name=<span class="string">"f1_score"</span>, **kwargs):
        <span class="builtin">super</span>().__init__(name=name, **kwargs)
        self.precision = keras.metrics.Precision()
        self.recall = keras.metrics.Recall()

    <span class="keyword">def</span> <span class="function">update_state</span>(self, y_true, y_pred, sample_weight=<span class="keyword">None</span>):
        self.precision.update_state(y_true, y_pred, sample_weight)
        self.recall.update_state(y_true, y_pred, sample_weight)

    <span class="keyword">def</span> <span class="function">result</span>(self):
        p = self.precision.result()
        r = self.recall.result()
        <span class="keyword">return</span> <span class="number">2</span> * (p * r) / (p + r + keras.backend.epsilon())

    <span class="keyword">def</span> <span class="function">reset_state</span>(self):
        self.precision.reset_state()
        self.recall.reset_state()
            </div>

            <h4>콜백(Callbacks)</h4>
            <div class="code-block">
<span class="comment"># 주요 콜백 — 학습 과정을 자동으로 제어</span>
callbacks = [
    <span class="comment"># 검증 손실이 5 에포크 동안 개선되지 않으면 학습 중단</span>
    keras.callbacks.EarlyStopping(
        monitor=<span class="string">"val_loss"</span>, patience=<span class="number">5</span>, restore_best_weights=<span class="keyword">True</span>
    ),
    <span class="comment"># 최적 모델 자동 저장</span>
    keras.callbacks.ModelCheckpoint(
        <span class="string">"best_model.keras"</span>, monitor=<span class="string">"val_loss"</span>, save_best_only=<span class="keyword">True</span>
    ),
    <span class="comment"># 검증 손실 정체 시 학습률 감소</span>
    keras.callbacks.ReduceLROnPlateau(
        monitor=<span class="string">"val_loss"</span>, factor=<span class="number">0.5</span>, patience=<span class="number">3</span>, min_lr=<span class="number">1e-6</span>
    ),
    <span class="comment"># TensorBoard 로그</span>
    keras.callbacks.TensorBoard(log_dir=<span class="string">"./logs"</span>, histogram_freq=<span class="number">1</span>),
]

model.fit(X_train, y_train, epochs=<span class="number">100</span>, callbacks=callbacks, validation_split=<span class="number">0.2</span>)

<span class="comment"># 커스텀 콜백</span>
<span class="keyword">class</span> <span class="function">PrintLR</span>(keras.callbacks.Callback):
    <span class="keyword">def</span> <span class="function">on_epoch_end</span>(self, epoch, logs=<span class="keyword">None</span>):
        lr = self.model.optimizer.learning_rate
        <span class="builtin">print</span>(f<span class="string">"\n에포크 {epoch+1} 학습률: {lr:.6f}"</span>)
            </div>

            <h4>커스텀 학습 루프 (GradientTape)</h4>
            <div class="code-block">
<span class="comment"># tf.GradientTape — 학습 과정을 완전히 제어</span>
model = MyModel()
optimizer = keras.optimizers.Adam(<span class="number">1e-3</span>)
loss_fn = keras.losses.SparseCategoricalCrossentropy()
train_acc = keras.metrics.SparseCategoricalAccuracy()

<span class="decorator">@tf.function</span>  <span class="comment"># 그래프 모드로 컴파일 → 성능 향상</span>
<span class="keyword">def</span> <span class="function">train_step</span>(x, y):
    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:
        predictions = model(x, training=<span class="keyword">True</span>)
        loss = loss_fn(y, predictions)
    gradients = tape.gradient(loss, model.trainable_variables)
    optimizer.apply_gradients(<span class="builtin">zip</span>(gradients, model.trainable_variables))
    train_acc.update_state(y, predictions)
    <span class="keyword">return</span> loss

<span class="comment"># 학습 루프</span>
<span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="builtin">range</span>(<span class="number">10</span>):
    train_acc.reset_state()
    <span class="keyword">for</span> x_batch, y_batch <span class="keyword">in</span> train_dataset:
        loss = train_step(x_batch, y_batch)
    <span class="builtin">print</span>(f<span class="string">"에포크 {epoch+1}, 손실: {loss:.4f}, 정확도: {train_acc.result():.4f}"</span>)
            </div>

            <h4>모델 저장 및 로드</h4>
            <div class="code-block">
<span class="comment"># ① Keras 형식 (권장) — 모델 구조 + 가중치 + 옵티마이저 상태</span>
model.save(<span class="string">"my_model.keras"</span>)
loaded_model = keras.models.load_model(<span class="string">"my_model.keras"</span>)

<span class="comment"># ② SavedModel 형식 (TF Serving 배포용)</span>
model.save(<span class="string">"saved_model_dir"</span>)   <span class="comment"># 디렉토리로 저장</span>
loaded_model = keras.models.load_model(<span class="string">"saved_model_dir"</span>)

<span class="comment"># ③ 가중치만 저장/로드 (모델 구조는 코드로 재생성)</span>
model.save_weights(<span class="string">"weights.weights.h5"</span>)
model.load_weights(<span class="string">"weights.weights.h5"</span>)

<span class="comment"># ④ TFLite 변환 (모바일/엣지 배포)</span>
converter = tf.lite.TFLiteConverter.from_saved_model(<span class="string">"saved_model_dir"</span>)
converter.optimizations = [tf.lite.Optimize.DEFAULT]  <span class="comment"># 양자화</span>
tflite_model = converter.convert()
<span class="keyword">with</span> <span class="builtin">open</span>(<span class="string">"model.tflite"</span>, <span class="string">"wb"</span>) <span class="keyword">as</span> f:
    f.write(tflite_model)

<span class="comment"># ⑤ ONNX 변환</span>
<span class="comment"># pip install tf2onnx</span>
<span class="comment"># python -m tf2onnx.convert --saved-model saved_model_dir --output model.onnx</span>
            </div>

            <h4>tf.data 입력 파이프라인</h4>
            <div class="code-block">
<span class="comment"># tf.data.Dataset — 효율적인 데이터 로딩 &amp; 전처리 파이프라인</span>

<span class="comment"># NumPy 배열에서 생성</span>
dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))

<span class="comment"># 파이프라인 구성 (체이닝)</span>
train_ds = (
    dataset
    .shuffle(buffer_size=<span class="number">10000</span>)      <span class="comment"># 데이터 섞기</span>
    .batch(<span class="number">32</span>)                        <span class="comment"># 배치 크기</span>
    .map(<span class="keyword">lambda</span> x, y: (x / <span class="number">255.0</span>, y), <span class="comment"># 전처리 (정규화)</span>
         num_parallel_calls=tf.data.AUTOTUNE)
    .prefetch(tf.data.AUTOTUNE)       <span class="comment"># GPU 연산 중 다음 배치 준비</span>
    .cache()                           <span class="comment"># 첫 에포크 후 메모리 캐시</span>
)

<span class="comment"># 이미지 디렉토리에서 데이터셋 생성</span>
train_ds = keras.utils.image_dataset_from_directory(
    <span class="string">"data/train"</span>,
    image_size=(<span class="number">224</span>, <span class="number">224</span>),
    batch_size=<span class="number">32</span>,
    label_mode=<span class="string">"categorical"</span>,       <span class="comment"># "int", "categorical", "binary"</span>
    validation_split=<span class="number">0.2</span>,
    subset=<span class="string">"training"</span>,
    seed=<span class="number">42</span>
)

<span class="comment"># CSV 파일에서 생성</span>
csv_ds = tf.data.experimental.make_csv_dataset(
    <span class="string">"data.csv"</span>,
    batch_size=<span class="number">32</span>,
    label_name=<span class="string">"target"</span>,
    num_epochs=<span class="number">1</span>
)

<span class="comment"># 커스텀 map 함수 (데이터 증강)</span>
<span class="keyword">def</span> <span class="function">augment</span>(image, label):
    image = tf.image.random_flip_left_right(image)
    image = tf.image.random_brightness(image, max_delta=<span class="number">0.2</span>)
    <span class="keyword">return</span> image, label

train_ds = train_ds.map(augment, num_parallel_calls=tf.data.AUTOTUNE)
            </div>

            <h4>GPU 메모리 관리</h4>
            <div class="code-block">
<span class="comment"># GPU 메모리 점진적 할당 (필수 설정 — OOM 방지)</span>
gpus = tf.config.list_physical_devices(<span class="string">"GPU"</span>)
<span class="keyword">for</span> gpu <span class="keyword">in</span> gpus:
    tf.config.experimental.set_memory_growth(gpu, <span class="keyword">True</span>)

<span class="comment"># 또는 메모리 한도 설정</span>
tf.config.set_logical_device_configuration(
    gpus[<span class="number">0</span>],
    [tf.config.LogicalDeviceConfiguration(memory_limit=<span class="number">4096</span>)]  <span class="comment"># 4GB</span>
)

<span class="comment"># 혼합 정밀도 학습 (float16 + float32) — 속도 2배, 메모리 절감</span>
keras.mixed_precision.set_global_policy(<span class="string">"mixed_float16"</span>)

<span class="comment"># 멀티 GPU 분산 학습</span>
strategy = tf.distribute.MirroredStrategy()  <span class="comment"># 단일 머신, 다중 GPU</span>
<span class="keyword">with</span> strategy.scope():
    model = keras.Sequential([...])
    model.compile(optimizer=<span class="string">"adam"</span>, loss=<span class="string">"sparse_categorical_crossentropy"</span>)
            </div>

            <div class="warning-box">
                <strong>주의사항:</strong>
                <code>set_memory_growth</code>는 프로그램 시작 시 GPU 사용 전에 호출해야 합니다.
                혼합 정밀도 사용 시 모델의 마지막 출력 레이어는 반드시 <code>dtype="float32"</code>로 지정하세요.
                <code>model(x, training=True/False)</code>에서 training 플래그를 정확히 전달해야
                Dropout과 BatchNormalization이 올바르게 동작합니다.
            </div>

            <h4>TensorFlow/Keras 핵심 정리</h4>
            <table class="comparison-table">
                <tr><th>작업</th><th>API / 메서드</th><th>비고</th></tr>
                <tr><td>간단한 모델 구축</td><td><code>keras.Sequential</code></td><td>선형 스택 구조</td></tr>
                <tr><td>복잡한 모델 구축</td><td><code>keras.Model</code> (Functional)</td><td>다중 입출력, 잔차 연결</td></tr>
                <tr><td>최대 유연성 모델</td><td>Model Subclassing</td><td>동적 로직, 연구용</td></tr>
                <tr><td>학습</td><td><code>model.fit()</code></td><td>콜백으로 제어</td></tr>
                <tr><td>세밀한 학습 제어</td><td><code>tf.GradientTape</code></td><td>GAN, 강화학습 등</td></tr>
                <tr><td>데이터 파이프라인</td><td><code>tf.data.Dataset</code></td><td>shuffle→batch→prefetch</td></tr>
                <tr><td>모델 저장</td><td><code>model.save(".keras")</code></td><td>Keras 형식 권장</td></tr>
                <tr><td>배포 변환</td><td><code>TFLiteConverter</code></td><td>모바일/엣지용</td></tr>
                <tr><td>성능 향상</td><td><code>@tf.function</code></td><td>그래프 모드 컴파일</td></tr>
                <tr><td>메모리 절감</td><td><code>mixed_float16</code></td><td>Ampere+ GPU 권장</td></tr>
                <tr><td>분산 학습</td><td><code>MirroredStrategy</code></td><td>멀티 GPU 자동 분배</td></tr>
                <tr><td>학습 모니터링</td><td><code>TensorBoard</code> 콜백</td><td><code>tensorboard --logdir ./logs</code></td></tr>
            </table>
            
            <h3>PyTorch (딥러닝)</h3>

            <p>PyTorch는 Meta(Facebook)가 개발한 오픈소스 딥러닝 프레임워크로,
            동적 계산 그래프(Define-by-Run) 방식으로 직관적인 디버깅과 유연한 모델 설계가 가능합니다.
            연구 커뮤니티에서 가장 널리 사용되며, TorchScript/ONNX를 통한 프로덕션 배포도 지원합니다.</p>

            <div class="tip-box">
                <strong>설치:</strong> <code>pip install torch torchvision torchaudio</code> &nbsp;|&nbsp;
                CUDA: <a href="https://pytorch.org/get-started/locally/">pytorch.org</a>에서 플랫폼별 명령어 확인 &nbsp;|&nbsp;
                확인: <code>python -c "import torch; print(torch.__version__); print(torch.cuda.is_available())"</code>
            </div>

            <h4>텐서(Tensor) 기본 연산</h4>
            <div class="code-block">
<span class="keyword">import</span> torch
<span class="keyword">import</span> numpy <span class="keyword">as</span> np

<span class="comment"># 텐서 생성</span>
a = torch.tensor([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>]], dtype=torch.float32)  <span class="comment"># 리스트에서</span>
b = torch.zeros(<span class="number">3</span>, <span class="number">4</span>)                                    <span class="comment"># 영행렬</span>
c = torch.ones(<span class="number">2</span>, <span class="number">3</span>)                                     <span class="comment"># 1행렬</span>
d = torch.randn(<span class="number">3</span>, <span class="number">3</span>)                                    <span class="comment"># 표준정규분포 난수</span>
e = torch.eye(<span class="number">3</span>)                                         <span class="comment"># 단위행렬</span>
f = torch.arange(<span class="number">0</span>, <span class="number">10</span>, <span class="number">2</span>)                               <span class="comment"># [0, 2, 4, 6, 8]</span>
g = torch.linspace(<span class="number">0</span>, <span class="number">1</span>, <span class="number">5</span>)                              <span class="comment"># [0, 0.25, 0.5, 0.75, 1]</span>
h = torch.empty(<span class="number">2</span>, <span class="number">3</span>).uniform_(<span class="number">0</span>, <span class="number">1</span>)                     <span class="comment"># 균일분포 난수 (in-place)</span>

<span class="comment"># 기본 수학 연산 (요소별)</span>
x = a + a               <span class="comment"># torch.add(a, a)</span>
x = a * a               <span class="comment"># torch.mul(a, a) — 요소별 곱</span>
x = a @ a               <span class="comment"># torch.matmul(a, a) — 행렬 곱</span>
x = a.sum()             <span class="comment"># 전체 합 → 스칼라 tensor(10.)</span>
x = a.mean(dim=<span class="number">0</span>)       <span class="comment"># 열 평균 → tensor([2., 3.])</span>
x = a.max(dim=<span class="number">1</span>)        <span class="comment"># 행 최대 → values, indices 반환</span>
x = torch.clamp(a, <span class="number">0</span>, <span class="number">3</span>)  <span class="comment"># 값 범위 제한 [0, 3]</span>

<span class="comment"># Shape 조작</span>
t = torch.randn(<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>)
t.shape                          <span class="comment"># torch.Size([2, 3, 4])</span>
r = t.view(<span class="number">6</span>, <span class="number">4</span>)                <span class="comment"># reshape (연속 메모리 필요)</span>
r = t.reshape(<span class="number">6</span>, <span class="number">4</span>)             <span class="comment"># reshape (자동 복사)</span>
r = t.view(-<span class="number">1</span>)                  <span class="comment"># 평탄화 → (24,)</span>
r = t.unsqueeze(<span class="number">0</span>)              <span class="comment"># (2,3,4) → (1,2,3,4) — 차원 추가</span>
r = r.squeeze(<span class="number">0</span>)                <span class="comment"># (1,2,3,4) → (2,3,4) — 차원 제거</span>
r = t.permute(<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>)          <span class="comment"># 축 재배열 (2,3,4) → (4,2,3)</span>
r = t.transpose(<span class="number">0</span>, <span class="number">1</span>)           <span class="comment"># 두 축 교환 (2,3,4) → (3,2,4)</span>

<span class="comment"># 결합 &amp; 분할</span>
x = torch.cat([a, a], dim=<span class="number">0</span>)    <span class="comment"># 행 방향 결합 (4,2)</span>
x = torch.stack([a, a], dim=<span class="number">0</span>)  <span class="comment"># 새 차원으로 쌓기 (2,2,2)</span>
chunks = t.chunk(<span class="number">3</span>, dim=<span class="number">1</span>)      <span class="comment"># dim=1 기준 3등분</span>

<span class="comment"># 타입 변환 &amp; NumPy 호환</span>
f = a.to(torch.float64)          <span class="comment"># float32 → float64</span>
f = a.int()                       <span class="comment"># → int32 (단축형)</span>
n = a.numpy()                     <span class="comment"># 텐서 → NumPy (CPU, 메모리 공유)</span>
t = torch.from_numpy(n)           <span class="comment"># NumPy → 텐서 (메모리 공유)</span>
t = a.clone().detach()            <span class="comment"># 독립 복사본 (그래프 분리)</span>
            </div>

            <h4>Autograd (자동 미분)</h4>
            <div class="code-block">
<span class="comment"># requires_grad=True → 연산 추적, 자동 미분 가능</span>
x = torch.tensor([<span class="number">2.0</span>, <span class="number">3.0</span>], requires_grad=<span class="keyword">True</span>)
y = x ** <span class="number">2</span> + <span class="number">3</span> * x + <span class="number">1</span>      <span class="comment"># y = x² + 3x + 1</span>
loss = y.sum()
loss.backward()                <span class="comment"># 역전파 — 그래디언트 계산</span>
<span class="builtin">print</span>(x.grad)                  <span class="comment"># dy/dx = 2x + 3 → tensor([7., 9.])</span>

<span class="comment"># 그래디언트 제어</span>
x.grad.zero_()                 <span class="comment"># 그래디언트 초기화 (축적 방지)</span>

<span class="comment"># 그래디언트 추적 비활성화 (추론/전처리 시)</span>
<span class="keyword">with</span> torch.no_grad():
    y = x * <span class="number">2</span>                  <span class="comment"># 연산 추적 안 함 → 메모리 절약</span>

y = x.detach()                 <span class="comment"># 그래프에서 분리된 새 텐서</span>

<span class="comment"># 고차 미분</span>
x = torch.tensor([<span class="number">1.0</span>], requires_grad=<span class="keyword">True</span>)
y = x ** <span class="number">3</span>
grad1 = torch.autograd.grad(y, x, create_graph=<span class="keyword">True</span>)[<span class="number">0</span>]  <span class="comment"># 3x² = 3</span>
grad2 = torch.autograd.grad(grad1, x)[<span class="number">0</span>]                  <span class="comment"># 6x  = 6</span>
            </div>

            <h4>nn.Module 모델 구축</h4>
            <div class="code-block">
<span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn

<span class="comment"># 기본 모델 정의</span>
<span class="keyword">class</span> <span class="function">Net</span>(nn.Module):
    <span class="keyword">def</span> <span class="function">__init__</span>(self, num_classes=<span class="number">10</span>):
        <span class="builtin">super</span>().__init__()
        self.fc1 = nn.Linear(<span class="number">784</span>, <span class="number">256</span>)
        self.bn1 = nn.BatchNorm1d(<span class="number">256</span>)
        self.fc2 = nn.Linear(<span class="number">256</span>, <span class="number">128</span>)
        self.dropout = nn.Dropout(<span class="number">0.3</span>)
        self.fc3 = nn.Linear(<span class="number">128</span>, num_classes)

    <span class="keyword">def</span> <span class="function">forward</span>(self, x):
        x = torch.relu(self.bn1(self.fc1(x)))
        x = torch.relu(self.fc2(x))
        x = self.dropout(x)      <span class="comment"># training 모드에서만 활성화</span>
        <span class="keyword">return</span> self.fc3(x)        <span class="comment"># 분류: CrossEntropyLoss가 softmax 포함</span>

model = Net(num_classes=<span class="number">10</span>)
<span class="builtin">print</span>(model)                      <span class="comment"># 모델 구조 출력</span>

<span class="comment"># 파라미터 확인</span>
total = <span class="builtin">sum</span>(p.numel() <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters())
trainable = <span class="builtin">sum</span>(p.numel() <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters() <span class="keyword">if</span> p.requires_grad)
<span class="builtin">print</span>(f<span class="string">"전체: {total:,} / 학습 가능: {trainable:,}"</span>)

<span class="comment"># 파라미터 순회</span>
<span class="keyword">for</span> name, param <span class="keyword">in</span> model.named_parameters():
    <span class="builtin">print</span>(f<span class="string">"{name}: {param.shape}"</span>)
            </div>

            <h4>nn.Sequential &amp; ModuleList</h4>
            <div class="code-block">
<span class="comment"># nn.Sequential — 레이어를 순서대로 쌓기</span>
model = nn.Sequential(
    nn.Linear(<span class="number">784</span>, <span class="number">256</span>),
    nn.ReLU(),
    nn.BatchNorm1d(<span class="number">256</span>),
    nn.Dropout(<span class="number">0.3</span>),
    nn.Linear(<span class="number">256</span>, <span class="number">128</span>),
    nn.ReLU(),
    nn.Linear(<span class="number">128</span>, <span class="number">10</span>)
)

<span class="comment"># OrderedDict로 이름 부여</span>
<span class="keyword">from</span> collections <span class="keyword">import</span> OrderedDict
model = nn.Sequential(OrderedDict([
    (<span class="string">"fc1"</span>, nn.Linear(<span class="number">784</span>, <span class="number">256</span>)),
    (<span class="string">"relu1"</span>, nn.ReLU()),
    (<span class="string">"fc2"</span>, nn.Linear(<span class="number">256</span>, <span class="number">10</span>)),
]))
model.fc1   <span class="comment"># 이름으로 레이어 접근</span>

<span class="comment"># nn.ModuleList — 동적 레이어 구성</span>
<span class="keyword">class</span> <span class="function">DynamicNet</span>(nn.Module):
    <span class="keyword">def</span> <span class="function">__init__</span>(self, layers_sizes):
        <span class="builtin">super</span>().__init__()
        self.layers = nn.ModuleList([
            nn.Linear(in_f, out_f)
            <span class="keyword">for</span> in_f, out_f <span class="keyword">in</span> <span class="builtin">zip</span>(layers_sizes[:-<span class="number">1</span>], layers_sizes[<span class="number">1</span>:])
        ])

    <span class="keyword">def</span> <span class="function">forward</span>(self, x):
        <span class="keyword">for</span> layer <span class="keyword">in</span> self.layers[:-<span class="number">1</span>]:
            x = torch.relu(layer(x))
        <span class="keyword">return</span> self.layers[-<span class="number">1</span>](x)

<span class="comment"># nn.ModuleDict — 조건부 레이어 선택</span>
<span class="keyword">class</span> <span class="function">FlexibleNet</span>(nn.Module):
    <span class="keyword">def</span> <span class="function">__init__</span>(self, activation=<span class="string">"relu"</span>):
        <span class="builtin">super</span>().__init__()
        self.fc = nn.Linear(<span class="number">784</span>, <span class="number">10</span>)
        self.activations = nn.ModuleDict({
            <span class="string">"relu"</span>: nn.ReLU(),
            <span class="string">"gelu"</span>: nn.GELU(),
            <span class="string">"silu"</span>: nn.SiLU(),
        })
        self.act = self.activations[activation]
            </div>

            <h4>잔차 연결 &amp; 고급 패턴</h4>
            <div class="code-block">
<span class="comment"># 잔차 블록 (ResNet 스타일)</span>
<span class="keyword">class</span> <span class="function">ResidualBlock</span>(nn.Module):
    <span class="keyword">def</span> <span class="function">__init__</span>(self, dim):
        <span class="builtin">super</span>().__init__()
        self.block = nn.Sequential(
            nn.Linear(dim, dim),
            nn.BatchNorm1d(dim),
            nn.ReLU(),
            nn.Linear(dim, dim),
            nn.BatchNorm1d(dim),
        )

    <span class="keyword">def</span> <span class="function">forward</span>(self, x):
        <span class="keyword">return</span> torch.relu(self.block(x) + x)  <span class="comment"># 잔차 연결</span>

<span class="comment"># 다중 입력 모델</span>
<span class="keyword">class</span> <span class="function">MultiInputModel</span>(nn.Module):
    <span class="keyword">def</span> <span class="function">__init__</span>(self):
        <span class="builtin">super</span>().__init__()
        self.text_branch = nn.Linear(<span class="number">100</span>, <span class="number">64</span>)
        self.meta_branch = nn.Linear(<span class="number">5</span>, <span class="number">16</span>)
        self.classifier = nn.Linear(<span class="number">80</span>, <span class="number">10</span>)

    <span class="keyword">def</span> <span class="function">forward</span>(self, text, meta):
        t = torch.relu(self.text_branch(text))
        m = torch.relu(self.meta_branch(meta))
        merged = torch.cat([t, m], dim=<span class="number">1</span>)  <span class="comment"># 특성 결합</span>
        <span class="keyword">return</span> self.classifier(merged)
            </div>

            <h4>주요 레이어 비교</h4>
            <table class="comparison-table">
                <tr><th>레이어</th><th>용도</th><th>주요 파라미터</th><th>입력 shape</th></tr>
                <tr><td>nn.Linear</td><td>완전연결 (MLP)</td><td>in_features, out_features</td><td>(batch, features)</td></tr>
                <tr><td>nn.Conv2d</td><td>이미지 특징 추출</td><td>in_channels, out_channels, kernel_size</td><td>(batch, C, H, W)</td></tr>
                <tr><td>nn.MaxPool2d</td><td>공간 다운샘플링</td><td>kernel_size, stride</td><td>(batch, C, H, W)</td></tr>
                <tr><td>nn.LSTM</td><td>시계열/순차 데이터</td><td>input_size, hidden_size, num_layers</td><td>(seq, batch, features)</td></tr>
                <tr><td>nn.GRU</td><td>경량 순환 레이어</td><td>input_size, hidden_size</td><td>(seq, batch, features)</td></tr>
                <tr><td>nn.Embedding</td><td>정수→밀집 벡터</td><td>num_embeddings, embedding_dim</td><td>(batch, seq_len) 정수</td></tr>
                <tr><td>nn.BatchNorm1d/2d</td><td>학습 안정화, 가속</td><td>num_features</td><td>(batch, features) / (B,C,H,W)</td></tr>
                <tr><td>nn.Dropout</td><td>과적합 방지</td><td>p (0~1)</td><td>임의</td></tr>
                <tr><td>nn.LayerNorm</td><td>Transformer 정규화</td><td>normalized_shape</td><td>임의</td></tr>
                <tr><td>nn.MultiheadAttention</td><td>어텐션 메커니즘</td><td>embed_dim, num_heads</td><td>(seq, batch, embed_dim)</td></tr>
            </table>

            <div class="tip-box">
                <strong>TensorFlow vs PyTorch 채널 순서:</strong>
                TensorFlow/Keras는 <code>(batch, H, W, C)</code> — channels-last,
                PyTorch는 <code>(batch, C, H, W)</code> — channels-first가 기본입니다.
                PyTorch에서 <code>.permute(0, 3, 1, 2)</code>로 변환하세요.
            </div>

            <h4>손실 함수(Loss Function)</h4>
            <table class="comparison-table">
                <tr><th>작업</th><th>손실 함수</th><th>출력 형태</th><th>레이블 형태</th></tr>
                <tr><td>다중 분류</td><td><code>nn.CrossEntropyLoss()</code></td><td>raw logits (N, C)</td><td>정수 (N,)</td></tr>
                <tr><td>이진 분류</td><td><code>nn.BCEWithLogitsLoss()</code></td><td>raw logits (N, 1)</td><td>float 0/1 (N, 1)</td></tr>
                <tr><td>이진 분류 (sigmoid 후)</td><td><code>nn.BCELoss()</code></td><td>확률 (N, 1)</td><td>float 0/1 (N, 1)</td></tr>
                <tr><td>회귀</td><td><code>nn.MSELoss()</code></td><td>(N, *)</td><td>(N, *)</td></tr>
                <tr><td>회귀 (이상치 강건)</td><td><code>nn.SmoothL1Loss()</code></td><td>(N, *)</td><td>(N, *)</td></tr>
                <tr><td>회귀 (L1)</td><td><code>nn.L1Loss()</code></td><td>(N, *)</td><td>(N, *)</td></tr>
                <tr><td>다중 레이블</td><td><code>nn.BCEWithLogitsLoss()</code></td><td>raw logits (N, C)</td><td>multi-hot (N, C)</td></tr>
            </table>
            <div class="code-block">
<span class="comment"># CrossEntropyLoss는 내부에 softmax를 포함 — 모델 출력에 softmax 적용하지 말 것!</span>
criterion = nn.CrossEntropyLoss()
logits = model(x)                     <span class="comment"># raw logits, softmax 적용 안 함</span>
loss = criterion(logits, labels)      <span class="comment"># labels: 정수 텐서 (LongTensor)</span>

<span class="comment"># 클래스 불균형 처리</span>
weights = torch.tensor([<span class="number">1.0</span>, <span class="number">5.0</span>, <span class="number">1.0</span>])  <span class="comment"># 클래스별 가중치</span>
criterion = nn.CrossEntropyLoss(weight=weights.to(device))

<span class="comment"># 커스텀 손실 함수</span>
<span class="keyword">class</span> <span class="function">FocalLoss</span>(nn.Module):
    <span class="keyword">def</span> <span class="function">__init__</span>(self, alpha=<span class="number">1.0</span>, gamma=<span class="number">2.0</span>):
        <span class="builtin">super</span>().__init__()
        self.alpha = alpha
        self.gamma = gamma

    <span class="keyword">def</span> <span class="function">forward</span>(self, inputs, targets):
        ce_loss = nn.functional.cross_entropy(inputs, targets, reduction=<span class="string">"none"</span>)
        pt = torch.exp(-ce_loss)
        <span class="keyword">return</span> (self.alpha * (<span class="number">1</span> - pt) ** self.gamma * ce_loss).mean()
            </div>

            <h4>옵티마이저(Optimizer) &amp; 스케줄러</h4>
            <div class="code-block">
<span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim

<span class="comment"># 주요 옵티마이저</span>
optim.SGD(model.parameters(), lr=<span class="number">0.01</span>, momentum=<span class="number">0.9</span>, weight_decay=<span class="number">1e-4</span>)
optim.Adam(model.parameters(), lr=<span class="number">1e-3</span>, weight_decay=<span class="number">1e-4</span>)
optim.AdamW(model.parameters(), lr=<span class="number">1e-3</span>, weight_decay=<span class="number">1e-2</span>)  <span class="comment"># 분리된 가중치 감쇠</span>
optim.RMSprop(model.parameters(), lr=<span class="number">1e-3</span>)

<span class="comment"># 파라미터 그룹별 학습률 설정</span>
optimizer = optim.Adam([
    {<span class="string">"params"</span>: model.fc1.parameters(), <span class="string">"lr"</span>: <span class="number">1e-4</span>},    <span class="comment"># 사전학습 레이어 (낮은 lr)</span>
    {<span class="string">"params"</span>: model.fc3.parameters(), <span class="string">"lr"</span>: <span class="number">1e-3</span>},    <span class="comment"># 새 레이어 (높은 lr)</span>
], weight_decay=<span class="number">1e-4</span>)

<span class="comment"># 학습률 스케줄러</span>
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=<span class="number">10</span>, gamma=<span class="number">0.1</span>)   <span class="comment"># 10 에포크마다 ×0.1</span>
scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=<span class="number">50</span>)        <span class="comment"># 코사인 감쇠</span>
scheduler = optim.lr_scheduler.ReduceLROnPlateau(                              <span class="comment"># 정체 시 감소</span>
    optimizer, mode=<span class="string">"min"</span>, factor=<span class="number">0.5</span>, patience=<span class="number">5</span>
)
scheduler = optim.lr_scheduler.OneCycleLR(                                     <span class="comment"># 1-Cycle 정책</span>
    optimizer, max_lr=<span class="number">0.01</span>, total_steps=<span class="number">1000</span>
)

<span class="comment"># 스케줄러 사용 (학습 루프 내에서)</span>
<span class="comment"># scheduler.step()            — 에포크 기반 (StepLR, CosineAnnealing)</span>
<span class="comment"># scheduler.step(val_loss)    — 메트릭 기반 (ReduceLROnPlateau)</span>
<span class="comment"># scheduler.step()            — 배치 기반 (OneCycleLR) — 매 배치 후 호출</span>
            </div>

            <h4>표준 학습 루프</h4>
            <div class="code-block">
<span class="keyword">import</span> torch
<span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn
<span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim

device = torch.device(<span class="string">"cuda"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">"cpu"</span>)
model = Net().to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=<span class="number">1e-3</span>)
scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=<span class="number">20</span>)

<span class="comment"># 학습 함수</span>
<span class="keyword">def</span> <span class="function">train_one_epoch</span>(model, loader, criterion, optimizer, device):
    model.train()                       <span class="comment"># Dropout, BatchNorm 학습 모드</span>
    running_loss = <span class="number">0.0</span>
    correct = <span class="number">0</span>
    total = <span class="number">0</span>
    <span class="keyword">for</span> inputs, labels <span class="keyword">in</span> loader:
        inputs, labels = inputs.to(device), labels.to(device)

        optimizer.zero_grad()           <span class="comment"># ① 그래디언트 초기화</span>
        outputs = model(inputs)         <span class="comment"># ② 순전파</span>
        loss = criterion(outputs, labels)
        loss.backward()                 <span class="comment"># ③ 역전파</span>
        optimizer.step()                <span class="comment"># ④ 가중치 갱신</span>

        running_loss += loss.item() * inputs.size(<span class="number">0</span>)
        _, predicted = outputs.max(<span class="number">1</span>)
        total += labels.size(<span class="number">0</span>)
        correct += predicted.eq(labels).sum().item()

    <span class="keyword">return</span> running_loss / total, correct / total

<span class="comment"># 검증 함수</span>
<span class="decorator">@torch.no_grad()</span>                        <span class="comment"># 그래디언트 비활성화</span>
<span class="keyword">def</span> <span class="function">evaluate</span>(model, loader, criterion, device):
    model.eval()                         <span class="comment"># Dropout 비활성화, BatchNorm 고정</span>
    running_loss = <span class="number">0.0</span>
    correct = <span class="number">0</span>
    total = <span class="number">0</span>
    <span class="keyword">for</span> inputs, labels <span class="keyword">in</span> loader:
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        running_loss += loss.item() * inputs.size(<span class="number">0</span>)
        _, predicted = outputs.max(<span class="number">1</span>)
        total += labels.size(<span class="number">0</span>)
        correct += predicted.eq(labels).sum().item()
    <span class="keyword">return</span> running_loss / total, correct / total

<span class="comment"># 학습 루프 (EarlyStopping 포함)</span>
best_val_loss = <span class="builtin">float</span>(<span class="string">"inf"</span>)
patience_counter = <span class="number">0</span>

<span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="builtin">range</span>(<span class="number">100</span>):
    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)
    val_loss, val_acc = evaluate(model, val_loader, criterion, device)
    scheduler.step()

    <span class="builtin">print</span>(f<span class="string">"[{epoch+1:3d}] train_loss={train_loss:.4f} acc={train_acc:.4f} | val_loss={val_loss:.4f} acc={val_acc:.4f}"</span>)

    <span class="keyword">if</span> val_loss &lt; best_val_loss:
        best_val_loss = val_loss
        patience_counter = <span class="number">0</span>
        torch.save(model.state_dict(), <span class="string">"best_model.pt"</span>)  <span class="comment"># 최적 모델 저장</span>
    <span class="keyword">else</span>:
        patience_counter += <span class="number">1</span>
        <span class="keyword">if</span> patience_counter >= <span class="number">10</span>:
            <span class="builtin">print</span>(<span class="string">"Early stopping!"</span>)
            <span class="keyword">break</span>

model.load_state_dict(torch.load(<span class="string">"best_model.pt"</span>))  <span class="comment"># 최적 가중치 복원</span>
            </div>

            <h4>DataLoader &amp; Dataset</h4>
            <div class="code-block">
<span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader, TensorDataset, random_split

<span class="comment"># ① TensorDataset — NumPy/텐서에서 바로 생성</span>
dataset = TensorDataset(
    torch.tensor(X_train, dtype=torch.float32),
    torch.tensor(y_train, dtype=torch.long)
)

<span class="comment"># ② 커스텀 Dataset</span>
<span class="keyword">class</span> <span class="function">MyDataset</span>(Dataset):
    <span class="keyword">def</span> <span class="function">__init__</span>(self, data, labels, transform=<span class="keyword">None</span>):
        self.data = data
        self.labels = labels
        self.transform = transform

    <span class="keyword">def</span> <span class="function">__len__</span>(self):
        <span class="keyword">return</span> <span class="builtin">len</span>(self.data)

    <span class="keyword">def</span> <span class="function">__getitem__</span>(self, idx):
        sample = self.data[idx]
        label = self.labels[idx]
        <span class="keyword">if</span> self.transform:
            sample = self.transform(sample)
        <span class="keyword">return</span> sample, label

<span class="comment"># DataLoader — 배치, 셔플, 병렬 로딩</span>
train_loader = DataLoader(
    dataset,
    batch_size=<span class="number">64</span>,
    shuffle=<span class="keyword">True</span>,            <span class="comment"># 학습 데이터 셔플</span>
    num_workers=<span class="number">4</span>,           <span class="comment"># 병렬 데이터 로딩 프로세스</span>
    pin_memory=<span class="keyword">True</span>,          <span class="comment"># GPU 전송 가속 (CUDA)</span>
    drop_last=<span class="keyword">True</span>,           <span class="comment"># 마지막 불완전 배치 제거</span>
)
val_loader = DataLoader(dataset, batch_size=<span class="number">128</span>, shuffle=<span class="keyword">False</span>)

<span class="comment"># 데이터 분할</span>
train_set, val_set = random_split(dataset, [<span class="number">0.8</span>, <span class="number">0.2</span>])

<span class="comment"># 이미지 데이터: torchvision transforms</span>
<span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms, datasets

transform_train = transforms.Compose([
    transforms.RandomResizedCrop(<span class="number">224</span>),
    transforms.RandomHorizontalFlip(),
    transforms.ColorJitter(brightness=<span class="number">0.2</span>, contrast=<span class="number">0.2</span>),
    transforms.ToTensor(),
    transforms.Normalize(mean=[<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>],
                         std=[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])
])
transform_val = transforms.Compose([
    transforms.Resize(<span class="number">256</span>),
    transforms.CenterCrop(<span class="number">224</span>),
    transforms.ToTensor(),
    transforms.Normalize(mean=[<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>],
                         std=[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])
])

<span class="comment"># 내장 데이터셋 (CIFAR-10, MNIST, ImageNet 등)</span>
train_ds = datasets.CIFAR10(<span class="string">"./data"</span>, train=<span class="keyword">True</span>, download=<span class="keyword">True</span>, transform=transform_train)
train_loader = DataLoader(train_ds, batch_size=<span class="number">64</span>, shuffle=<span class="keyword">True</span>, num_workers=<span class="number">4</span>)

<span class="comment"># ImageFolder — 디렉토리 구조에서 자동 로딩 (data/train/cat/*.jpg, data/train/dog/*.jpg)</span>
train_ds = datasets.ImageFolder(<span class="string">"data/train"</span>, transform=transform_train)
            </div>

            <h4>모델 저장 및 로드</h4>
            <div class="code-block">
<span class="comment"># ① state_dict 저장/로드 (권장 — 가중치만, 코드 유지)</span>
torch.save(model.state_dict(), <span class="string">"model_weights.pt"</span>)

model = Net()                                       <span class="comment"># 모델 구조 재생성 필요</span>
model.load_state_dict(torch.load(<span class="string">"model_weights.pt"</span>, weights_only=<span class="keyword">True</span>))
model.eval()

<span class="comment"># ② 전체 모델 저장 (구조 + 가중치 — pickle 의존)</span>
torch.save(model, <span class="string">"full_model.pt"</span>)
model = torch.load(<span class="string">"full_model.pt"</span>, weights_only=<span class="keyword">False</span>)

<span class="comment"># ③ 체크포인트 저장 (학습 재개용)</span>
torch.save({
    <span class="string">"epoch"</span>: epoch,
    <span class="string">"model_state_dict"</span>: model.state_dict(),
    <span class="string">"optimizer_state_dict"</span>: optimizer.state_dict(),
    <span class="string">"scheduler_state_dict"</span>: scheduler.state_dict(),
    <span class="string">"best_val_loss"</span>: best_val_loss,
}, <span class="string">"checkpoint.pt"</span>)

<span class="comment"># 체크포인트 복원</span>
ckpt = torch.load(<span class="string">"checkpoint.pt"</span>, weights_only=<span class="keyword">False</span>)
model.load_state_dict(ckpt[<span class="string">"model_state_dict"</span>])
optimizer.load_state_dict(ckpt[<span class="string">"optimizer_state_dict"</span>])
scheduler.load_state_dict(ckpt[<span class="string">"scheduler_state_dict"</span>])
start_epoch = ckpt[<span class="string">"epoch"</span>] + <span class="number">1</span>

<span class="comment"># ④ TorchScript 변환 (C++/프로덕션 배포)</span>
scripted = torch.jit.script(model)          <span class="comment"># Python 제어흐름 포함 가능</span>
scripted.save(<span class="string">"model_scripted.pt"</span>)

traced = torch.jit.trace(model, torch.randn(<span class="number">1</span>, <span class="number">784</span>))  <span class="comment"># 입력 기반 추적</span>
traced.save(<span class="string">"model_traced.pt"</span>)

loaded = torch.jit.load(<span class="string">"model_scripted.pt"</span>)

<span class="comment"># ⑤ ONNX 변환</span>
dummy = torch.randn(<span class="number">1</span>, <span class="number">784</span>)
torch.onnx.export(model, dummy, <span class="string">"model.onnx"</span>,
                  input_names=[<span class="string">"input"</span>], output_names=[<span class="string">"output"</span>],
                  dynamic_axes={<span class="string">"input"</span>: {<span class="number">0</span>: <span class="string">"batch"</span>}, <span class="string">"output"</span>: {<span class="number">0</span>: <span class="string">"batch"</span>}})
            </div>

            <h4>GPU &amp; 디바이스 관리</h4>
            <div class="code-block">
<span class="comment"># 디바이스 설정</span>
device = torch.device(<span class="string">"cuda"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">"cpu"</span>)
device = torch.device(<span class="string">"cuda:0"</span>)   <span class="comment"># 특정 GPU 지정</span>

<span class="comment"># 텐서/모델을 디바이스로 이동</span>
x = x.to(device)                   <span class="comment"># 텐서 이동</span>
model = model.to(device)           <span class="comment"># 모델 이동 (파라미터 + 버퍼)</span>

<span class="comment"># GPU 정보 확인</span>
torch.cuda.is_available()           <span class="comment"># GPU 사용 가능 여부</span>
torch.cuda.device_count()           <span class="comment"># GPU 개수</span>
torch.cuda.get_device_name(<span class="number">0</span>)      <span class="comment"># GPU 이름</span>
torch.cuda.memory_allocated()       <span class="comment"># 현재 메모리 사용량</span>
torch.cuda.memory_reserved()        <span class="comment"># 예약된 메모리</span>
torch.cuda.empty_cache()            <span class="comment"># 미사용 캐시 해제</span>

<span class="comment"># 혼합 정밀도 학습 (AMP) — 속도 2배↑, 메모리 절감</span>
scaler = torch.amp.GradScaler()
<span class="keyword">for</span> inputs, labels <span class="keyword">in</span> loader:
    inputs, labels = inputs.to(device), labels.to(device)
    optimizer.zero_grad()
    <span class="keyword">with</span> torch.amp.autocast(device_type=<span class="string">"cuda"</span>):  <span class="comment"># float16 자동 변환</span>
        outputs = model(inputs)
        loss = criterion(outputs, labels)
    scaler.scale(loss).backward()    <span class="comment"># 스케일링된 역전파</span>
    scaler.step(optimizer)           <span class="comment"># 가중치 갱신</span>
    scaler.update()                  <span class="comment"># 스케일 조정</span>

<span class="comment"># 멀티 GPU (DataParallel — 간단하지만 비효율)</span>
<span class="keyword">if</span> torch.cuda.device_count() > <span class="number">1</span>:
    model = nn.DataParallel(model)   <span class="comment"># 배치를 GPU에 분배</span>
model = model.to(device)

<span class="comment"># 멀티 GPU (DistributedDataParallel — 권장, 고성능)</span>
<span class="comment"># torchrun --nproc_per_node=4 train.py</span>
<span class="keyword">import</span> torch.distributed <span class="keyword">as</span> dist
<span class="keyword">from</span> torch.nn.parallel <span class="keyword">import</span> DistributedDataParallel <span class="keyword">as</span> DDP
dist.init_process_group(backend=<span class="string">"nccl"</span>)
local_rank = <span class="builtin">int</span>(os.environ[<span class="string">"LOCAL_RANK"</span>])
model = DDP(model.to(local_rank), device_ids=[local_rank])
            </div>

            <div class="warning-box">
                <strong>주의사항:</strong>
                <code>model.train()</code>과 <code>model.eval()</code>을 학습/추론 전에 반드시 호출하세요 —
                Dropout과 BatchNorm의 동작이 달라집니다.
                <code>CrossEntropyLoss</code>는 softmax를 내장하므로 모델 출력에 softmax를 중복 적용하면 안 됩니다.
                <code>loss.backward()</code> 전에 <code>optimizer.zero_grad()</code>를 호출하세요 — PyTorch는 그래디언트를 기본으로 누적합니다.
            </div>

            <h4>추론 &amp; 배포</h4>
            <div class="code-block">
<span class="comment"># 추론 모드 — 메모리 최적화, autograd 완전 비활성화</span>
model.eval()
<span class="keyword">with</span> torch.inference_mode():          <span class="comment"># torch.no_grad()보다 빠름</span>
    predictions = model(x.to(device))
    probs = torch.softmax(predictions, dim=<span class="number">1</span>)
    classes = probs.argmax(dim=<span class="number">1</span>)

<span class="comment"># 배치 추론 (대량 데이터)</span>
all_preds = []
model.eval()
<span class="keyword">with</span> torch.inference_mode():
    <span class="keyword">for</span> batch <span class="keyword">in</span> test_loader:
        inputs = batch[<span class="number">0</span>].to(device)
        preds = model(inputs).argmax(dim=<span class="number">1</span>)
        all_preds.append(preds.cpu())
all_preds = torch.cat(all_preds)

<span class="comment"># torch.compile — PyTorch 2.0+ 자동 최적화 (JIT 컴파일)</span>
model = torch.compile(model)         <span class="comment"># 첫 실행 시 컴파일, 이후 가속</span>
model = torch.compile(model, mode=<span class="string">"reduce-overhead"</span>)  <span class="comment"># 오버헤드 최소화</span>
            </div>

            <h4>그래디언트 클리핑 &amp; 정규화</h4>
            <div class="code-block">
<span class="comment"># 그래디언트 클리핑 — 그래디언트 폭발 방지 (RNN, Transformer 필수)</span>
loss.backward()
torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=<span class="number">1.0</span>)  <span class="comment"># L2 norm 기준</span>
torch.nn.utils.clip_grad_value_(model.parameters(), clip_value=<span class="number">0.5</span>) <span class="comment"># 절대값 기준</span>
optimizer.step()

<span class="comment"># 가중치 초기화</span>
<span class="keyword">def</span> <span class="function">init_weights</span>(m):
    <span class="keyword">if</span> <span class="builtin">isinstance</span>(m, nn.Linear):
        nn.init.kaiming_normal_(m.weight, mode=<span class="string">"fan_out"</span>, nonlinearity=<span class="string">"relu"</span>)
        <span class="keyword">if</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:
            nn.init.zeros_(m.bias)
    <span class="keyword">elif</span> <span class="builtin">isinstance</span>(m, nn.Conv2d):
        nn.init.kaiming_normal_(m.weight, mode=<span class="string">"fan_out"</span>)

model.apply(init_weights)  <span class="comment"># 모든 하위 모듈에 재귀 적용</span>

<span class="comment"># 레이어 동결 (전이 학습)</span>
<span class="keyword">for</span> param <span class="keyword">in</span> model.fc1.parameters():
    param.requires_grad = <span class="keyword">False</span>      <span class="comment"># fc1 레이어 가중치 고정</span>

<span class="comment"># 동결된 파라미터 제외한 옵티마이저</span>
optimizer = optim.Adam(<span class="builtin">filter</span>(<span class="keyword">lambda</span> p: p.requires_grad, model.parameters()), lr=<span class="number">1e-3</span>)
            </div>

            <h4>PyTorch 핵심 정리</h4>
            <table class="comparison-table">
                <tr><th>작업</th><th>API / 메서드</th><th>비고</th></tr>
                <tr><td>모델 정의</td><td><code>nn.Module</code> 상속</td><td>__init__ + forward</td></tr>
                <tr><td>간단한 모델</td><td><code>nn.Sequential</code></td><td>이름 부여 시 OrderedDict</td></tr>
                <tr><td>학습 모드</td><td><code>model.train()</code></td><td>Dropout/BN 활성화</td></tr>
                <tr><td>추론 모드</td><td><code>model.eval()</code> + <code>inference_mode()</code></td><td>메모리 최적화</td></tr>
                <tr><td>역전파</td><td><code>loss.backward()</code></td><td>zero_grad → forward → backward → step</td></tr>
                <tr><td>데이터 로딩</td><td><code>DataLoader</code></td><td>pin_memory=True (GPU)</td></tr>
                <tr><td>모델 저장</td><td><code>torch.save(state_dict)</code></td><td>가중치만 저장 권장</td></tr>
                <tr><td>체크포인트</td><td>dict로 epoch/optimizer 포함 저장</td><td>학습 재개용</td></tr>
                <tr><td>프로덕션 배포</td><td><code>torch.jit.script/trace</code></td><td>TorchScript C++ 런타임</td></tr>
                <tr><td>성능 향상</td><td><code>torch.compile()</code></td><td>PyTorch 2.0+ JIT 컴파일</td></tr>
                <tr><td>혼합 정밀도</td><td><code>torch.amp.autocast</code></td><td>GradScaler 필수</td></tr>
                <tr><td>멀티 GPU</td><td><code>DistributedDataParallel</code></td><td>torchrun으로 실행</td></tr>
                <tr><td>그래디언트 클리핑</td><td><code>clip_grad_norm_</code></td><td>RNN/Transformer 필수</td></tr>
                <tr><td>전이 학습</td><td><code>requires_grad = False</code></td><td>레이어 동결</td></tr>
            </table>
            
            <h3>CNN (합성곱 신경망)</h3>

            <p>합성곱 신경망(Convolutional Neural Network)은 이미지 인식, 객체 탐지, 세그멘테이션 등
            시각적 패턴 인식에 최적화된 아키텍처입니다. 합성곱 레이어가 공간적 특징을 계층적으로 추출하고,
            풀링으로 차원을 줄인 뒤 완전연결층에서 분류합니다.</p>

            <h4>합성곱 연산 이해</h4>
            <div class="code-block">
<span class="comment"># Conv2D 핵심 파라미터 이해</span>
<span class="comment">#</span>
<span class="comment"># 입력: (batch, H, W, C) — Keras  /  (batch, C, H, W) — PyTorch</span>
<span class="comment">#</span>
<span class="comment"># filters/out_channels : 출력 특성맵 수 (학습할 필터 개수)</span>
<span class="comment"># kernel_size          : 필터 크기 (3×3이 가장 보편적)</span>
<span class="comment"># strides              : 필터 이동 간격 (2이면 출력 크기 절반)</span>
<span class="comment"># padding              : "same" → 입출력 크기 동일, "valid" → 패딩 없음</span>
<span class="comment">#</span>
<span class="comment"># 출력 크기 계산: O = (I - K + 2P) / S + 1</span>
<span class="comment">#   I=입력크기, K=커널크기, P=패딩, S=스트라이드</span>
<span class="comment">#   예: 입력 28×28, kernel=3, padding=0, stride=1 → 26×26</span>
<span class="comment">#   예: 입력 28×28, kernel=3, padding=1, stride=1 → 28×28 (same)</span>
<span class="comment">#   예: 입력 28×28, kernel=3, padding=0, stride=2 → 13×13</span>
            </div>

            <h4>CNN — Keras 구현</h4>
            <div class="code-block">
<span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras
<span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers

<span class="comment"># 기본 CNN (MNIST 분류)</span>
model = keras.Sequential([
    <span class="comment"># 블록 1: 합성곱 → 정규화 → 활성화 → 풀링</span>
    layers.Conv2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">"same"</span>, input_shape=(<span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)),
    layers.BatchNormalization(),
    layers.ReLU(),
    layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)),         <span class="comment"># 28×28 → 14×14</span>

    <span class="comment"># 블록 2</span>
    layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">"same"</span>),
    layers.BatchNormalization(),
    layers.ReLU(),
    layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)),         <span class="comment"># 14×14 → 7×7</span>

    <span class="comment"># 블록 3</span>
    layers.Conv2D(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), padding=<span class="string">"same"</span>),
    layers.BatchNormalization(),
    layers.ReLU(),
    layers.GlobalAveragePooling2D(),     <span class="comment"># 7×7×128 → 128 (Flatten 대신 권장)</span>

    <span class="comment"># 분류 헤드</span>
    layers.Dropout(<span class="number">0.5</span>),
    layers.Dense(<span class="number">10</span>, activation=<span class="string">"softmax"</span>)
])

model.compile(optimizer=<span class="string">"adam"</span>, loss=<span class="string">"sparse_categorical_crossentropy"</span>, metrics=[<span class="string">"accuracy"</span>])

<span class="comment"># 1D 합성곱 (텍스트, 시계열)</span>
text_cnn = keras.Sequential([
    layers.Embedding(<span class="number">10000</span>, <span class="number">128</span>, input_length=<span class="number">200</span>),
    layers.Conv1D(<span class="number">64</span>, <span class="number">5</span>, activation=<span class="string">"relu"</span>),   <span class="comment"># 5-gram 특징 추출</span>
    layers.GlobalMaxPooling1D(),
    layers.Dense(<span class="number">1</span>, activation=<span class="string">"sigmoid"</span>)
])
            </div>

            <h4>CNN — PyTorch 구현</h4>
            <div class="code-block">
<span class="keyword">import</span> torch
<span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn

<span class="keyword">class</span> <span class="function">CNN</span>(nn.Module):
    <span class="keyword">def</span> <span class="function">__init__</span>(self, num_classes=<span class="number">10</span>):
        <span class="builtin">super</span>().__init__()
        self.features = nn.Sequential(
            <span class="comment"># 블록 1</span>
            nn.Conv2d(<span class="number">1</span>, <span class="number">32</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),  <span class="comment"># (1,28,28)→(32,28,28)</span>
            nn.BatchNorm2d(<span class="number">32</span>),
            nn.ReLU(inplace=<span class="keyword">True</span>),
            nn.MaxPool2d(<span class="number">2</span>),                               <span class="comment"># →(32,14,14)</span>

            <span class="comment"># 블록 2</span>
            nn.Conv2d(<span class="number">32</span>, <span class="number">64</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>), <span class="comment"># →(64,14,14)</span>
            nn.BatchNorm2d(<span class="number">64</span>),
            nn.ReLU(inplace=<span class="keyword">True</span>),
            nn.MaxPool2d(<span class="number">2</span>),                               <span class="comment"># →(64,7,7)</span>

            <span class="comment"># 블록 3</span>
            nn.Conv2d(<span class="number">64</span>, <span class="number">128</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),
            nn.BatchNorm2d(<span class="number">128</span>),
            nn.ReLU(inplace=<span class="keyword">True</span>),
            nn.AdaptiveAvgPool2d((<span class="number">1</span>, <span class="number">1</span>)),                <span class="comment"># →(128,1,1) 어떤 입력 크기든 OK</span>
        )
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Dropout(<span class="number">0.5</span>),
            nn.Linear(<span class="number">128</span>, num_classes),
        )

    <span class="keyword">def</span> <span class="function">forward</span>(self, x):
        x = self.features(x)
        <span class="keyword">return</span> self.classifier(x)

<span class="comment"># Depthwise Separable Convolution (MobileNet 스타일 — 경량화)</span>
depthwise_sep = nn.Sequential(
    nn.Conv2d(<span class="number">64</span>, <span class="number">64</span>, <span class="number">3</span>, padding=<span class="number">1</span>, groups=<span class="number">64</span>),  <span class="comment"># depthwise: 채널별 독립 합성곱</span>
    nn.Conv2d(<span class="number">64</span>, <span class="number">128</span>, <span class="number">1</span>),                       <span class="comment"># pointwise: 1×1 합성곱으로 채널 결합</span>
)

<span class="comment"># Dilated (Atrous) Convolution — 수용 영역 확장</span>
dilated = nn.Conv2d(<span class="number">64</span>, <span class="number">64</span>, <span class="number">3</span>, padding=<span class="number">2</span>, dilation=<span class="number">2</span>)  <span class="comment"># 3×3 필터가 5×5 영역 커버</span>

<span class="comment"># Transposed Convolution — 업샘플링 (세그멘테이션, GAN 생성기)</span>
upsample = nn.ConvTranspose2d(<span class="number">64</span>, <span class="number">32</span>, kernel_size=<span class="number">4</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)  <span class="comment"># 크기 2배</span>
            </div>

            <h4>주요 CNN 아키텍처 비교</h4>
            <table class="comparison-table">
                <tr><th>아키텍처</th><th>연도</th><th>핵심 기법</th><th>파라미터</th><th>특징</th></tr>
                <tr><td>LeNet-5</td><td>1998</td><td>Conv→Pool→FC</td><td>60K</td><td>CNN의 시초, 손글씨 인식</td></tr>
                <tr><td>AlexNet</td><td>2012</td><td>ReLU, Dropout, GPU</td><td>60M</td><td>딥러닝 붐의 시작</td></tr>
                <tr><td>VGGNet</td><td>2014</td><td>3×3 필터 반복</td><td>138M</td><td>단순한 구조, 깊은 네트워크</td></tr>
                <tr><td>GoogLeNet</td><td>2014</td><td>Inception 모듈</td><td>6.8M</td><td>다양한 필터 크기 병렬 적용</td></tr>
                <tr><td>ResNet</td><td>2015</td><td>잔차 연결 (Skip)</td><td>25M (50)</td><td>100+층 학습 가능, 가장 범용</td></tr>
                <tr><td>DenseNet</td><td>2017</td><td>밀집 연결</td><td>8M (121)</td><td>모든 이전 층과 연결</td></tr>
                <tr><td>MobileNet</td><td>2017</td><td>Depthwise Separable</td><td>3.4M</td><td>모바일/엣지 배포용 경량화</td></tr>
                <tr><td>EfficientNet</td><td>2019</td><td>복합 스케일링</td><td>5.3M (B0)</td><td>깊이×너비×해상도 최적 균형</td></tr>
                <tr><td>ConvNeXt</td><td>2022</td><td>Transformer 기법 적용</td><td>29M</td><td>현대화된 순수 CNN, ViT 경쟁</td></tr>
            </table>

            <h4>데이터 증강 (Data Augmentation)</h4>
            <div class="code-block">
<span class="comment"># Keras — 레이어 기반 증강 (GPU 가속, 모델에 포함)</span>
data_augmentation = keras.Sequential([
    layers.RandomFlip(<span class="string">"horizontal"</span>),
    layers.RandomRotation(<span class="number">0.1</span>),           <span class="comment"># ±36도</span>
    layers.RandomZoom(<span class="number">0.2</span>),                <span class="comment"># ±20% 확대/축소</span>
    layers.RandomTranslation(<span class="number">0.1</span>, <span class="number">0.1</span>),  <span class="comment"># ±10% 이동</span>
    layers.RandomContrast(<span class="number">0.2</span>),
])

model = keras.Sequential([
    data_augmentation,    <span class="comment"># 학습 시에만 적용 (추론 시 자동 비활성화)</span>
    layers.Conv2D(<span class="number">32</span>, <span class="number">3</span>, activation=<span class="string">"relu"</span>),
    <span class="comment"># ...</span>
])

<span class="comment"># PyTorch — torchvision.transforms</span>
<span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms

transform_train = transforms.Compose([
    transforms.RandomResizedCrop(<span class="number">224</span>, scale=(<span class="number">0.8</span>, <span class="number">1.0</span>)),
    transforms.RandomHorizontalFlip(p=<span class="number">0.5</span>),
    transforms.RandomRotation(<span class="number">15</span>),
    transforms.ColorJitter(brightness=<span class="number">0.2</span>, contrast=<span class="number">0.2</span>, saturation=<span class="number">0.2</span>, hue=<span class="number">0.1</span>),
    transforms.RandomErasing(p=<span class="number">0.3</span>),      <span class="comment"># 랜덤 영역 마스킹 (CutOut)</span>
    transforms.ToTensor(),
    transforms.Normalize([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], [<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>]),
])

<span class="comment"># albumentations — 고급 증강 라이브러리 (pip install albumentations)</span>
<span class="keyword">import</span> albumentations <span class="keyword">as</span> A
<span class="keyword">from</span> albumentations.pytorch <span class="keyword">import</span> ToTensorV2

aug = A.Compose([
    A.RandomCrop(<span class="number">224</span>, <span class="number">224</span>),
    A.HorizontalFlip(p=<span class="number">0.5</span>),
    A.OneOf([                              <span class="comment"># 셋 중 하나만 적용</span>
        A.GaussNoise(var_limit=(<span class="number">10</span>, <span class="number">50</span>)),
        A.GaussianBlur(blur_limit=<span class="number">3</span>),
        A.MotionBlur(blur_limit=<span class="number">3</span>),
    ], p=<span class="number">0.3</span>),
    A.Normalize(mean=[<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], std=[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>]),
    ToTensorV2(),
])
            </div>

            <div class="tip-box">
                <strong>GlobalAveragePooling vs Flatten:</strong>
                <code>Flatten</code>은 특성맵을 1차원으로 펴서 파라미터가 폭증하고 과적합 위험이 큽니다.
                <code>GlobalAveragePooling2D</code>는 각 특성맵의 평균을 내어 파라미터 수를 대폭 줄이며,
                현대 CNN에서 표준으로 사용합니다.
            </div>

            <h4>CNN 핵심 정리</h4>
            <table class="comparison-table">
                <tr><th>개념</th><th>설명</th><th>권장 설정</th></tr>
                <tr><td>커널 크기</td><td>필터 크기, 작을수록 깊이로 보상</td><td>3×3 (가장 범용)</td></tr>
                <tr><td>패딩</td><td>입력 테두리 0 채움</td><td>"same" / padding=1 (크기 유지)</td></tr>
                <tr><td>스트라이드</td><td>필터 이동 간격</td><td>1 (특징 추출), 2 (다운샘플링)</td></tr>
                <tr><td>풀링</td><td>공간 다운샘플링</td><td>MaxPool 2×2 또는 stride=2 Conv</td></tr>
                <tr><td>정규화</td><td>학습 안정화</td><td>BatchNorm (Conv 직후)</td></tr>
                <tr><td>활성화</td><td>비선형성 도입</td><td>ReLU (기본), GELU (Transformer계열)</td></tr>
                <tr><td>출력 풀링</td><td>특성맵→벡터 변환</td><td>GlobalAveragePooling (Flatten 대신)</td></tr>
                <tr><td>필터 수 패턴</td><td>깊어질수록 증가</td><td>32→64→128→256 (2배씩)</td></tr>
            </table>

            <h3>RNN/LSTM (시퀀스 데이터)</h3>

            <p>순환 신경망(Recurrent Neural Network)은 시퀀스 데이터(텍스트, 시계열, 음성)를 처리하는
            아키텍처입니다. LSTM과 GRU는 장기 의존성 문제(기울기 소실)를 해결한 발전된 RNN 셀입니다.</p>

            <h4>RNN/LSTM/GRU 비교</h4>
            <table class="comparison-table">
                <tr><th>셀 타입</th><th>게이트</th><th>파라미터</th><th>장점</th><th>단점</th></tr>
                <tr><td>SimpleRNN</td><td>없음</td><td>적음</td><td>간단, 빠름</td><td>기울기 소실 심함, 장기 의존성 불가</td></tr>
                <tr><td>LSTM</td><td>forget, input, output (3개)</td><td>많음</td><td>장기 의존성 학습, 가장 범용</td><td>느림, 메모리 사용 높음</td></tr>
                <tr><td>GRU</td><td>reset, update (2개)</td><td>중간</td><td>LSTM과 유사 성능, 더 빠름</td><td>매우 긴 시퀀스에서 LSTM보다 약간 열세</td></tr>
            </table>

            <h4>LSTM/GRU — Keras 구현</h4>
            <div class="code-block">
<span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras
<span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers

<span class="comment"># 텍스트 분류 (감정 분석)</span>
model = keras.Sequential([
    layers.Embedding(<span class="number">10000</span>, <span class="number">128</span>),         <span class="comment"># 어휘 10000개 → 128차원 벡터</span>
    layers.LSTM(<span class="number">128</span>, dropout=<span class="number">0.2</span>),         <span class="comment"># 마지막 타임스텝 출력만 반환</span>
    layers.Dense(<span class="number">1</span>, activation=<span class="string">"sigmoid"</span>)  <span class="comment"># 이진 분류</span>
])

<span class="comment"># 양방향 (Bidirectional) — 과거+미래 문맥 모두 활용</span>
model = keras.Sequential([
    layers.Embedding(<span class="number">10000</span>, <span class="number">128</span>),
    layers.Bidirectional(layers.LSTM(<span class="number">64</span>)),   <span class="comment"># 출력 차원: 64×2 = 128</span>
    layers.Dense(<span class="number">1</span>, activation=<span class="string">"sigmoid"</span>)
])

<span class="comment"># 다층 (Stacked) LSTM — return_sequences=True로 모든 타임스텝 전달</span>
model = keras.Sequential([
    layers.Embedding(<span class="number">10000</span>, <span class="number">128</span>),
    layers.LSTM(<span class="number">128</span>, return_sequences=<span class="keyword">True</span>, dropout=<span class="number">0.2</span>),  <span class="comment"># (batch, seq, 128)</span>
    layers.LSTM(<span class="number">64</span>, dropout=<span class="number">0.2</span>),                              <span class="comment"># (batch, 64)</span>
    layers.Dense(<span class="number">1</span>, activation=<span class="string">"sigmoid"</span>)
])

<span class="comment"># GRU — LSTM보다 경량, 비슷한 성능</span>
model = keras.Sequential([
    layers.Embedding(<span class="number">10000</span>, <span class="number">128</span>),
    layers.GRU(<span class="number">64</span>, return_sequences=<span class="keyword">True</span>),
    layers.GRU(<span class="number">32</span>),
    layers.Dense(<span class="number">1</span>, activation=<span class="string">"sigmoid"</span>)
])

<span class="comment"># 시계열 예측 (Sequence-to-One)</span>
model = keras.Sequential([
    layers.LSTM(<span class="number">64</span>, input_shape=(<span class="number">30</span>, <span class="number">5</span>)),    <span class="comment"># 30 타임스텝, 5 특성</span>
    layers.Dense(<span class="number">1</span>)                           <span class="comment"># 다음 값 예측 (회귀)</span>
])

<span class="comment"># 시계열 다중 스텝 예측 (Sequence-to-Sequence)</span>
model = keras.Sequential([
    layers.LSTM(<span class="number">64</span>, return_sequences=<span class="keyword">True</span>, input_shape=(<span class="number">30</span>, <span class="number">5</span>)),
    layers.LSTM(<span class="number">32</span>, return_sequences=<span class="keyword">True</span>),
    layers.TimeDistributed(layers.Dense(<span class="number">1</span>))  <span class="comment"># 각 타임스텝에 Dense 적용</span>
])
            </div>

            <h4>LSTM/GRU — PyTorch 구현</h4>
            <div class="code-block">
<span class="keyword">import</span> torch
<span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn

<span class="keyword">class</span> <span class="function">TextClassifier</span>(nn.Module):
    <span class="keyword">def</span> <span class="function">__init__</span>(self, vocab_size, embed_dim, hidden_dim, num_classes):
        <span class="builtin">super</span>().__init__()
        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=<span class="number">0</span>)
        self.lstm = nn.LSTM(
            embed_dim, hidden_dim,
            num_layers=<span class="number">2</span>,           <span class="comment"># 2층 스택</span>
            batch_first=<span class="keyword">True</span>,       <span class="comment"># 입력: (batch, seq, features)</span>
            bidirectional=<span class="keyword">True</span>,     <span class="comment"># 양방향</span>
            dropout=<span class="number">0.3</span>,             <span class="comment"># 층 간 드롭아웃</span>
        )
        self.fc = nn.Linear(hidden_dim * <span class="number">2</span>, num_classes)  <span class="comment"># ×2: 양방향</span>
        self.dropout = nn.Dropout(<span class="number">0.5</span>)

    <span class="keyword">def</span> <span class="function">forward</span>(self, x):
        embedded = self.embedding(x)         <span class="comment"># (batch, seq, embed_dim)</span>
        output, (hidden, cell) = self.lstm(embedded)
        <span class="comment"># hidden: (num_layers*directions, batch, hidden_dim)</span>
        <span class="comment"># 마지막 층의 정방향 + 역방향 결합</span>
        hidden = torch.cat([hidden[-<span class="number">2</span>], hidden[-<span class="number">1</span>]], dim=<span class="number">1</span>)
        <span class="keyword">return</span> self.fc(self.dropout(hidden))

<span class="comment"># GRU 버전 — cell state 없음</span>
<span class="keyword">class</span> <span class="function">GRUClassifier</span>(nn.Module):
    <span class="keyword">def</span> <span class="function">__init__</span>(self, vocab_size, embed_dim, hidden_dim, num_classes):
        <span class="builtin">super</span>().__init__()
        self.embedding = nn.Embedding(vocab_size, embed_dim)
        self.gru = nn.GRU(embed_dim, hidden_dim, batch_first=<span class="keyword">True</span>, bidirectional=<span class="keyword">True</span>)
        self.fc = nn.Linear(hidden_dim * <span class="number">2</span>, num_classes)

    <span class="keyword">def</span> <span class="function">forward</span>(self, x):
        embedded = self.embedding(x)
        output, hidden = self.gru(embedded)   <span class="comment"># GRU는 hidden만 반환 (cell 없음)</span>
        hidden = torch.cat([hidden[-<span class="number">2</span>], hidden[-<span class="number">1</span>]], dim=<span class="number">1</span>)
        <span class="keyword">return</span> self.fc(hidden)

<span class="comment"># 시계열 예측</span>
<span class="keyword">class</span> <span class="function">TimeSeriesLSTM</span>(nn.Module):
    <span class="keyword">def</span> <span class="function">__init__</span>(self, input_dim, hidden_dim, output_dim):
        <span class="builtin">super</span>().__init__()
        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=<span class="number">2</span>,
                            batch_first=<span class="keyword">True</span>, dropout=<span class="number">0.2</span>)
        self.fc = nn.Linear(hidden_dim, output_dim)

    <span class="keyword">def</span> <span class="function">forward</span>(self, x):
        out, _ = self.lstm(x)       <span class="comment"># (batch, seq_len, hidden_dim)</span>
        <span class="keyword">return</span> self.fc(out[:, -<span class="number">1</span>, :])  <span class="comment"># 마지막 타임스텝만 사용</span>
            </div>

            <h4>패딩 &amp; 패킹 (가변 길이 시퀀스 처리)</h4>
            <div class="code-block">
<span class="comment"># Keras — 자동 패딩/마스킹</span>
padded = keras.utils.pad_sequences(sequences, maxlen=<span class="number">200</span>, padding=<span class="string">"post"</span>)
<span class="comment"># Embedding의 mask_zero=True로 패딩 위치 자동 무시</span>
layers.Embedding(<span class="number">10000</span>, <span class="number">128</span>, mask_zero=<span class="keyword">True</span>)

<span class="comment"># PyTorch — pack_padded_sequence (효율적 연산)</span>
<span class="keyword">from</span> torch.nn.utils.rnn <span class="keyword">import</span> pad_sequence, pack_padded_sequence, pad_packed_sequence

<span class="comment"># 가변 길이 시퀀스 패딩</span>
sequences = [torch.tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]), torch.tensor([<span class="number">4</span>,<span class="number">5</span>]), torch.tensor([<span class="number">6</span>])]
padded = pad_sequence(sequences, batch_first=<span class="keyword">True</span>, padding_value=<span class="number">0</span>)
<span class="comment"># tensor([[1, 2, 3],</span>
<span class="comment">#         [4, 5, 0],</span>
<span class="comment">#         [6, 0, 0]])</span>

lengths = torch.tensor([<span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>])
packed = pack_padded_sequence(padded, lengths, batch_first=<span class="keyword">True</span>, enforce_sorted=<span class="keyword">False</span>)
output, hidden = lstm(packed)                         <span class="comment"># 패딩 위치 연산 건너뜀</span>
output, out_lengths = pad_packed_sequence(output, batch_first=<span class="keyword">True</span>)  <span class="comment"># 다시 패딩</span>
            </div>

            <div class="warning-box">
                <strong>주의:</strong>
                <code>return_sequences=True</code>(Keras) / <code>output</code>(PyTorch)는 모든 타임스텝의 출력을 반환합니다.
                다층 RNN에서 중간 레이어는 반드시 모든 타임스텝을 다음 레이어에 전달해야 합니다.
                PyTorch LSTM의 기본 입력은 <code>(seq, batch, features)</code>이며, <code>batch_first=True</code>로
                <code>(batch, seq, features)</code>로 변경하는 것을 권장합니다.
            </div>

            <h4>RNN/LSTM 핵심 정리</h4>
            <table class="comparison-table">
                <tr><th>작업</th><th>권장 구조</th><th>비고</th></tr>
                <tr><td>텍스트 분류</td><td>Embedding → BiLSTM → Dense</td><td>양방향이 단방향보다 우수</td></tr>
                <tr><td>감성 분석</td><td>Embedding → BiGRU → Dense</td><td>GRU가 더 빠르고 비슷한 성능</td></tr>
                <tr><td>시계열 예측 (단일)</td><td>LSTM → Dense(1)</td><td>마지막 타임스텝 사용</td></tr>
                <tr><td>시계열 예측 (다중)</td><td>LSTM(return_seq) → TimeDistributed</td><td>모든 타임스텝 예측</td></tr>
                <tr><td>기계 번역</td><td>Encoder-Decoder + Attention</td><td>Transformer로 대체 추세</td></tr>
                <tr><td>음성 인식</td><td>BiLSTM + CTC Loss</td><td>가변 길이 정렬 불필요</td></tr>
                <tr><td>일반 권장</td><td>Transformer</td><td>긴 시퀀스, 병렬화 우수</td></tr>
            </table>

            <h3>Transformer (자연어 처리)</h3>

            <p>Transformer는 Self-Attention 메커니즘 기반으로 시퀀스를 병렬 처리하는 아키텍처입니다.
            RNN의 순차 처리 한계를 극복하여 NLP(BERT, GPT), 비전(ViT), 음성 등 거의 모든 분야에서
            최고 성능을 달성하고 있습니다. "Attention Is All You Need" (2017) 논문에서 제안되었습니다.</p>

            <h4>Self-Attention 메커니즘</h4>
            <div class="code-block">
<span class="comment"># Scaled Dot-Product Attention</span>
<span class="comment">#</span>
<span class="comment"># Attention(Q, K, V) = softmax(Q·K^T / √d_k) · V</span>
<span class="comment">#</span>
<span class="comment"># Q (Query)  : "내가 찾는 것" — 각 토큰이 다른 토큰에게 묻는 질의</span>
<span class="comment"># K (Key)    : "내가 가진 것" — 각 토큰이 제공하는 키</span>
<span class="comment"># V (Value)  : "내 내용"     — 실제 전달할 정보</span>
<span class="comment"># √d_k       : 스케일링 — 내적 값이 커지면 softmax 기울기 소실 방지</span>

<span class="keyword">import</span> torch
<span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn
<span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F
<span class="keyword">import</span> math

<span class="keyword">def</span> <span class="function">scaled_dot_product_attention</span>(Q, K, V, mask=<span class="keyword">None</span>):
    d_k = Q.size(-<span class="number">1</span>)
    scores = torch.matmul(Q, K.transpose(-<span class="number">2</span>, -<span class="number">1</span>)) / math.sqrt(d_k)  <span class="comment"># (batch, heads, seq, seq)</span>
    <span class="keyword">if</span> mask <span class="keyword">is not</span> <span class="keyword">None</span>:
        scores = scores.masked_fill(mask == <span class="number">0</span>, <span class="builtin">float</span>(<span class="string">"-inf"</span>))         <span class="comment"># 마스킹 위치 -∞</span>
    attn_weights = F.softmax(scores, dim=-<span class="number">1</span>)                          <span class="comment"># 어텐션 가중치</span>
    output = torch.matmul(attn_weights, V)                             <span class="comment"># 가중 합</span>
    <span class="keyword">return</span> output, attn_weights
            </div>

            <h4>Multi-Head Attention (PyTorch 구현)</h4>
            <div class="code-block">
<span class="keyword">class</span> <span class="function">MultiHeadAttention</span>(nn.Module):
    <span class="keyword">def</span> <span class="function">__init__</span>(self, d_model, num_heads):
        <span class="builtin">super</span>().__init__()
        <span class="keyword">assert</span> d_model % num_heads == <span class="number">0</span>
        self.d_model = d_model
        self.num_heads = num_heads
        self.d_k = d_model // num_heads

        self.W_q = nn.Linear(d_model, d_model)
        self.W_k = nn.Linear(d_model, d_model)
        self.W_v = nn.Linear(d_model, d_model)
        self.W_o = nn.Linear(d_model, d_model)

    <span class="keyword">def</span> <span class="function">forward</span>(self, query, key, value, mask=<span class="keyword">None</span>):
        batch_size = query.size(<span class="number">0</span>)

        <span class="comment"># 선형 변환 후 헤드 분할: (batch, seq, d_model) → (batch, heads, seq, d_k)</span>
        Q = self.W_q(query).view(batch_size, -<span class="number">1</span>, self.num_heads, self.d_k).transpose(<span class="number">1</span>, <span class="number">2</span>)
        K = self.W_k(key).view(batch_size, -<span class="number">1</span>, self.num_heads, self.d_k).transpose(<span class="number">1</span>, <span class="number">2</span>)
        V = self.W_v(value).view(batch_size, -<span class="number">1</span>, self.num_heads, self.d_k).transpose(<span class="number">1</span>, <span class="number">2</span>)

        <span class="comment"># Scaled Dot-Product Attention</span>
        attn_out, attn_weights = scaled_dot_product_attention(Q, K, V, mask)

        <span class="comment"># 헤드 결합: (batch, heads, seq, d_k) → (batch, seq, d_model)</span>
        attn_out = attn_out.transpose(<span class="number">1</span>, <span class="number">2</span>).contiguous().view(batch_size, -<span class="number">1</span>, self.d_model)
        <span class="keyword">return</span> self.W_o(attn_out)

<span class="comment"># PyTorch 내장 (권장 — Flash Attention 자동 적용)</span>
mha = nn.MultiheadAttention(embed_dim=<span class="number">512</span>, num_heads=<span class="number">8</span>, batch_first=<span class="keyword">True</span>)
attn_output, attn_weights = mha(query, key, value, attn_mask=mask)
            </div>

            <h4>Positional Encoding</h4>
            <div class="code-block">
<span class="comment"># Transformer는 위치 정보가 없으므로 Positional Encoding을 추가</span>
<span class="comment"># PE(pos, 2i)   = sin(pos / 10000^(2i/d_model))</span>
<span class="comment"># PE(pos, 2i+1) = cos(pos / 10000^(2i/d_model))</span>

<span class="keyword">class</span> <span class="function">PositionalEncoding</span>(nn.Module):
    <span class="keyword">def</span> <span class="function">__init__</span>(self, d_model, max_len=<span class="number">5000</span>, dropout=<span class="number">0.1</span>):
        <span class="builtin">super</span>().__init__()
        self.dropout = nn.Dropout(dropout)

        pe = torch.zeros(max_len, d_model)
        position = torch.arange(<span class="number">0</span>, max_len).unsqueeze(<span class="number">1</span>).float()
        div_term = torch.exp(torch.arange(<span class="number">0</span>, d_model, <span class="number">2</span>).float() * -(math.log(<span class="number">10000.0</span>) / d_model))

        pe[:, <span class="number">0</span>::<span class="number">2</span>] = torch.sin(position * div_term)  <span class="comment"># 짝수 인덱스: sin</span>
        pe[:, <span class="number">1</span>::<span class="number">2</span>] = torch.cos(position * div_term)  <span class="comment"># 홀수 인덱스: cos</span>
        pe = pe.unsqueeze(<span class="number">0</span>)  <span class="comment"># (1, max_len, d_model)</span>
        self.register_buffer(<span class="string">"pe"</span>, pe)

    <span class="keyword">def</span> <span class="function">forward</span>(self, x):
        x = x + self.pe[:, :x.size(<span class="number">1</span>)]
        <span class="keyword">return</span> self.dropout(x)
            </div>

            <h4>Transformer Encoder Block</h4>
            <div class="code-block">
<span class="keyword">class</span> <span class="function">TransformerEncoderBlock</span>(nn.Module):
    <span class="keyword">def</span> <span class="function">__init__</span>(self, d_model, num_heads, d_ff, dropout=<span class="number">0.1</span>):
        <span class="builtin">super</span>().__init__()
        self.self_attn = nn.MultiheadAttention(d_model, num_heads, batch_first=<span class="keyword">True</span>)
        self.ffn = nn.Sequential(
            nn.Linear(d_model, d_ff),     <span class="comment"># d_ff = d_model × 4 가 일반적</span>
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(d_ff, d_model),
        )
        self.norm1 = nn.LayerNorm(d_model)
        self.norm2 = nn.LayerNorm(d_model)
        self.dropout = nn.Dropout(dropout)

    <span class="keyword">def</span> <span class="function">forward</span>(self, x, mask=<span class="keyword">None</span>):
        <span class="comment"># Pre-LayerNorm 구조 (Post-LN보다 학습 안정적)</span>
        normed = self.norm1(x)
        attn_out, _ = self.self_attn(normed, normed, normed, attn_mask=mask)
        x = x + self.dropout(attn_out)     <span class="comment"># 잔차 연결</span>

        normed = self.norm2(x)
        ffn_out = self.ffn(normed)
        x = x + self.dropout(ffn_out)      <span class="comment"># 잔차 연결</span>
        <span class="keyword">return</span> x

<span class="comment"># PyTorch 내장 Encoder (권장)</span>
encoder_layer = nn.TransformerEncoderLayer(
    d_model=<span class="number">512</span>, nhead=<span class="number">8</span>, dim_feedforward=<span class="number">2048</span>,
    dropout=<span class="number">0.1</span>, activation=<span class="string">"gelu"</span>, batch_first=<span class="keyword">True</span>, norm_first=<span class="keyword">True</span>
)
encoder = nn.TransformerEncoder(encoder_layer, num_layers=<span class="number">6</span>)
            </div>

            <h4>Transformer Decoder Block</h4>
            <div class="code-block">
<span class="keyword">class</span> <span class="function">TransformerDecoderBlock</span>(nn.Module):
    <span class="keyword">def</span> <span class="function">__init__</span>(self, d_model, num_heads, d_ff, dropout=<span class="number">0.1</span>):
        <span class="builtin">super</span>().__init__()
        self.self_attn = nn.MultiheadAttention(d_model, num_heads, batch_first=<span class="keyword">True</span>)
        self.cross_attn = nn.MultiheadAttention(d_model, num_heads, batch_first=<span class="keyword">True</span>)
        self.ffn = nn.Sequential(
            nn.Linear(d_model, d_ff), nn.GELU(), nn.Dropout(dropout),
            nn.Linear(d_ff, d_model),
        )
        self.norm1 = nn.LayerNorm(d_model)
        self.norm2 = nn.LayerNorm(d_model)
        self.norm3 = nn.LayerNorm(d_model)
        self.dropout = nn.Dropout(dropout)

    <span class="keyword">def</span> <span class="function">forward</span>(self, x, encoder_out, tgt_mask=<span class="keyword">None</span>, memory_mask=<span class="keyword">None</span>):
        <span class="comment"># ① Masked Self-Attention (미래 토큰 참조 방지)</span>
        normed = self.norm1(x)
        attn_out, _ = self.self_attn(normed, normed, normed, attn_mask=tgt_mask)
        x = x + self.dropout(attn_out)

        <span class="comment"># ② Cross-Attention (인코더 출력 참조)</span>
        normed = self.norm2(x)
        attn_out, _ = self.cross_attn(normed, encoder_out, encoder_out, attn_mask=memory_mask)
        x = x + self.dropout(attn_out)

        <span class="comment"># ③ Feed-Forward</span>
        normed = self.norm3(x)
        x = x + self.dropout(self.ffn(normed))
        <span class="keyword">return</span> x

<span class="comment"># Causal Mask 생성 (디코더용 — 미래 토큰 가리기)</span>
<span class="keyword">def</span> <span class="function">generate_causal_mask</span>(seq_len):
    <span class="keyword">return</span> torch.triu(torch.ones(seq_len, seq_len), diagonal=<span class="number">1</span>).bool()
    <span class="comment"># [[False, True,  True ],</span>
    <span class="comment">#  [False, False, True ],</span>
    <span class="comment">#  [False, False, False]]</span>
            </div>

            <h4>완전한 Transformer 모델 (분류)</h4>
            <div class="code-block">
<span class="keyword">class</span> <span class="function">TransformerClassifier</span>(nn.Module):
    <span class="keyword">def</span> <span class="function">__init__</span>(self, vocab_size, d_model=<span class="number">256</span>, num_heads=<span class="number">8</span>,
                 num_layers=<span class="number">4</span>, d_ff=<span class="number">512</span>, num_classes=<span class="number">2</span>,
                 max_len=<span class="number">512</span>, dropout=<span class="number">0.1</span>):
        <span class="builtin">super</span>().__init__()
        self.embedding = nn.Embedding(vocab_size, d_model)
        self.pos_encoding = PositionalEncoding(d_model, max_len, dropout)

        encoder_layer = nn.TransformerEncoderLayer(
            d_model, num_heads, d_ff, dropout,
            activation=<span class="string">"gelu"</span>, batch_first=<span class="keyword">True</span>, norm_first=<span class="keyword">True</span>
        )
        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers)
        self.classifier = nn.Sequential(
            nn.LayerNorm(d_model),
            nn.Linear(d_model, num_classes)
        )

    <span class="keyword">def</span> <span class="function">forward</span>(self, x, src_mask=<span class="keyword">None</span>):
        x = self.embedding(x) * math.sqrt(self.d_model)  <span class="comment"># 스케일링</span>
        x = self.pos_encoding(x)
        x = self.encoder(x, src_key_padding_mask=src_mask)
        x = x.mean(dim=<span class="number">1</span>)        <span class="comment"># 평균 풀링 (또는 [CLS] 토큰)</span>
        <span class="keyword">return</span> self.classifier(x)
            </div>

            <h4>Hugging Face Transformers 활용</h4>
            <div class="code-block">
<span class="comment"># pip install transformers datasets</span>

<span class="comment"># ① Pipeline — 가장 간단한 사용법 (추론 전용)</span>
<span class="keyword">from</span> transformers <span class="keyword">import</span> pipeline

<span class="comment"># 감성 분석</span>
classifier = pipeline(<span class="string">"sentiment-analysis"</span>)
result = classifier(<span class="string">"This movie is amazing!"</span>)
<span class="comment"># [{'label': 'POSITIVE', 'score': 0.9998}]</span>

<span class="comment"># 텍스트 생성</span>
generator = pipeline(<span class="string">"text-generation"</span>, model=<span class="string">"gpt2"</span>)
output = generator(<span class="string">"The future of AI"</span>, max_length=<span class="number">50</span>)

<span class="comment"># 질의응답</span>
qa = pipeline(<span class="string">"question-answering"</span>)
result = qa(question=<span class="string">"What is PyTorch?"</span>, context=<span class="string">"PyTorch is a deep learning framework."</span>)

<span class="comment"># 요약</span>
summarizer = pipeline(<span class="string">"summarization"</span>, model=<span class="string">"facebook/bart-large-cnn"</span>)
summary = summarizer(long_text, max_length=<span class="number">130</span>, min_length=<span class="number">30</span>)

<span class="comment"># ② 직접 모델 로드 — 토크나이저 + 모델</span>
<span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer, AutoModel, AutoModelForSequenceClassification

tokenizer = AutoTokenizer.from_pretrained(<span class="string">"bert-base-uncased"</span>)
model = AutoModelForSequenceClassification.from_pretrained(<span class="string">"bert-base-uncased"</span>, num_labels=<span class="number">2</span>)

<span class="comment"># 토크나이징</span>
inputs = tokenizer(
    <span class="string">"Hello, how are you?"</span>,
    padding=<span class="keyword">True</span>,
    truncation=<span class="keyword">True</span>,
    max_length=<span class="number">128</span>,
    return_tensors=<span class="string">"pt"</span>     <span class="comment"># "pt"=PyTorch, "tf"=TensorFlow, "np"=NumPy</span>
)
<span class="comment"># {'input_ids': tensor([[101, 7592, ...]]), 'attention_mask': tensor([[1, 1, ...]])}</span>

outputs = model(**inputs)
logits = outputs.logits     <span class="comment"># (batch, num_labels)</span>

<span class="comment"># ③ 파인튜닝 (Hugging Face Trainer)</span>
<span class="keyword">from</span> transformers <span class="keyword">import</span> TrainingArguments, Trainer
<span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset

dataset = load_dataset(<span class="string">"imdb"</span>)

<span class="keyword">def</span> <span class="function">tokenize_fn</span>(examples):
    <span class="keyword">return</span> tokenizer(examples[<span class="string">"text"</span>], truncation=<span class="keyword">True</span>, max_length=<span class="number">256</span>)

tokenized = dataset.map(tokenize_fn, batched=<span class="keyword">True</span>)

training_args = TrainingArguments(
    output_dir=<span class="string">"./results"</span>,
    num_train_epochs=<span class="number">3</span>,
    per_device_train_batch_size=<span class="number">16</span>,
    per_device_eval_batch_size=<span class="number">64</span>,
    learning_rate=<span class="number">2e-5</span>,
    weight_decay=<span class="number">0.01</span>,
    eval_strategy=<span class="string">"epoch"</span>,
    save_strategy=<span class="string">"epoch"</span>,
    load_best_model_at_end=<span class="keyword">True</span>,
    fp16=<span class="keyword">True</span>,                <span class="comment"># 혼합 정밀도</span>
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized[<span class="string">"train"</span>],
    eval_dataset=tokenized[<span class="string">"test"</span>],
)
trainer.train()
            </div>

            <h4>주요 Transformer 모델 비교</h4>
            <table class="comparison-table">
                <tr><th>모델</th><th>구조</th><th>특징</th><th>주요 용도</th></tr>
                <tr><td>BERT</td><td>Encoder</td><td>양방향, MLM+NSP 사전학습</td><td>분류, QA, NER</td></tr>
                <tr><td>GPT-2/3/4</td><td>Decoder</td><td>단방향, 자기회귀 생성</td><td>텍스트 생성, 대화</td></tr>
                <tr><td>T5</td><td>Encoder-Decoder</td><td>모든 NLP를 text-to-text로 통합</td><td>번역, 요약, QA</td></tr>
                <tr><td>BART</td><td>Encoder-Decoder</td><td>노이즈 제거 자기부호화기</td><td>요약, 번역</td></tr>
                <tr><td>RoBERTa</td><td>Encoder</td><td>BERT 학습 전략 최적화</td><td>분류, NER (BERT 대체)</td></tr>
                <tr><td>DeBERTa</td><td>Encoder</td><td>분리된 어텐션 + 향상된 디코딩</td><td>SuperGLUE SOTA</td></tr>
                <tr><td>ViT</td><td>Encoder</td><td>이미지를 패치로 분할하여 처리</td><td>이미지 분류</td></tr>
                <tr><td>Whisper</td><td>Encoder-Decoder</td><td>음성→텍스트 범용 모델</td><td>음성 인식, 번역</td></tr>
                <tr><td>LLaMA</td><td>Decoder</td><td>효율적 오픈소스 LLM</td><td>텍스트 생성, 추론</td></tr>
            </table>

            <div class="tip-box">
                <strong>Transformer 하이퍼파라미터 가이드:</strong>
                <code>d_model</code> = 임베딩 차원 (256~1024),
                <code>num_heads</code> = 어텐션 헤드 수 (d_model의 약수, 보통 8~16),
                <code>d_ff</code> = FFN 히든 차원 (보통 d_model × 4),
                <code>num_layers</code> = 블록 수 (6~12).
                학습률은 워밍업(warmup) 후 감소하는 스케줄이 필수적입니다.
            </div>

            <h4>Transformer 핵심 정리</h4>
            <table class="comparison-table">
                <tr><th>구성 요소</th><th>역할</th><th>핵심 포인트</th></tr>
                <tr><td>Self-Attention</td><td>토큰 간 관계 모델링</td><td>O(n²) 복잡도, Flash Attention으로 개선</td></tr>
                <tr><td>Multi-Head</td><td>다양한 관계 패턴 포착</td><td>헤드별 독립 어텐션 후 결합</td></tr>
                <tr><td>Positional Encoding</td><td>순서 정보 부여</td><td>sin/cos (고정) 또는 학습 가능</td></tr>
                <tr><td>Feed-Forward</td><td>비선형 변환</td><td>각 위치에 독립 적용 (MLP)</td></tr>
                <tr><td>LayerNorm</td><td>학습 안정화</td><td>Pre-LN (블록 앞) 이 더 안정적</td></tr>
                <tr><td>잔차 연결</td><td>그래디언트 흐름 보존</td><td>모든 서브레이어에 적용</td></tr>
                <tr><td>Causal Mask</td><td>미래 토큰 가리기</td><td>디코더/자기회귀 모델 필수</td></tr>
                <tr><td>Cross-Attention</td><td>인코더-디코더 연결</td><td>Q=디코더, K/V=인코더</td></tr>
            </table>

            <h3>전이 학습 (Transfer Learning)</h3>

            <p>전이 학습은 대규모 데이터로 사전학습된 모델의 지식을 새로운 작업에 재활용하는 기법입니다.
            적은 데이터와 짧은 학습 시간으로 높은 성능을 달성할 수 있어, 실무에서 모델을 처음부터
            학습하는 경우보다 전이 학습을 사용하는 경우가 훨씬 더 많습니다.</p>

            <h4>전이 학습 전략</h4>
            <table class="comparison-table">
                <tr><th>전략</th><th>방법</th><th>데이터 양</th><th>적합한 경우</th></tr>
                <tr><td>Feature Extraction</td><td>사전학습 레이어 동결, 헤드만 학습</td><td>적음 (&lt;1000)</td><td>새 데이터가 원본과 유사</td></tr>
                <tr><td>Fine-tuning (전체)</td><td>모든 레이어를 낮은 lr로 학습</td><td>많음 (&gt;10000)</td><td>데이터 충분, 도메인 다름</td></tr>
                <tr><td>Gradual Unfreezing</td><td>뒤쪽 레이어부터 순차적 해동</td><td>중간</td><td>안정적인 파인튜닝</td></tr>
                <tr><td>Discriminative LR</td><td>레이어별 다른 학습률</td><td>중간~많음</td><td>앞쪽=낮은lr, 뒤쪽=높은lr</td></tr>
            </table>

            <h4>이미지 전이 학습 — Keras</h4>
            <div class="code-block">
<span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras
<span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers
<span class="keyword">from</span> tensorflow.keras.applications <span class="keyword">import</span> EfficientNetV2B0, ResNet50V2

<span class="comment"># ① Feature Extraction (특성 추출) — 사전학습 레이어 동결</span>
base_model = EfficientNetV2B0(weights=<span class="string">"imagenet"</span>, include_top=<span class="keyword">False</span>, input_shape=(<span class="number">224</span>, <span class="number">224</span>, <span class="number">3</span>))
base_model.trainable = <span class="keyword">False</span>   <span class="comment"># 모든 레이어 동결</span>

model = keras.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dropout(<span class="number">0.3</span>),
    layers.Dense(<span class="number">128</span>, activation=<span class="string">"relu"</span>),
    layers.Dense(<span class="number">10</span>, activation=<span class="string">"softmax"</span>)
])

model.compile(optimizer=keras.optimizers.Adam(<span class="number">1e-3</span>),  <span class="comment"># 높은 lr OK (헤드만 학습)</span>
              loss=<span class="string">"sparse_categorical_crossentropy"</span>, metrics=[<span class="string">"accuracy"</span>])
model.fit(train_ds, epochs=<span class="number">10</span>, validation_data=val_ds)

<span class="comment"># ② Fine-tuning — 헤드 학습 후 일부 레이어 해동</span>
base_model.trainable = <span class="keyword">True</span>
<span class="keyword">for</span> layer <span class="keyword">in</span> base_model.layers[:-<span class="number">30</span>]:   <span class="comment"># 앞쪽 레이어는 동결 유지</span>
    layer.trainable = <span class="keyword">False</span>

model.compile(optimizer=keras.optimizers.Adam(<span class="number">1e-5</span>),  <span class="comment"># 매우 낮은 lr (기존 가중치 보호)</span>
              loss=<span class="string">"sparse_categorical_crossentropy"</span>, metrics=[<span class="string">"accuracy"</span>])
model.fit(train_ds, epochs=<span class="number">10</span>, validation_data=val_ds)

<span class="comment"># 사용 가능한 사전학습 모델</span>
<span class="comment"># keras.applications.EfficientNetV2B0~L  — 효율적, 최신 권장</span>
<span class="comment"># keras.applications.ResNet50V2          — 범용, 검증된 성능</span>
<span class="comment"># keras.applications.MobileNetV3Large    — 모바일/엣지용</span>
<span class="comment"># keras.applications.ConvNeXtTiny        — 최신 순수 CNN</span>
            </div>

            <h4>이미지 전이 학습 — PyTorch</h4>
            <div class="code-block">
<span class="keyword">import</span> torch
<span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn
<span class="keyword">from</span> torchvision <span class="keyword">import</span> models

<span class="comment"># ① Feature Extraction</span>
model = models.efficientnet_v2_s(weights=<span class="string">"IMAGENET1K_V1"</span>)

<span class="comment"># 모든 레이어 동결</span>
<span class="keyword">for</span> param <span class="keyword">in</span> model.parameters():
    param.requires_grad = <span class="keyword">False</span>

<span class="comment"># 분류 헤드 교체</span>
model.classifier = nn.Sequential(
    nn.Dropout(<span class="number">0.3</span>),
    nn.Linear(model.classifier[<span class="number">1</span>].in_features, <span class="number">10</span>)
)

<span class="comment"># 교체된 헤드만 학습됨 (requires_grad=True 기본)</span>
optimizer = torch.optim.Adam(model.classifier.parameters(), lr=<span class="number">1e-3</span>)

<span class="comment"># ② Fine-tuning — Discriminative Learning Rate</span>
<span class="keyword">for</span> param <span class="keyword">in</span> model.parameters():
    param.requires_grad = <span class="keyword">True</span>       <span class="comment"># 전체 해동</span>

optimizer = torch.optim.AdamW([
    {<span class="string">"params"</span>: model.features[:<span class="number">5</span>].parameters(), <span class="string">"lr"</span>: <span class="number">1e-6</span>},   <span class="comment"># 앞쪽: 아주 낮은 lr</span>
    {<span class="string">"params"</span>: model.features[<span class="number">5</span>:].parameters(), <span class="string">"lr"</span>: <span class="number">1e-5</span>},   <span class="comment"># 중간: 낮은 lr</span>
    {<span class="string">"params"</span>: model.classifier.parameters(), <span class="string">"lr"</span>: <span class="number">1e-3</span>},     <span class="comment"># 헤드: 높은 lr</span>
], weight_decay=<span class="number">0.01</span>)

<span class="comment"># ResNet 헤드 교체</span>
resnet = models.resnet50(weights=<span class="string">"IMAGENET1K_V2"</span>)
resnet.fc = nn.Linear(resnet.fc.in_features, <span class="number">10</span>)  <span class="comment"># 마지막 FC 교체</span>

<span class="comment"># ViT (Vision Transformer) 전이 학습</span>
vit = models.vit_b_16(weights=<span class="string">"IMAGENET1K_V1"</span>)
vit.heads = nn.Linear(vit.heads[<span class="number">0</span>].in_features, <span class="number">10</span>)
            </div>

            <h4>NLP 전이 학습 — Hugging Face</h4>
            <div class="code-block">
<span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer, AutoModelForSequenceClassification

<span class="comment"># 사전학습 모델 + 분류 헤드</span>
model_name = <span class="string">"bert-base-uncased"</span>
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=<span class="number">3</span>)

<span class="comment"># Layer-wise Learning Rate Decay (LLRD)</span>
<span class="keyword">from</span> transformers <span class="keyword">import</span> AdamW

no_decay = [<span class="string">"bias"</span>, <span class="string">"LayerNorm.weight"</span>]
optimizer_grouped = []
lr = <span class="number">2e-5</span>
decay_rate = <span class="number">0.9</span>

<span class="keyword">for</span> i <span class="keyword">in</span> <span class="builtin">range</span>(<span class="number">12</span>, -<span class="number">1</span>, -<span class="number">1</span>):   <span class="comment"># BERT 12층 → 0층</span>
    layer_lr = lr * (decay_rate ** (<span class="number">12</span> - i))
    layer_params = [(n, p) <span class="keyword">for</span> n, p <span class="keyword">in</span> model.named_parameters() <span class="keyword">if</span> f<span class="string">"layer.{i}."</span> <span class="keyword">in</span> n]
    optimizer_grouped.append({
        <span class="string">"params"</span>: [p <span class="keyword">for</span> n, p <span class="keyword">in</span> layer_params <span class="keyword">if</span> <span class="keyword">not</span> <span class="builtin">any</span>(nd <span class="keyword">in</span> n <span class="keyword">for</span> nd <span class="keyword">in</span> no_decay)],
        <span class="string">"lr"</span>: layer_lr, <span class="string">"weight_decay"</span>: <span class="number">0.01</span>
    })

<span class="comment"># 한국어 모델 예시</span>
<span class="comment"># tokenizer = AutoTokenizer.from_pretrained("klue/bert-base")</span>
<span class="comment"># model = AutoModelForSequenceClassification.from_pretrained("klue/bert-base", num_labels=5)</span>
            </div>

            <h4>사전학습 모델 비교 (이미지)</h4>
            <table class="comparison-table">
                <tr><th>모델</th><th>파라미터</th><th>ImageNet Top-1</th><th>추론 속도</th><th>적합한 용도</th></tr>
                <tr><td>MobileNetV3-Small</td><td>2.5M</td><td>67.5%</td><td>매우 빠름</td><td>모바일, 엣지</td></tr>
                <tr><td>EfficientNet-B0</td><td>5.3M</td><td>77.1%</td><td>빠름</td><td>경량 서버</td></tr>
                <tr><td>ResNet-50</td><td>25M</td><td>80.9%</td><td>보통</td><td>범용 베이스라인</td></tr>
                <tr><td>EfficientNetV2-S</td><td>21M</td><td>84.2%</td><td>보통</td><td>서버 권장</td></tr>
                <tr><td>ConvNeXt-Tiny</td><td>29M</td><td>82.1%</td><td>보통</td><td>현대 CNN</td></tr>
                <tr><td>ViT-B/16</td><td>86M</td><td>84.5%</td><td>느림</td><td>대규모 데이터</td></tr>
                <tr><td>EfficientNetV2-L</td><td>118M</td><td>85.7%</td><td>느림</td><td>최고 정확도</td></tr>
            </table>

            <div class="warning-box">
                <strong>전이 학습 주의사항:</strong>
                Feature extraction 단계에서는 높은 학습률(1e-3)을 사용해도 되지만,
                fine-tuning 단계에서는 반드시 낮은 학습률(1e-5~1e-4)을 사용하세요 — 사전학습 가중치가 파괴됩니다.
                입력 이미지의 전처리(정규화 값)는 사전학습 시 사용된 것과 동일해야 합니다.
                데이터가 매우 적으면(&lt;500) fine-tuning 대신 feature extraction만 사용하세요.
            </div>

            <h4>전이 학습 핵심 정리</h4>
            <table class="comparison-table">
                <tr><th>단계</th><th>동결 범위</th><th>학습률</th><th>에포크</th></tr>
                <tr><td>1. Feature Extraction</td><td>사전학습 전체 동결</td><td>1e-3</td><td>5~10</td></tr>
                <tr><td>2. Fine-tuning (뒤쪽)</td><td>앞쪽 동결, 뒤쪽 30% 해동</td><td>1e-5</td><td>5~15</td></tr>
                <tr><td>3. Fine-tuning (전체)</td><td>전체 해동 (선택)</td><td>1e-5~1e-6</td><td>3~5</td></tr>
                <tr><td>NLP Fine-tuning</td><td>전체 해동 + LLRD</td><td>2e-5 (상위) ~2e-6 (하위)</td><td>3~5</td></tr>
            </table>

            <div class="level-guide beginner">
                <div class="level-guide-header">초급자 가이드 - 딥러닝이란 무엇인가?</div>
                <div class="level-guide-content">
                    <p>딥러닝을 일상적인 비유로 이해해보세요:</p>
                    <ul>
                        <li><strong>신경망 = 뇌의 모방</strong>: 인간의 뇌처럼 여러 층(layer)의 뉴런이 연결되어 정보를 처리합니다. "깊은(deep)" 학습이라는 이름은 이 층이 여러 개라는 뜻입니다.</li>
                        <li><strong>학습 과정</strong>: (1) 데이터를 보여줌 → (2) 예측함 → (3) 정답과 비교 → (4) 틀린 만큼 조정 → 반복. 이것이 "역전파(Backpropagation)"의 핵심입니다.</li>
                        <li><strong>CNN = 이미지 전문가</strong>: 사진에서 특징(모서리, 패턴, 형태)을 단계적으로 인식합니다.</li>
                        <li><strong>RNN/LSTM = 시퀀스 전문가</strong>: 문장의 앞뒤 문맥을 기억하며 처리합니다.</li>
                        <li><strong>Transformer = 현대 AI의 핵심</strong>: ChatGPT, DALL-E 등 최신 AI의 기반 구조입니다.</li>
                    </ul>
                    <p><strong>시작 팁:</strong> 수학이 부족해도 걱정하지 마세요. Keras는 <code>model.add(Dense(64, activation="relu"))</code>처럼 블록 쌓기 방식으로 모델을 만들 수 있습니다.</p>
                </div>
            </div>

            <div class="level-guide intermediate">
                <div class="level-guide-header">중급자 가이드 - 딥러닝 실전 개발 전략</div>
                <div class="level-guide-content">
                    <p>효과적인 딥러닝 모델 개발을 위한 실전 가이드:</p>
                    <ul>
                        <li><strong>전이 학습 우선</strong>: 처음부터 모델을 훈련하지 마세요. ResNet, BERT, GPT 등 사전 훈련된 모델을 Fine-tuning하는 것이 일반적으로 더 빠르고 좋은 성능을 냅니다.</li>
                        <li><strong>데이터 증강(Augmentation)</strong>: 이미지 회전, 반전, 크롭 등으로 훈련 데이터를 인위적으로 늘립니다. <code>torchvision.transforms</code>나 <code>albumentations</code>를 활용합니다.</li>
                        <li><strong>학습률(Learning Rate)</strong>: 가장 중요한 하이퍼파라미터입니다. Learning Rate Finder로 최적값을 찾고, Cosine Annealing이나 OneCycleLR 스케줄러를 사용합니다.</li>
                        <li><strong>과적합 방지</strong>: Dropout, Early Stopping, Weight Decay(L2 정규화), 데이터 증강을 조합하여 과적합을 방지합니다.</li>
                        <li><strong>Mixed Precision Training</strong>: <code>torch.cuda.amp</code>로 FP16/FP32 혼합 정밀도를 사용하면 메모리 50% 절약, 학습 속도 2-3배 향상이 가능합니다.</li>
                    </ul>
                </div>
            </div>

            <div class="level-guide advanced">
                <div class="level-guide-header">고급자 가이드 - 대규모 모델 학습과 최적화</div>
                <div class="level-guide-content">
                    <p>프로덕션 수준의 딥러닝 시스템을 위한 고급 기법:</p>
                    <ul>
                        <li><strong>분산 학습</strong>: <code>DistributedDataParallel(DDP)</code>로 멀티 GPU 학습을 수행합니다. DeepSpeed나 FSDP(Fully Sharded Data Parallel)로 수백억 파라미터 모델도 학습 가능합니다.</li>
                        <li><strong>모델 압축</strong>: 양자화(Quantization, INT8/INT4), 지식 증류(Knowledge Distillation), 가지치기(Pruning)로 모델 크기를 줄이고 추론 속도를 높입니다.</li>
                        <li><strong>LLM Fine-tuning</strong>: LoRA(Low-Rank Adaptation), QLoRA로 대규모 언어 모델을 효율적으로 미세조정합니다. PEFT(Parameter-Efficient Fine-Tuning) 라이브러리가 이를 쉽게 만들어줍니다.</li>
                        <li><strong>추론 최적화</strong>: TensorRT, ONNX Runtime, vLLM으로 추론 속도를 최적화합니다. KV Cache, Flash Attention, Speculative Decoding 등의 기법이 사용됩니다.</li>
                        <li><strong>RAG(Retrieval Augmented Generation)</strong>: LLM에 외부 지식을 결합하여 환각(hallucination)을 줄이고 최신 정보를 반영합니다. LangChain, LlamaIndex 등의 프레임워크를 활용합니다.</li>
                    </ul>
                </div>
            </div>

        </section>

        <section id="resources">
            <h2>15. 참고 자료 & 다음 단계</h2>
            <span class="level-badge level-beginner">초급</span>
            <span class="level-badge level-intermediate">중급</span>
            <span class="level-badge level-advanced">고급</span>
            
            <h3>추천 학습 리소스</h3>
            <p>파이썬 학습의 핵심은 <strong>공식 문서를 기준</strong>으로 삼고, 실습 프로젝트를 통해 지식을 체화하는 것입니다. 다음은 신뢰할 수 있는 주요 학습 리소스입니다.</p>
            <div class="resource-links">
                <a href="https://docs.python.org/ko/3/" class="resource-link" target="_blank">
                    <strong>공식 문서</strong>
                    <p>Python 공식 문서</p>
                </a>
                <a href="https://www.python.org/" class="resource-link" target="_blank">
                    <strong>Python.org</strong>
                    <p>파이썬 공식 웹사이트</p>
                </a>
                <a href="https://wikidocs.net/" class="resource-link" target="_blank">
                    <strong>위키독스</strong>
                    <p>한국어 파이썬 튜토리얼</p>
                </a>
                <a href="https://github.com/" class="resource-link" target="_blank">
                    <strong>GitHub</strong>
                    <p>오픈소스 프로젝트</p>
                </a>
            </div>
            
            <h3>주요 라이브러리</h3>
            <p>파이썬의 진정한 힘은 풍부한 서드파티 라이브러리 생태계에 있습니다. 웹 개발, 데이터 분석, AI, 자동화 등 모든 분야에서 검증된 라이브러리를 활용하면 개발 시간을 획기적으로 단축할 수 있습니다.</p>
            <div class="feature-grid">
                <div class="feature-card">
                    <h4>🌐 웹 프레임워크</h4>
                    <ul>
                        <li><strong>Django</strong> - Full-stack 프레임워크</li>
                        <li><strong>Flask</strong> - 경량 웹 프레임워크</li>
                        <li><strong>FastAPI</strong> - 최신 비동기 API</li>
                    </ul>
                </div>
                <div class="feature-card">
                    <h4>📊 데이터 분석</h4>
                    <ul>
                        <li><strong>NumPy</strong> - 수치 계산</li>
                        <li><strong>Pandas</strong> - 데이터 처리</li>
                        <li><strong>Matplotlib</strong> - 시각화</li>
                    </ul>
                </div>
                <div class="feature-card">
                    <h4>🤖 머신러닝/AI</h4>
                    <ul>
                        <li><strong>TensorFlow</strong> - 딥러닝</li>
                        <li><strong>PyTorch</strong> - 딥러닝</li>
                        <li><strong>scikit-learn</strong> - ML 라이브러리</li>
                    </ul>
                </div>
                <div class="feature-card">
                    <h4>🔧 유틸리티</h4>
                    <ul>
                        <li><strong>requests</strong> - HTTP 요청</li>
                        <li><strong>BeautifulSoup</strong> - 웹 스크래핑</li>
                        <li><strong>SQLAlchemy</strong> - DB ORM</li>
                    </ul>
                </div>
            </div>
            
            <h3>학습 로드맵</h3>
            <p>파이썬 학습은 단계적으로 진행하는 것이 효과적입니다. 기초 문법부터 시작하여 자료구조, 함수, OOP를 익히고, 이후 관심 분야(웹, 데이터, AI 등)에 맞는 전문 라이브러리를 학습하는 것이 권장됩니다.</p>
            <div class="svg-container">
                <svg width="800" height="400" viewBox="0 0 800 400" xmlns="http://www.w3.org/2000/svg">
                    <defs>
                        <marker id="arrow-roadmap" markerWidth="10" markerHeight="7" refX="9" refY="3.5" orient="auto">
                            <polygon points="0 0, 10 3.5, 0 7" fill="#667eea"/>
                        </marker>
                    </defs>

                    <!-- Stage 1 -->
                    <rect x="30" y="30" width="170" height="80" rx="15" fill="#4CAF50"/>
                    <text x="115" y="65" text-anchor="middle" fill="white" font-weight="bold" font-size="14">1단계: 기초</text>
                    <text x="115" y="90" text-anchor="middle" fill="white" font-size="11">문법, 변수, 제어문</text>

                    <!-- Arrow 1 -->
                    <line x1="200" y1="70" x2="250" y2="70" stroke="#667eea" stroke-width="3" marker-end="url(#arrow-roadmap)"/>

                    <!-- Stage 2 -->
                    <rect x="250" y="30" width="170" height="80" rx="15" fill="#2196F3"/>
                    <text x="335" y="65" text-anchor="middle" fill="white" font-weight="bold" font-size="14">2단계: 함수&자료구조</text>
                    <text x="335" y="90" text-anchor="middle" fill="white" font-size="11">함수, 리스트, 딕셔너리</text>

                    <!-- Arrow 2 -->
                    <line x1="420" y1="70" x2="470" y2="70" stroke="#667eea" stroke-width="3" marker-end="url(#arrow-roadmap)"/>

                    <!-- Stage 3 -->
                    <rect x="470" y="30" width="170" height="80" rx="15" fill="#FF9800"/>
                    <text x="555" y="65" text-anchor="middle" fill="white" font-weight="bold" font-size="14">3단계: 객체지향</text>
                    <text x="555" y="90" text-anchor="middle" fill="white" font-size="11">클래스, 상속, 캡슐화</text>

                    <!-- Arrow 3 -->
                    <line x1="640" y1="70" x2="690" y2="70" stroke="#667eea" stroke-width="3" marker-end="url(#arrow-roadmap)"/>

                    <!-- Stage 4 -->
                    <rect x="690" y="30" width="80" height="80" rx="15" fill="#9C27B0"/>
                    <text x="730" y="65" text-anchor="middle" fill="white" font-weight="bold" font-size="14">4단계</text>
                    <text x="730" y="85" text-anchor="middle" fill="white" font-size="11">실전</text>

                    <!-- Middle Section -->
                    <rect x="250" y="150" width="300" height="60" rx="10" fill="var(--svg-blue)" stroke="#2196F3" stroke-width="2"/>
                    <text x="400" y="185" text-anchor="middle" fill="var(--svg-blue-text)" font-weight="bold">실전 프로젝트 진행</text>

                    <!-- Bottom Section -->
                    <rect x="30" y="240" width="740" height="130" rx="15" fill="var(--svg-gray)" stroke="var(--border)" stroke-width="2"/>
                    <text x="400" y="270" text-anchor="middle" font-weight="bold" fill="var(--text-primary)" font-size="16">전문 분야 선택</text>

                    <rect x="50" y="290" width="150" height="60" rx="10" fill="var(--svg-green)" stroke="#4CAF50"/>
                    <text x="125" y="325" text-anchor="middle" fill="var(--svg-green-text)" font-weight="bold">웹 개발</text>

                    <rect x="220" y="290" width="150" height="60" rx="10" fill="var(--svg-orange)" stroke="#ff9800"/>
                    <text x="295" y="325" text-anchor="middle" fill="var(--svg-orange-text)" font-weight="bold">데이터 분석</text>

                    <rect x="390" y="290" width="150" height="60" rx="10" fill="var(--svg-blue)" stroke="#2196F3"/>
                    <text x="465" y="325" text-anchor="middle" fill="var(--svg-blue-text)" font-weight="bold">AI/ML</text>

                    <rect x="560" y="290" width="150" height="60" rx="10" fill="var(--svg-pink)" stroke="#e91e63"/>
                    <text x="635" y="325" text-anchor="middle" fill="var(--svg-pink-text)" font-weight="bold">자동화/스크립트</text>
                </svg>
            </div>
            
            <h3>빠른 참조 Cheat Sheet</h3>
            <p>자주 사용하는 파이썬 문법과 함수를 카테고리별로 정리한 빠른 참조표입니다. 코딩 중 문법이 기억나지 않을 때 빠르게 찾아볼 수 있습니다.</p>
            <table class="comparison-table">
                <tr><th>카테고리</th><th>주요 함수/문법</th></tr>
                <tr><td>문자열</td><td>.upper(), .lower(), .strip(), .split(), .join(), f-string, .replace(), .find()</td></tr>
                <tr><td>리스트</td><td>.append(), .extend(), .pop(), .sort(), .reverse(), list comprehension</td></tr>
                <tr><td>딕셔너리</td><td>.keys(), .values(), .items(), .get(), dict comprehension, {**d1, **d2}</td></tr>
                <tr><td>집합</td><td>.add(), .remove(), | (합집합), & (교집합), - (차집합)</td></tr>
                <tr><td>파일</td><td>open(), read(), readlines(), write(), with문</td></tr>
                <tr><td>예외</td><td>try/except/finally, raise, except (Error1, Error2)</td></tr>
                <tr><td>함수</td><td>def, *args, **kwargs, lambda, map(), filter()</td></tr>
                <tr><td>클래스</td><td>class, __init__, self, @property, @staticmethod, @classmethod</td></tr>
                <tr><td>타입힌트</td><td>: int, -> str, List[int], Dict[str, Any], Optional[X]</td></tr>
            </table>
            
            <h3>itertools 예제</h3>
            <p><code>itertools</code>는 효율적인 반복 작업을 위한 표준 라이브러리 모듈입니다. 순열(permutations), 조합(combinations), 체이닝(chain), 누적(accumulate) 등 수학적 반복 패턴을 <strong>메모리 효율적인 이터레이터</strong>로 제공합니다.</p>
            <div class="code-block">
<span class="keyword">from</span> itertools <span class="keyword">import</span> chain, combinations, permutations, accumulate

<span class="comment"># 체인</span>
list(chain([<span class="number">1</span>,<span class="number">2</span>], [<span class="number">3</span>,<span class="number">4</span>]))  <span class="comment"># [1,2,3,4]</span>

<span class="comment"># 순열</span>
list(permutations(<span class="string">"ABC"</span>, <span class="number">2</span>))  <span class="comment"># [('A','B'), ('A','C'), ...]</span>

<span class="comment"># 조합</span>
list(combinations(<span class="string">"ABC"</span>, <span class="number">2</span>))  <span class="comment"># [('A','B'), ('A','C'), ('B','C')]</span>

<span class="comment"># 누적</span>
list(accumulate([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>]))  <span class="comment"># [1, 3, 6, 10]</span>
            </div>
            
            <h3>functools 예제</h3>
            <p><code>functools</code>는 함수형 프로그래밍을 지원하는 고차 함수 모듈입니다. <code>@lru_cache</code>는 함수 결과를 캐싱하여 반복 호출을 최적화하고, <code>partial</code>은 함수의 일부 인자를 미리 고정하며, <code>reduce</code>는 시퀀스를 하나의 값으로 누적 계산합니다.</p>
            <div class="code-block">
<span class="keyword">from</span> functools <span class="keyword">import</span> lru_cache, partial, reduce

<span class="comment"># 메모이제이션</span>
<span class="decorator">@lru_cache</span>
<span class="keyword">def</span> <span class="function">fib</span>(n):
    <span class="keyword">if</span> n < <span class="number">2</span>: <span class="keyword">return</span> n
    <span class="keyword">return</span> fib(n-<span class="number">1</span>) + fib(n-<span class="number">2</span>)

<span class="comment"># 부분 함수</span>
add5 = partial(<span class="keyword">lambda</span> x, y: x + y, <span class="number">5</span>)
add5(<span class="number">3</span>)  <span class="comment"># 8</span>

<span class="comment"># 누적 계산</span>
reduce(<span class="keyword">lambda</span> x, y: x + y, [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>])  <span class="comment"># 10</span>
            </div>
            
            <h3>collections 예제</h3>
            <p><code>collections</code>는 내장 컨테이너(dict, list, set, tuple)를 확장한 특수 자료구조를 제공합니다. <code>Counter</code>는 요소 빈도를 세고, <code>defaultdict</code>는 존재하지 않는 키에 기본값을 자동 생성하며, <code>deque</code>는 양쪽 끝에서 O(1) 삽입/삭제가 가능한 큐입니다.</p>
            <div class="code-block">
<span class="keyword">from</span> collections <span class="keyword">import</span> Counter, defaultdict, OrderedDict

<span class="comment"># 카운터</span>
Counter(<span class="string">"hello"</span>)  <span class="comment"># Counter({'l':2, 'h':1, 'e':1, 'o':1})</span>

<span class="comment"># 기본값 딕셔너리</span>
d = defaultdict(<span class="builtin">int</span>)
d[<span class="string">"count"</span>] += <span class="number">1</span>  <span class="comment"># 오류 없이 1</span>
            </div>
            
            <h3>PEP 주요 규칙</h3>
            <p><strong>PEP(Python Enhancement Proposal)</strong>는 파이썬의 새로운 기능, 코딩 스타일, 프로세스 등을 제안하는 공식 문서입니다. 특히 <strong>PEP 8</strong>(코딩 스타일 가이드)은 파이썬 커뮤니티의 사실상 표준이며, 모든 파이썬 개발자가 숙지해야 할 핵심 문서입니다.</p>
            <ul>
                <li><strong>PEP 8</strong>: Python 스타일 가이드</li>
                <li><strong>PEP 20</strong>: Python 철학 (import this)</li>
                <li><strong>PEP 257</strong>: Docstring 규칙</li>
                <li><strong>PEP 484</strong>: 타입 힌트</li>
                <li><strong>PEP 498</strong>: f-string</li>
                <li><strong>PEP 572</strong>: Walrus 연산자 (:=)</li>
                <li><strong>PEP 622</strong>: Structural Pattern Matching</li>
            </ul>
            
            <div class="level-guide beginner">
                <div class="level-guide-header">초급자 학습 전략 - 파이썬 시작하기</div>
                <div class="level-guide-content">
                    <p>프로그래밍이 처음이라면 다음 순서로 학습하세요:</p>
                    <ul>
                        <li><strong>1주차</strong>: 변수, 자료형, print() 익히기. 간단한 계산기 프로그램 만들기.</li>
                        <li><strong>2주차</strong>: if/else 조건문, for/while 반복문. 구구단, 가위바위보 게임 만들기.</li>
                        <li><strong>3주차</strong>: 리스트, 딕셔너리 다루기. 학생 성적 관리 프로그램 만들기.</li>
                        <li><strong>4주차</strong>: 함수 정의와 호출. 기존 코드를 함수로 리팩토링하기.</li>
                        <li><strong>5-6주차</strong>: 파일 입출력, 예외 처리. 메모장 프로그램, 주소록 프로그램 만들기.</li>
                    </ul>
                    <p><strong>핵심 조언:</strong> "이론 30% + 실습 70%" 비율을 유지하세요. 강의를 듣고 끝나는 것이 아니라, 직접 코드를 타이핑하고 수정해보는 것이 가장 효과적입니다. 에러 메시지를 두려워하지 마세요 - 에러가 곧 학습의 기회입니다!</p>
                </div>
            </div>

            <div class="level-guide intermediate">
                <div class="level-guide-header">중급자 학습 전략 - 실무 역량 키우기</div>
                <div class="level-guide-content">
                    <p>기초 문법을 넘어 실무 개발자로 성장하기 위한 전략:</p>
                    <ul>
                        <li><strong>프로젝트 기반 학습</strong>: 웹 스크래퍼, REST API 서버, 데이터 분석 대시보드, CLI 도구 등 실제 동작하는 프로젝트를 완성하세요.</li>
                        <li><strong>오픈소스 기여</strong>: GitHub에서 관심 있는 프로젝트의 이슈를 해결하며 실전 경험을 쌓으세요. "good first issue" 태그를 찾아보세요.</li>
                        <li><strong>코드 품질 도구</strong>: <code>black</code>(포매터), <code>ruff</code>(린터), <code>mypy</code>(타입 체커), <code>pytest</code>(테스트)를 프로젝트에 도입하세요.</li>
                        <li><strong>디자인 패턴</strong>: 싱글턴, 팩토리, 옵저버, 데코레이터 패턴 등을 파이썬에 맞게 구현해보세요.</li>
                        <li><strong>알고리즘</strong>: LeetCode, 프로그래머스에서 Python으로 알고리즘 문제를 풀며 자료구조와 알고리즘 역량을 키우세요.</li>
                    </ul>
                </div>
            </div>

            <div class="level-guide advanced">
                <div class="level-guide-header">고급자 학습 전략 - 전문가 수준 도달하기</div>
                <div class="level-guide-content">
                    <p>시니어 개발자/아키텍트 수준으로 도약하기 위한 심화 학습:</p>
                    <ul>
                        <li><strong>CPython 소스코드 읽기</strong>: <code>cpython/Objects/</code> 디렉토리의 C 소스코드를 읽으며 파이썬의 내부 동작을 이해하세요. <code>listobject.c</code>, <code>dictobject.c</code>부터 시작합니다.</li>
                        <li><strong>동시성/병렬성 마스터</strong>: asyncio 이벤트 루프, Threading, Multiprocessing, concurrent.futures의 차이와 적합한 사용 상황을 완벽히 이해하세요.</li>
                        <li><strong>시스템 설계</strong>: 마이크로서비스 아키텍처, 메시지 큐(RabbitMQ, Kafka), 캐싱(Redis), 컨테이너(Docker, K8s)와 파이썬 서비스의 통합을 학습하세요.</li>
                        <li><strong>성능 프로파일링</strong>: <code>cProfile</code>, <code>py-spy</code>, <code>memory_profiler</code>로 CPU/메모리 병목을 분석하고, Cython이나 Rust 바인딩(PyO3)으로 핫스팟을 최적화하세요.</li>
                        <li><strong>PEP 제안 추적</strong>: Python Steering Council의 결정과 새로운 PEP를 추적하며 언어의 진화 방향을 이해하세요. <code>discuss.python.org</code>에서 커뮤니티 논의에 참여할 수 있습니다.</li>
                    </ul>
                </div>
            </div>

            <div class="quiz-box">
                <h3>🎓 마무리 퀴즈</h3>
                <p>파이썬 학습을 시작하셨습니다! 다음 중 어느 분야에 가장 관심이 있으신가요?</p>
                <div class="quiz-option" onclick="alert('웹 개발은 Django, Flask, FastAPI를 배우보세요!')">🌐 웹 개발</div>
                <div class="quiz-option" onclick="alert('데이터 분석은 Pandas, NumPy, Matplotlib을 배우보세요!')">📊 데이터 분석</div>
                <div class="quiz-option" onclick="alert('AI/ML은 TensorFlow, PyTorch, scikit-learn을 배우보세요!')">🤖 머신러닝/AI</div>
                <div class="quiz-option" onclick="alert('자동화는 Selenium, BeautifulSoup, requests를 배우보세요!')">⚡ 자동화/스크립트</div>
            </div>
        </section>
        
            <footer>
                <p>© 2025 MINZKN.COM. Python Complete Guide</p>
                <p>초급부터 고급 개발자까지 모두를 위한 파이썬 레퍼런스</p>
                <p>Licensed under the <a href="https://opensource.org/licenses/MIT" target="_blank" rel="noopener">MIT License</a></p>
            </footer>

        </main>
    </div><!-- /.layout -->

    <!-- 위로가기 버튼 -->
    <button class="back-to-top" id="backToTop" aria-label="맨 위로 이동">↑</button>

    <script>
        // ─── 테마 관리 ────────────────────────────────────────
        const THEME_KEY = 'pydocs_theme';

        function applyTheme(theme) {
            document.documentElement.setAttribute('data-theme', theme);
            const icon = document.querySelector('.theme-icon');
            if (icon) icon.textContent = theme === 'dark' ? '☀️' : '🌙';
        }

        // 저장된 테마 복원 (기본: dark)
        applyTheme(localStorage.getItem(THEME_KEY) || 'dark');

        document.getElementById('themeToggle').addEventListener('click', () => {
            const next = document.documentElement.getAttribute('data-theme') === 'dark' ? 'light' : 'dark';
            localStorage.setItem(THEME_KEY, next);
            applyTheme(next);
        });

        // ─── 모바일 사이드바 ──────────────────────────────────
        const hamburger  = document.getElementById('hamburger');
        const sideNav    = document.getElementById('sideNav');
        const navOverlay = document.getElementById('navOverlay');

        function openNav() {
            sideNav.classList.add('open');
            navOverlay.classList.add('active');
            hamburger.classList.add('open');
            document.body.style.overflow = 'hidden';
        }

        function closeNav() {
            sideNav.classList.remove('open');
            navOverlay.classList.remove('active');
            hamburger.classList.remove('open');
            document.body.style.overflow = '';
        }

        hamburger.addEventListener('click', () =>
            sideNav.classList.contains('open') ? closeNav() : openNav()
        );
        navOverlay.addEventListener('click', closeNav);

        // 링크 클릭 시 모바일 메뉴 닫기
        sideNav.querySelectorAll('a').forEach(link => {
            link.addEventListener('click', () => {
                if (window.innerWidth <= 1024) closeNav();
            });
        });

        // ─── 스크롤 프로그레스 바 + 위로가기 버튼 ────────────
        const progressBar = document.getElementById('progressBar');
        const backToTop   = document.getElementById('backToTop');

        window.addEventListener('scroll', () => {
            const scrolled = document.documentElement.scrollTop;
            const height   = document.documentElement.scrollHeight - document.documentElement.clientHeight;
            progressBar.style.width = ((scrolled / height) * 100) + '%';
            backToTop.classList.toggle('visible', scrolled > 400);
        }, { passive: true });

        backToTop.addEventListener('click', () =>
            window.scrollTo({ top: 0, behavior: 'smooth' })
        );

        // ─── 스크롤 스파이 (IntersectionObserver) ─────────────
        const navLinks = document.querySelectorAll('.side-nav a');

        const observer = new IntersectionObserver((entries) => {
            entries.forEach(entry => {
                if (entry.isIntersecting) {
                    const id = entry.target.getAttribute('id');
                    navLinks.forEach(link =>
                        link.classList.toggle('active', link.getAttribute('href') === '#' + id)
                    );
                }
            });
        }, {
            rootMargin: '-60px 0px -60% 0px',
            threshold: 0
        });

        document.querySelectorAll('section[id]').forEach(sec => observer.observe(sec));

        // ─── 레벨 가이드 박스 토글 ────────────────────────────
        document.querySelectorAll('.level-guide-header').forEach(header => {
            header.addEventListener('click', () => {
                header.classList.toggle('collapsed');
                const content = header.nextElementSibling;
                if (content) content.classList.toggle('collapsed');
            });
        });
    </script>
</body>
</html>
